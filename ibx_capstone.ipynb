{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_GJz9NHXViPRErw5CmROBgksbu_y3Q5B",
      "authorship_tag": "ABX9TyOfRbi4jGQvBx+voZXlRor/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawa1983/Capstone/blob/main/ibx_capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feasibility of Implementing the GTFS Stops-to-GeoDataFrame Workflow Entirely in Python\n",
        "\n",
        "## Executive summary\n",
        "\n",
        "From my perspective as the implementer, **every task implied by our conversation and the attached notebook-style pipeline can be implemented using Python code**, including: reading GTFS `stops.txt` from GitHub, handling parsing issues, filtering by `location_type`, constructing a `GeoDataFrame` from `stop_lon/stop_lat`, reprojecting, buffering, spatial joins, mapping, exporting, and even scaling to large GTFS tables with an embedded analytical engine (DuckDB). The key nuance is what “entirely in Python” means in practice:\n",
        "\n",
        "Python can orchestrate all steps, but several geospatial capabilities rely on **native (non-Python) libraries** under the hood—most notably **GEOS, PROJ, and GDAL** that power Shapely/GeoPandas’ geometry, CRS transforms, and file I/O. GeoPandas explicitly notes this dependency stack and that installation can be challenging without managed environments. citeturn2search1turn2search6\n",
        "\n",
        "Similarly, any pipeline that downloads MTA GTFS feeds, Census ACS data, NYC Open Data (Socrata), or GBFS feeds is still “Python-implemented,” but requires **network access** and sometimes **API keys / rate-limit hygiene** (especially for Census and Socrata). citeturn10search1turn11search0turn12view0\n",
        "\n",
        "## Inventory of tasks and code patterns implied by the conversation and attached pipeline\n",
        "\n",
        "Below is a consolidated inventory of the operations I need to support, grouped by the work they perform. (This includes the explicit items you listed and the additional geospatial/data-engineering patterns present in the attached pipeline.)\n",
        "\n",
        "Data acquisition and ingestion includes reading GTFS text files (especially `stops.txt`) from a GitHub-hosted location and learning to avoid the “blob page HTML” trap; pandas can read URLs directly, but only if the URL resolves to the raw file. The GitHub UI explicitly provides a “Raw” view for unstylized file contents—which is what scripts should target. citeturn6search15turn5view0\n",
        "\n",
        "Robust parsing includes handling `ParserError` conditions, malformed rows, delimiter/quoting mismatches, encoding issues, and choosing appropriate parsing engines. Pandas supports an `engine` parameter and `on_bad_lines` behavior to skip/warn/process malformed lines. citeturn5view0turn1view2\n",
        "\n",
        "GTFS semantics includes treating `stop_lat`/`stop_lon` as the stop coordinates and using `location_type` to distinguish platforms/stops vs stations and other location types. The GTFS reference defines the allowed `location_type` values (0/empty stop/platform; 1 station; 2 entrance/exit; 3 generic node; 4 boarding area) and specifies when `stop_lat/stop_lon` are required. citeturn7view0turn1view1\n",
        "\n",
        "Geospatial modeling includes creating point geometries from longitude/latitude (`points_from_xy`), setting CRS (usually EPSG:4326 for GTFS), reprojecting to a projected CRS for accurate distance/area work (`to_crs`), building buffers, and forming study-area bounding boxes/unions. GeoPandas explicitly documents that `points_from_xy` assumes x=longitude and y=latitude for geographic coordinates. citeturn1view3turn1view5\n",
        "\n",
        "Spatial analytics includes spatial joins (`sjoin`) with predicates (`within`, `intersects`, sometimes `dwithin`), nearest-neighbor queries using spatial indexes (`sindex`), clipping layers, and computing derived metrics (counts/densities, proximity distances). GeoPandas documents `sjoin` and notes that operations are planar (not geodesic). citeturn1view4turn3search3\n",
        "\n",
        "Scaling and performance includes using DuckDB to query large GTFS tables (e.g., `stop_times.txt`, `trips.txt`, `routes.txt`) without loading everything into pandas; DuckDB documents CSV “auto detection” and provides `read_csv_auto`/`read_csv` paths to handle varied CSV dialects. citeturn3search1turn3search1\n",
        "\n",
        "Outputs include exporting tabular results (CSV) and geospatial layers (GeoPackage, GeoJSON, etc.). GeoPandas’ `to_file` writes via the Pyogrio or Fiona I/O engines (both GDAL/OGR-backed), and supports drivers such as `\"GPKG\"`. citeturn2search0turn9search2\n",
        "\n",
        "Visualization includes static plotting (GeoPandas/Matplotlib) and interactive HTML maps (Folium). Folium’s documentation shows standard patterns for MarkerCluster and saving maps to HTML. citeturn3search8turn3search0  \n",
        "If I choose Kepler.gl, I must account for Jupyter extension requirements (Node + JupyterLab extensions) beyond Python-only pip installs. citeturn4search2\n",
        "\n",
        "## Python implementation patterns for each major task\n",
        "\n",
        "I can implement every item you enumerated with mainstream Python libraries; the sections below focus on the most “load-bearing” patterns and parameters I need to get right.\n",
        "\n",
        "For reading GTFS from GitHub correctly, the core rule is: **don’t use a `.../blob/...` URL with pandas** because that serves an HTML page. Instead, I use a raw-content URL (either via GitHub’s “Raw” view or the `raw.githubusercontent.com` format), which is explicitly meant to show raw file content without styling. citeturn6search15\n",
        "\n",
        "For parsing and handling malformed rows, pandas provides the knobs I need. The `engine` parameter governs the parsing backend, and `on_bad_lines` defines how to handle lines with too many fields; it supports `'error'`, `'warn'`, `'skip'`, or a callable (noting callable signatures differ across engines). citeturn5view0turn1view2  \n",
        "Separators and quoting are equally important: `sep` can be a single-character delimiter or regex, but regex delimiters force the Python engine and can ignore quoted data. citeturn5view1\n",
        "\n",
        "For filtering stations using `location_type`, I must treat GTFS semantics carefully: a station is `location_type=1` per the GTFS reference; platforms/stops are `location_type=0` or empty. citeturn7view0turn1view1  \n",
        "In real feeds, `location_type` might be missing or blank; in those cases, robust code defaults missing values to 0 (stop/platform) and filters accordingly.\n",
        "\n",
        "For creating a GeoDataFrame from stop longitude and latitude, GeoPandas gives me the canonical pattern: `geopandas.points_from_xy(x, y, crs=...)` and then `GeoDataFrame(..., geometry=...)`. GeoPandas explicitly documents that for geographic coordinates it assumes `x = longitude` and `y = latitude`. citeturn1view3\n",
        "\n",
        "For reprojection, `GeoDataFrame.to_crs()` is the standard. It requires that the current CRS is set, and it transforms coordinates assuming **planar segments** (it does not perform geodesic transformations of entire geometries). citeturn1view5  \n",
        "For city-scale distance/buffer analysis, I typically reproject WGS84 points (EPSG:4326) into an **appropriate projected CRS** (e.g., a local State Plane or UTM zone).\n",
        "\n",
        "For buffering, I use `GeoSeries.buffer(distance)` with distances expressed in the units of the CRS. GeoPandas provides the buffer method at the GeoSeries level. citeturn4search13  \n",
        "The key operational point is that GeoPandas geometry ops are planar. The `sjoin` docs explicitly state every operation is planar, and GeoPandas warns when buffering in a geographic CRS because degrees are not linear units; the practical mitigation is reprojecting first. citeturn1view4turn1view5\n",
        "\n",
        "For spatial joins, I use `geopandas.sjoin(left, right, predicate=...)`, selecting `predicate=\"within\"` for point-in-polygon counts, or `predicate=\"intersects\"` for polygon overlap. GeoPandas documents `sjoin` and supported predicates, and its spatial index documentation explains that `sindex` uses Shapely’s STRtree. citeturn1view4turn3search3\n",
        "\n",
        "For mapping, Folium produces interactive HTML entirely from Python code, but requires a browser (or notebook renderer) to view. Marker clustering is a documented plugin pattern. citeturn3search0turn3search8  \n",
        "If I use Kepler.gl, I still write Python, but the Jupyter integration specifically requires **Node** and JupyterLab extensions—so the runtime environment is not “Python-only.” citeturn4search2\n",
        "\n",
        "For scaling, DuckDB is a strong option for GTFS tables like `stop_times.txt` that can become very large. DuckDB’s CSV auto-detection documentation describes how it infers delimiter/quoting/types because CSV is not self-describing. citeturn3search1\n",
        "\n",
        "## Tasks that require non-Python system dependencies or external services\n",
        "\n",
        "The most important boundary is that many “Python geospatial” libraries are Python interfaces over mature C/C++ geospatial stacks.\n",
        "\n",
        "GeoPandas explicitly states it depends on **GEOS, GDAL, and PROJ**, and warns these can be a challenge to install in some environments. citeturn2search1  \n",
        "Shapely likewise describes itself as manipulating planar geometries and is built on the GEOS library. citeturn2search6  \n",
        "GeoPandas file output uses Pyogrio or Fiona, both of which bind to GDAL/OGR drivers. GeoPandas `to_file` documents that it writes any OGR data source supported by Pyogrio or Fiona. citeturn2search0turn9search6turn2search5  \n",
        "This matters if I interpret “entirely in Python” as “no compiled dependencies”: that stricter goal is generally **not realistic** for serious vector GIS operations because GEOS/PROJ/GDAL are foundational.\n",
        "\n",
        "If the workflow includes raster operations (even “if needed”), Rasterio is Python-controlled but depends on GDAL and its dependencies. citeturn9search0\n",
        "\n",
        "Interactive visualization can introduce non-Python requirements. Folium is pure Python on the generation side, but renders in a web browser (Leaflet JS). citeturn3search8  \n",
        "Kepler.gl’s Jupyter mode requires Node and JupyterLab extensions per official docs. citeturn4search2\n",
        "\n",
        "External services and APIs are also not “purely local,” even though I call them from Python:\n",
        "\n",
        "- ACS via Census API is explicitly an API-based access method. citeturn10search1turn10search5  \n",
        "- NYC Open Data is served via Socrata’s SODA API; Socrata documents the `within_box` geospatial filter I would use for bounding-box queries. citeturn11search0turn11search15  \n",
        "- Socrata geospatial ordering can be subtle: point geometries use GeoJSON/WKT “lon,lat” order, while `within_box` uses “latitude, longitude corners” in conventional order; Socrata documents this distinction. citeturn11search0turn11search17  \n",
        "- GBFS is a published standard; `station_information.json` is a specified feed and is part of the official “Current Version” reference. citeturn12view0turn12view1  \n",
        "- MTA data is published under its developer resources portal. citeturn10search0turn10search8\n",
        "\n",
        "## Environment constraints treated as open-ended\n",
        "\n",
        "Several practical constraints are not specified and materially affect implementation choices:\n",
        "\n",
        "Dataset scale is unknown: a small single-feed GTFS can be handled with pandas; multi-feed (bus-by-borough) plus `stop_times.txt` often motivates DuckDB/Dask/Polars patterns. DuckDB provides a pragmatic “SQL over CSV” approach without requiring a separate database. citeturn3search1\n",
        "\n",
        "Execution environment is unknown (local laptop vs Colab vs server). This primarily impacts geospatial dependency installation: pip wheels may “just work” in some setups, but conda-forge is often the smoother path for GDAL/PROJ/GEOS stacks, which GeoPandas highlights as an installation complexity. citeturn2search1turn2search4\n",
        "\n",
        "Operating system is not stated; Windows environments in particular often benefit from conda distributions for GDAL-family libraries; Docker can provide reproducibility across OSes at the cost of container overhead.\n",
        "\n",
        "Network access and credentials are unspecified: ACS requires a Census API key for production usage; Socrata APIs can require app tokens for better rate limits; some environments block outbound HTTP.\n",
        "\n",
        "## Compatibility table for pip-only, conda-forge, and Docker approaches\n",
        "\n",
        "The table below compares three realistic ways I can run the full pipeline.\n",
        "\n",
        "| Approach | What I mean by it | Typical install commands | Pros | Cons / gotchas |\n",
        "|---|---|---|---|---|\n",
        "| pip-only (wheels) | Use `pip` in venv; rely on prebuilt wheels bundling native libs where available | `python -m venv .venv` → `pip install -U pip` → `pip install pandas geopandas shapely pyproj pyogrio fiona duckdb folium requests networkx` | Fast to start; fits many notebook environments | May hit binary incompatibilities around GDAL/OGR stacks; Pyogrio docs explicitly warn pip installs can encounter GDAL version mismatches depending on what gets compiled/installed. citeturn2search4turn2search1 |\n",
        "| conda-forge | Use conda/mamba to install GeoPandas stack with consistent GDAL/PROJ/GEOS | `mamba create -n geo python=3.12 -c conda-forge geopandas pyogrio fiona gdal pandas shapely pyproj duckdb folium requests networkx` | Most reliable for GDAL/PROJ/GEOS; aligns with GeoPandas guidance that base C libs can be challenging and installation recommendations matter. citeturn2search1turn2search4 | Heavier environment tooling; slower cold-start than pip |\n",
        "| Docker | Containerize OS + dependencies + code | Use a GDAL-capable base image or micromamba image; then install conda-forge stack | Best reproducibility; good for CI and deployment | Requires Docker runtime; file permissions/volumes; for Kepler.gl you still may need Node tooling inside container if running JupyterLab extensions. citeturn4search2 |\n",
        "\n",
        "A useful implementation detail for GeoPandas I/O performance: GeoPandas notes that as of version 1.0 the default I/O engine changed from Fiona to Pyogrio for performance reasons, and the engine can be configured. citeturn9search2\n",
        "\n",
        "## Reference code snippets for robust Python implementations\n",
        "\n",
        "The snippets below are intentionally defensive and cover the workflow elements you listed: raw GitHub reads, parsing failures, filtering station rows, creating GeoDataFrames, reprojecting for distance, buffering, spatial joins, mapping, and exporting.\n",
        "\n",
        "### Reading GTFS `stops.txt` from GitHub robustly"
      ],
      "metadata": {
        "id": "HP0ufKOwy_OF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section A — Spatial Framework"
      ],
      "metadata": {
        "id": "E3ljH9TW2-a3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose of the Code\n",
        "\n",
        "The purpose of this code is to combine two separate transit stop datasets into one clean, unified file. Specifically, it retrieves an existing GTFS stops file from your GitHub repository and merges it with a second file containing IBX stop coordinates. The end goal is to produce an updated stops dataset that includes both the original transit system stops and the IBX stops in a single, usable file.\n",
        "\n",
        "First, the script ensures that GitHub links are usable for data processing. Standard GitHub “blob” URLs display files as web pages rather than raw text, which makes them unsuitable for automated downloads. The code converts those links into raw file URLs so the actual data content can be accessed directly. It then downloads the file and checks that the response is not an HTML page. This validation step prevents errors caused by accidentally loading a webpage instead of the intended dataset.\n",
        "\n",
        "Next, the script loads both the original stops file and the IBX stops file into structured tables using pandas. Once loaded, it standardizes key fields such as latitude, longitude, and location type. This ensures that geographic coordinates are stored as numeric values and that required columns follow a consistent format. Standardizing data types is critical because mapping systems, routing algorithms, and GTFS validation tools rely on properly formatted numerical coordinates and consistent schema structures.\n",
        "\n",
        "After cleaning and standardizing the data, the two datasets are merged into one combined table. The IBX stops are appended to the original stops list, and any duplicate stop identifiers are resolved by keeping the most recent entry. This ensures that IBX stop information overrides older entries if the same stop ID appears in both datasets. The result is a unified dataset without duplicate stop IDs and with consistent formatting across all records.\n",
        "\n",
        "Finally, the combined dataset is saved as a new file. This output serves as an updated GTFS-compatible stops file that includes IBX stops alongside the existing system stops. Overall, the script functions as a streamlined data pipeline: it downloads, validates, cleans, merges, and exports transit stop data into a structured and reusable format suitable for further analysis, mapping, or integration into a GTFS feed.\n"
      ],
      "metadata": {
        "id": "iTnMK_Q25yKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable postponed evaluation of type hints (improves forward reference handling)\n",
        "from __future__ import annotations\n",
        "\n",
        "# Standard library imports\n",
        "import re                     # Used for pattern matching GitHub URLs\n",
        "from io import StringIO       # Allows treating text as a file-like object\n",
        "\n",
        "# Third-party libraries\n",
        "import requests               # Handles HTTP requests to download files\n",
        "import pandas as pd           # Data manipulation and CSV processing\n",
        "\n",
        "\n",
        "def github_blob_to_raw(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert a standard GitHub 'blob' URL into a raw content URL.\n",
        "\n",
        "    Example:\n",
        "    https://github.com/org/repo/blob/main/file.txt\n",
        "    ->\n",
        "    https://raw.githubusercontent.com/org/repo/main/file.txt\n",
        "\n",
        "    If the URL is already raw (or not a GitHub blob link),\n",
        "    return it unchanged.\n",
        "    \"\"\"\n",
        "    # Match GitHub blob URL pattern\n",
        "    m = re.match(r\"^https?://github\\.com/([^/]+)/([^/]+)/blob/([^/]+)/(.*)$\", url)\n",
        "    if not m:\n",
        "        # If it does not match the blob format, return original URL\n",
        "        return url\n",
        "\n",
        "    # Extract organization, repository, branch, and file path\n",
        "    org, repo, branch, path = m.groups()\n",
        "\n",
        "    # Construct equivalent raw GitHub URL\n",
        "    return f\"https://raw.githubusercontent.com/{org}/{repo}/{branch}/{path}\"\n",
        "\n",
        "\n",
        "def read_text_csv(url: str, *, timeout: int = 60) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Download a CSV/text file from a URL and load it into a pandas DataFrame.\n",
        "\n",
        "    - Automatically converts GitHub blob URLs to raw URLs.\n",
        "    - Verifies that the downloaded content is not HTML.\n",
        "    - Parses the file as a comma-separated CSV.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure URL points to raw file content (not a GitHub HTML page)\n",
        "    raw_url = github_blob_to_raw(url)\n",
        "\n",
        "    # Send HTTP GET request to retrieve file contents\n",
        "    r = requests.get(raw_url, timeout=timeout)\n",
        "\n",
        "    # Raise an error if the request failed (e.g., 404 or 500)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    # Inspect the beginning of the response to ensure it is not HTML\n",
        "    head = r.text[:2000].lstrip().lower()\n",
        "    if head.startswith(\"<!doctype html\") or \"<html\" in head[:200]:\n",
        "        raise ValueError(\n",
        "            \"URL did not resolve to raw text content (looks like HTML). \"\n",
        "            \"Use a raw.githubusercontent.com URL.\"\n",
        "        )\n",
        "\n",
        "    # Read the downloaded text into a pandas DataFrame\n",
        "    # - sep=\",\" specifies comma-delimited file\n",
        "    # - on_bad_lines=\"warn\" skips malformed rows with a warning\n",
        "    # - low_memory=False prevents dtype guessing issues\n",
        "    return pd.read_csv(\n",
        "        StringIO(r.text),\n",
        "        sep=\",\",\n",
        "        encoding=\"utf-8\",\n",
        "        on_bad_lines=\"warn\",\n",
        "        engine=\"c\",\n",
        "        low_memory=False,\n",
        "    )\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Load GTFS and IBX stop files\n",
        "# ----------------------------\n",
        "\n",
        "# Load main GTFS stops file from GitHub\n",
        "stops_df = read_text_csv(\n",
        "    \"https://github.com/hawa1983/Capstone/blob/main/stops.txt\"\n",
        ")\n",
        "\n",
        "# Load IBX stops file from raw GitHub URL\n",
        "ibx_df = read_text_csv(\n",
        "    \"https://raw.githubusercontent.com/hawa1983/Capstone/refs/heads/main/ibx%20stops%20coordinates.txt\"\n",
        ")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Normalize Data Types\n",
        "# ----------------------------\n",
        "\n",
        "# Ensure latitude, longitude, and location_type\n",
        "# are properly formatted in both datasets\n",
        "for df in (stops_df, ibx_df):\n",
        "\n",
        "    # Convert latitude and longitude to numeric values\n",
        "    # Invalid values are converted to NaN\n",
        "    df[\"stop_lat\"] = pd.to_numeric(df[\"stop_lat\"], errors=\"coerce\")\n",
        "    df[\"stop_lon\"] = pd.to_numeric(df[\"stop_lon\"], errors=\"coerce\")\n",
        "\n",
        "    # Ensure location_type exists and is an integer\n",
        "    if \"location_type\" in df.columns:\n",
        "        df[\"location_type\"] = (\n",
        "            pd.to_numeric(df[\"location_type\"], errors=\"coerce\")\n",
        "            .fillna(0)          # Replace missing values with 0\n",
        "            .astype(int)        # Convert to integer\n",
        "        )\n",
        "    else:\n",
        "        # If column is missing, create it with default value 0\n",
        "        df[\"location_type\"] = 0\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Merge Datasets\n",
        "# ----------------------------\n",
        "\n",
        "# Combine original stops and IBX stops into one DataFrame\n",
        "combined_stops = pd.concat([stops_df, ibx_df], ignore_index=True)\n",
        "\n",
        "# Remove duplicate stop_id entries\n",
        "# If duplicates exist, keep the last occurrence (IBX overrides original)\n",
        "combined_stops_df = (\n",
        "    combined_stops\n",
        "    .drop_duplicates(subset=[\"stop_id\"], keep=\"last\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Save Combined File\n",
        "# ----------------------------\n",
        "\n",
        "# Define output filename\n",
        "output_file = \"stops_with_ibx.csv\"\n",
        "\n",
        "# Write merged dataset to CSV without row index\n",
        "combined_stops_df.to_csv(output_file, index=False)\n",
        "\n",
        "# Confirm successful save\n",
        "print(f\"File saved as: {output_file}\")\n",
        "\n",
        "display(combined_stops_df.tail(19))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "ntoNNIh56DUO",
        "outputId": "be42fd07-b4a7-4dc4-c0ed-3da730f3b88c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved as: stops_with_ibx.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     stop_id               stop_name  stop_lat  stop_lon  location_type  \\\n",
              "1497   IBX_1        Roosevelt Avenue   40.7465  -73.8910              1   \n",
              "1498   IBX_2            Grand Avenue   40.7289  -73.8897              1   \n",
              "1499   IBX_3            Eliot Avenue   40.7255  -73.8792              1   \n",
              "1500   IBX_4     Metropolitan Avenue   40.7119  -73.8896              1   \n",
              "1501   IBX_5           Myrtle Avenue   40.6997  -73.9109              1   \n",
              "1502   IBX_6           Wilson Avenue   40.6871  -73.9030              1   \n",
              "1503   IBX_7         Atlantic Avenue   40.6835  -73.9083              1   \n",
              "1504   IBX_8           Sutter Avenue   40.6696  -73.9022              1   \n",
              "1505   IBX_9          Livonia Avenue   40.6644  -73.9002              1   \n",
              "1506  IBX_10             Linden Blvd   40.6555  -73.9060              1   \n",
              "1507  IBX_11           Remsen Avenue   40.6510  -73.9160              1   \n",
              "1508  IBX_12            Utica Avenue   40.6459  -73.9319              1   \n",
              "1509  IBX_13       Flatbush–Nostrand   40.6328  -73.9470              1   \n",
              "1510  IBX_14          East 16 Street   40.6298  -73.9607              1   \n",
              "1511  IBX_15         McDonald Avenue   40.6255  -73.9777              1   \n",
              "1512  IBX_16      New Utrecht Avenue   40.6209  -73.9903              1   \n",
              "1513  IBX_17                8 Avenue   40.6372  -74.0017              1   \n",
              "1514  IBX_18                4 Avenue   40.6452  -74.0113              1   \n",
              "1515  IBX_19  Brooklyn Army Terminal   40.6458  -74.0320              1   \n",
              "\n",
              "     parent_station  \n",
              "1497            NaN  \n",
              "1498            NaN  \n",
              "1499            NaN  \n",
              "1500            NaN  \n",
              "1501            NaN  \n",
              "1502            NaN  \n",
              "1503            NaN  \n",
              "1504            NaN  \n",
              "1505            NaN  \n",
              "1506            NaN  \n",
              "1507            NaN  \n",
              "1508            NaN  \n",
              "1509            NaN  \n",
              "1510            NaN  \n",
              "1511            NaN  \n",
              "1512            NaN  \n",
              "1513            NaN  \n",
              "1514            NaN  \n",
              "1515            NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec05b88e-9581-4b65-9a55-053d1eae60e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>stop_lat</th>\n",
              "      <th>stop_lon</th>\n",
              "      <th>location_type</th>\n",
              "      <th>parent_station</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>IBX_1</td>\n",
              "      <td>Roosevelt Avenue</td>\n",
              "      <td>40.7465</td>\n",
              "      <td>-73.8910</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>IBX_2</td>\n",
              "      <td>Grand Avenue</td>\n",
              "      <td>40.7289</td>\n",
              "      <td>-73.8897</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>IBX_3</td>\n",
              "      <td>Eliot Avenue</td>\n",
              "      <td>40.7255</td>\n",
              "      <td>-73.8792</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>IBX_4</td>\n",
              "      <td>Metropolitan Avenue</td>\n",
              "      <td>40.7119</td>\n",
              "      <td>-73.8896</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1501</th>\n",
              "      <td>IBX_5</td>\n",
              "      <td>Myrtle Avenue</td>\n",
              "      <td>40.6997</td>\n",
              "      <td>-73.9109</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1502</th>\n",
              "      <td>IBX_6</td>\n",
              "      <td>Wilson Avenue</td>\n",
              "      <td>40.6871</td>\n",
              "      <td>-73.9030</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503</th>\n",
              "      <td>IBX_7</td>\n",
              "      <td>Atlantic Avenue</td>\n",
              "      <td>40.6835</td>\n",
              "      <td>-73.9083</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1504</th>\n",
              "      <td>IBX_8</td>\n",
              "      <td>Sutter Avenue</td>\n",
              "      <td>40.6696</td>\n",
              "      <td>-73.9022</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1505</th>\n",
              "      <td>IBX_9</td>\n",
              "      <td>Livonia Avenue</td>\n",
              "      <td>40.6644</td>\n",
              "      <td>-73.9002</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1506</th>\n",
              "      <td>IBX_10</td>\n",
              "      <td>Linden Blvd</td>\n",
              "      <td>40.6555</td>\n",
              "      <td>-73.9060</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1507</th>\n",
              "      <td>IBX_11</td>\n",
              "      <td>Remsen Avenue</td>\n",
              "      <td>40.6510</td>\n",
              "      <td>-73.9160</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1508</th>\n",
              "      <td>IBX_12</td>\n",
              "      <td>Utica Avenue</td>\n",
              "      <td>40.6459</td>\n",
              "      <td>-73.9319</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1509</th>\n",
              "      <td>IBX_13</td>\n",
              "      <td>Flatbush–Nostrand</td>\n",
              "      <td>40.6328</td>\n",
              "      <td>-73.9470</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1510</th>\n",
              "      <td>IBX_14</td>\n",
              "      <td>East 16 Street</td>\n",
              "      <td>40.6298</td>\n",
              "      <td>-73.9607</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>IBX_15</td>\n",
              "      <td>McDonald Avenue</td>\n",
              "      <td>40.6255</td>\n",
              "      <td>-73.9777</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>IBX_16</td>\n",
              "      <td>New Utrecht Avenue</td>\n",
              "      <td>40.6209</td>\n",
              "      <td>-73.9903</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>IBX_17</td>\n",
              "      <td>8 Avenue</td>\n",
              "      <td>40.6372</td>\n",
              "      <td>-74.0017</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>IBX_18</td>\n",
              "      <td>4 Avenue</td>\n",
              "      <td>40.6452</td>\n",
              "      <td>-74.0113</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>40.6458</td>\n",
              "      <td>-74.0320</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec05b88e-9581-4b65-9a55-053d1eae60e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec05b88e-9581-4b65-9a55-053d1eae60e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec05b88e-9581-4b65-9a55-053d1eae60e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"stops_df:\", len(stops_df))\n",
        "print(\"ibx_df:\", len(ibx_df))\n",
        "print(\"combined_stops_df:\", len(combined_stops_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JIw4pKJVxes",
        "outputId": "ad894ad9-d74b-4a4b-8bfe-dae5af90152e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stops_df: 1497\n",
            "ibx_df: 19\n",
            "combined_stops_df: 1516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_stops_df[combined_stops_df[\"stop_name\"].astype(str).str.contains(\"Woodside|Bay Ridge|Jackson Heights|Atlantic\", case=False, na=False)].tail(30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "z8VkLsNyV2Dp",
        "outputId": "0bc0ee3b-17a5-44b7-8cfb-19868cf04cfc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     stop_id                 stop_name   stop_lat   stop_lon  location_type  \\\n",
              "210      235  Atlantic Av-Barclays Ctr  40.684359 -73.977666              1   \n",
              "211     235N  Atlantic Av-Barclays Ctr  40.684359 -73.977666              0   \n",
              "212     235S  Atlantic Av-Barclays Ctr  40.684359 -73.977666              0   \n",
              "492      712            61 St-Woodside  40.745630 -73.902984              1   \n",
              "493     712N            61 St-Woodside  40.745630 -73.902984              0   \n",
              "494     712S            61 St-Woodside  40.745630 -73.902984              0   \n",
              "804      D24  Atlantic Av-Barclays Ctr  40.684460 -73.976890              1   \n",
              "805     D24N  Atlantic Av-Barclays Ctr  40.684460 -73.976890              0   \n",
              "806     D24S  Atlantic Av-Barclays Ctr  40.684460 -73.976890              0   \n",
              "1194     L24               Atlantic Av  40.675345 -73.903097              1   \n",
              "1195    L24N               Atlantic Av  40.675345 -73.903097              0   \n",
              "1196    L24S               Atlantic Av  40.675345 -73.903097              0   \n",
              "1386     R31  Atlantic Av-Barclays Ctr  40.683666 -73.978810              1   \n",
              "1387    R31N  Atlantic Av-Barclays Ctr  40.683666 -73.978810              0   \n",
              "1388    R31S  Atlantic Av-Barclays Ctr  40.683666 -73.978810              0   \n",
              "1413     R42              Bay Ridge Av  40.634967 -74.023377              1   \n",
              "1414    R42N              Bay Ridge Av  40.634967 -74.023377              0   \n",
              "1415    R42S              Bay Ridge Av  40.634967 -74.023377              0   \n",
              "1422     R45           Bay Ridge-95 St  40.616622 -74.030876              1   \n",
              "1423    R45N           Bay Ridge-95 St  40.616622 -74.030876              0   \n",
              "1424    R45S           Bay Ridge-95 St  40.616622 -74.030876              0   \n",
              "1503   IBX_7           Atlantic Avenue  40.683500 -73.908300              1   \n",
              "\n",
              "     parent_station  \n",
              "210             NaN  \n",
              "211             235  \n",
              "212             235  \n",
              "492             NaN  \n",
              "493             712  \n",
              "494             712  \n",
              "804             NaN  \n",
              "805             D24  \n",
              "806             D24  \n",
              "1194            NaN  \n",
              "1195            L24  \n",
              "1196            L24  \n",
              "1386            NaN  \n",
              "1387            R31  \n",
              "1388            R31  \n",
              "1413            NaN  \n",
              "1414            R42  \n",
              "1415            R42  \n",
              "1422            NaN  \n",
              "1423            R45  \n",
              "1424            R45  \n",
              "1503            NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cd0095c-e4c6-4f74-b13e-f56bc50b023c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>stop_lat</th>\n",
              "      <th>stop_lon</th>\n",
              "      <th>location_type</th>\n",
              "      <th>parent_station</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>235</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>40.684359</td>\n",
              "      <td>-73.977666</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>235N</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>40.684359</td>\n",
              "      <td>-73.977666</td>\n",
              "      <td>0</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>235S</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>40.684359</td>\n",
              "      <td>-73.977666</td>\n",
              "      <td>0</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>712</td>\n",
              "      <td>61 St-Woodside</td>\n",
              "      <td>40.745630</td>\n",
              "      <td>-73.902984</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>712N</td>\n",
              "      <td>61 St-Woodside</td>\n",
              "      <td>40.745630</td>\n",
              "      <td>-73.902984</td>\n",
              "      <td>0</td>\n",
              "      <td>712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>712S</td>\n",
              "      <td>61 St-Woodside</td>\n",
              "      <td>40.745630</td>\n",
              "      <td>-73.902984</td>\n",
              "      <td>0</td>\n",
              "      <td>712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>D24</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>40.684460</td>\n",
              "      <td>-73.976890</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>D24N</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>40.684460</td>\n",
              "      <td>-73.976890</td>\n",
              "      <td>0</td>\n",
              "      <td>D24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>D24S</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>40.684460</td>\n",
              "      <td>-73.976890</td>\n",
              "      <td>0</td>\n",
              "      <td>D24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194</th>\n",
              "      <td>L24</td>\n",
              "      <td>Atlantic Av</td>\n",
              "      <td>40.675345</td>\n",
              "      <td>-73.903097</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>L24N</td>\n",
              "      <td>Atlantic Av</td>\n",
              "      <td>40.675345</td>\n",
              "      <td>-73.903097</td>\n",
              "      <td>0</td>\n",
              "      <td>L24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>L24S</td>\n",
              "      <td>Atlantic Av</td>\n",
              "      <td>40.675345</td>\n",
              "      <td>-73.903097</td>\n",
              "      <td>0</td>\n",
              "      <td>L24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1386</th>\n",
              "      <td>R31</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>40.683666</td>\n",
              "      <td>-73.978810</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>R31N</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>40.683666</td>\n",
              "      <td>-73.978810</td>\n",
              "      <td>0</td>\n",
              "      <td>R31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1388</th>\n",
              "      <td>R31S</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>40.683666</td>\n",
              "      <td>-73.978810</td>\n",
              "      <td>0</td>\n",
              "      <td>R31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1413</th>\n",
              "      <td>R42</td>\n",
              "      <td>Bay Ridge Av</td>\n",
              "      <td>40.634967</td>\n",
              "      <td>-74.023377</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1414</th>\n",
              "      <td>R42N</td>\n",
              "      <td>Bay Ridge Av</td>\n",
              "      <td>40.634967</td>\n",
              "      <td>-74.023377</td>\n",
              "      <td>0</td>\n",
              "      <td>R42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1415</th>\n",
              "      <td>R42S</td>\n",
              "      <td>Bay Ridge Av</td>\n",
              "      <td>40.634967</td>\n",
              "      <td>-74.023377</td>\n",
              "      <td>0</td>\n",
              "      <td>R42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422</th>\n",
              "      <td>R45</td>\n",
              "      <td>Bay Ridge-95 St</td>\n",
              "      <td>40.616622</td>\n",
              "      <td>-74.030876</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1423</th>\n",
              "      <td>R45N</td>\n",
              "      <td>Bay Ridge-95 St</td>\n",
              "      <td>40.616622</td>\n",
              "      <td>-74.030876</td>\n",
              "      <td>0</td>\n",
              "      <td>R45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>R45S</td>\n",
              "      <td>Bay Ridge-95 St</td>\n",
              "      <td>40.616622</td>\n",
              "      <td>-74.030876</td>\n",
              "      <td>0</td>\n",
              "      <td>R45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503</th>\n",
              "      <td>IBX_7</td>\n",
              "      <td>Atlantic Avenue</td>\n",
              "      <td>40.683500</td>\n",
              "      <td>-73.908300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cd0095c-e4c6-4f74-b13e-f56bc50b023c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1cd0095c-e4c6-4f74-b13e-f56bc50b023c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1cd0095c-e4c6-4f74-b13e-f56bc50b023c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"combined_stops_df[combined_stops_df[\\\"stop_name\\\"]\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"235\",\n          \"R31N\",\n          \"D24S\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Atlantic Av-Barclays Ctr\",\n          \"61 St-Woodside\",\n          \"Atlantic Avenue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03831165503438841,\n        \"min\": 40.616622,\n        \"max\": 40.74563,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          40.74563,\n          40.634967,\n          40.684359\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0491879383095368,\n        \"min\": -74.030876,\n        \"max\": -73.902984,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -73.902984,\n          -74.023377,\n          -73.977666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_station\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"235\",\n          \"712\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ibx_bad = ibx_df[ibx_df[\"stop_lat\"].isna() | ibx_df[\"stop_lon\"].isna()]\n",
        "print(\"IBX rows with missing coords:\", len(ibx_bad))\n",
        "ibx_bad.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "CUcMq4ZTV5Ph",
        "outputId": "6e1fa2be-0abd-41d4-d74b-f943aef302a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IBX rows with missing coords: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [stop_id, stop_name, stop_lat, stop_lon, location_type]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa117678-304b-4462-8311-f8e21a8fcd92\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>stop_lat</th>\n",
              "      <th>stop_lon</th>\n",
              "      <th>location_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa117678-304b-4462-8311-f8e21a8fcd92')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa117678-304b-4462-8311-f8e21a8fcd92 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa117678-304b-4462-8311-f8e21a8fcd92');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ibx_bad",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering GTFS Stations from the Combined Stops Dataset\n",
        "\n",
        "This code extracts only **station-level stops** from the merged GTFS dataset. In GTFS, the `location_type` field is used to classify different types of stops. A value of `1` represents a **station**, while other values (such as `0`) typically represent individual boarding stops or platforms.\n",
        "\n",
        "First, the code retrieves the `location_type` column from the `combined_stops` DataFrame. If the column does not exist, it defaults to `0`, which prevents the code from failing due to a missing field. It then converts the values in this column to numeric form, coercing any invalid entries into missing values. Those missing values are replaced with `0`, and the column is cast to integers. This ensures that the filtering step works reliably and that all values follow GTFS enumeration rules.\n",
        "\n",
        "Next, the code creates a new DataFrame called `stations_df` by selecting only the rows where `location_type` equals `1`. This isolates records that represent stations rather than platforms or other stop types. The `.copy()` method is used to create a separate DataFrame, avoiding potential warnings or unintended modifications to the original dataset.\n",
        "\n",
        "Finally, the `display()` function shows the filtered station-level records. In summary, this code segment cleans and standardizes the `location_type` field, then filters the dataset to include only GTFS-defined stations.\n"
      ],
      "metadata": {
        "id": "htcD7Svu6yCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GTFS uses the \"location_type\" field to classify stop types.\n",
        "# According to GTFS enumerations:\n",
        "#   0 = Stop/Platform (default)\n",
        "#   1 = Station\n",
        "#   2 = Entrance/Exit\n",
        "#   3 = Generic Node\n",
        "#   4 = Boarding Area\n",
        "# Here, we want to isolate only stations (location_type == 1).\n",
        "\n",
        "# Safely retrieve the \"location_type\" column from the combined dataset.\n",
        "# If the column does not exist, default to 0 (treat all rows as regular stops).\n",
        "loc = combined_stops_df.get(\"location_type\", 0)\n",
        "\n",
        "# Convert the location_type values to numeric:\n",
        "# - errors=\"coerce\" converts invalid or non-numeric values to NaN\n",
        "# - fillna(0) replaces missing values with 0 (default stop/platform)\n",
        "# - astype(int) ensures values are stored as integers for reliable comparison\n",
        "loc = pd.to_numeric(loc, errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# Filter the dataset to include only rows where location_type == 1 (stations).\n",
        "# loc.eq(1) creates a Boolean mask selecting only station rows.\n",
        "# .copy() creates a separate DataFrame to avoid modifying the original data.\n",
        "stations_df = combined_stops_df.loc[loc.eq(1)].copy()\n",
        "\n",
        "# Display the filtered station-level stops.\n",
        "# This allows you to inspect only GTFS-defined stations.\n",
        "display(stations_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8U8l1ildzqv0",
        "outputId": "bacf01c7-7e52-4eee-dbbb-7a3550d4fa76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     stop_id                  stop_name   stop_lat   stop_lon  location_type  \\\n",
              "0        101  Van Cortlandt Park-242 St  40.889248 -73.898583              1   \n",
              "3        103                     238 St  40.884667 -73.900870              1   \n",
              "6        104                     231 St  40.878856 -73.904834              1   \n",
              "9        106         Marble Hill-225 St  40.874561 -73.909831              1   \n",
              "12       107                     215 St  40.869444 -73.915279              1   \n",
              "...      ...                        ...        ...        ...            ...   \n",
              "1511  IBX_15            McDonald Avenue  40.625500 -73.977700              1   \n",
              "1512  IBX_16         New Utrecht Avenue  40.620900 -73.990300              1   \n",
              "1513  IBX_17                   8 Avenue  40.637200 -74.001700              1   \n",
              "1514  IBX_18                   4 Avenue  40.645200 -74.011300              1   \n",
              "1515  IBX_19     Brooklyn Army Terminal  40.645800 -74.032000              1   \n",
              "\n",
              "     parent_station  \n",
              "0               NaN  \n",
              "3               NaN  \n",
              "6               NaN  \n",
              "9               NaN  \n",
              "12              NaN  \n",
              "...             ...  \n",
              "1511            NaN  \n",
              "1512            NaN  \n",
              "1513            NaN  \n",
              "1514            NaN  \n",
              "1515            NaN  \n",
              "\n",
              "[518 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40dd433e-dea8-4607-b1fa-2a2acca4cdf1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>stop_lat</th>\n",
              "      <th>stop_lon</th>\n",
              "      <th>location_type</th>\n",
              "      <th>parent_station</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>40.889248</td>\n",
              "      <td>-73.898583</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>40.884667</td>\n",
              "      <td>-73.900870</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>40.878856</td>\n",
              "      <td>-73.904834</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>40.874561</td>\n",
              "      <td>-73.909831</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>40.869444</td>\n",
              "      <td>-73.915279</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>IBX_15</td>\n",
              "      <td>McDonald Avenue</td>\n",
              "      <td>40.625500</td>\n",
              "      <td>-73.977700</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>IBX_16</td>\n",
              "      <td>New Utrecht Avenue</td>\n",
              "      <td>40.620900</td>\n",
              "      <td>-73.990300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>IBX_17</td>\n",
              "      <td>8 Avenue</td>\n",
              "      <td>40.637200</td>\n",
              "      <td>-74.001700</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>IBX_18</td>\n",
              "      <td>4 Avenue</td>\n",
              "      <td>40.645200</td>\n",
              "      <td>-74.011300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>40.645800</td>\n",
              "      <td>-74.032000</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>518 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40dd433e-dea8-4607-b1fa-2a2acca4cdf1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-40dd433e-dea8-4607-b1fa-2a2acca4cdf1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-40dd433e-dea8-4607-b1fa-2a2acca4cdf1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_dbee01c3-9562-4959-a057-bb730a4e5484\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('stations_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dbee01c3-9562-4959-a057-bb730a4e5484 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('stations_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stations_df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This matches the GTFS reference semantics: station rows are `location_type = 1`, while platforms/stops are `0` or empty. citeturn7view0turn1view1\n",
        "\n",
        "### Validating latitude/longitude columns before geometry construction"
      ],
      "metadata": {
        "id": "3tSuIfFZz6Cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validating and Cleaning GTFS Stop Coordinates\n",
        "\n",
        "This code validates that the stop dataset contains proper geographic coordinate fields and removes any records with invalid latitude or longitude values.\n",
        "\n",
        "First, it defines a set of required columns: `stop_lat` and `stop_lon`. These fields are mandatory in GTFS because they store the geographic coordinates of each stop. The code then checks whether these required columns are actually present in the `stops_df` DataFrame. If either column is missing, it raises a `ValueError` and stops execution. This prevents downstream errors and ensures the dataset meets minimum GTFS structural requirements.\n",
        "\n",
        "Next, the code converts both the latitude and longitude columns to numeric values. If any values are non-numeric (for example, text or malformed entries), they are coerced into missing values (`NaN`). This step ensures the coordinate fields are stored in a numeric format suitable for geographic validation and mapping.\n",
        "\n",
        "After conversion, the code applies geographic boundary checks. Valid latitude values must fall between -90 and 90 degrees, and valid longitude values must fall between -180 and 180 degrees. These are the universal bounds for real-world geographic coordinates. The `between()` function creates a logical mask that identifies rows where both latitude and longitude fall within valid ranges.\n",
        "\n",
        "Finally, the dataset is filtered to keep only rows with valid coordinates. Any stops with missing, malformed, or out-of-range coordinates are removed. The `.copy()` method ensures that the filtered result is stored as a clean, independent DataFrame.\n",
        "\n",
        "In summary, this code performs structural validation and geographic quality control on the GTFS stop data, ensuring that all remaining stops contain valid numeric latitude and longitude values within real-world bounds.\n"
      ],
      "metadata": {
        "id": "OqIli0Ps7Vp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# Validate Required Coordinate Columns\n",
        "# --------------------------------------------\n",
        "\n",
        "# Define the set of required coordinate columns.\n",
        "# GTFS requires stop_lat (latitude) and stop_lon (longitude)\n",
        "# to properly define the geographic location of each stop.\n",
        "required = {\"stop_lat\", \"stop_lon\"}\n",
        "\n",
        "# Determine whether any required columns are missing\n",
        "# by subtracting the existing columns from the required set.\n",
        "missing = required - set(combined_stops_df.columns)\n",
        "\n",
        "# If any required columns are missing, raise an error\n",
        "# to stop execution and prevent downstream failures.\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing required columns: {missing}\")\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# Convert Coordinates to Numeric\n",
        "# --------------------------------------------\n",
        "\n",
        "# GTFS defines stop_lat and stop_lon as numeric latitude\n",
        "# and longitude values (in decimal degrees).\n",
        "# Convert both columns to numeric types:\n",
        "# - errors=\"coerce\" converts invalid values to NaN\n",
        "combined_stops_df[\"stop_lat\"] = pd.to_numeric(combined_stops_df[\"stop_lat\"], errors=\"coerce\")\n",
        "combined_stops_df[\"stop_lon\"] = pd.to_numeric(combined_stops_df[\"stop_lon\"], errors=\"coerce\")\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# Validate Geographic Bounds\n",
        "# --------------------------------------------\n",
        "\n",
        "# Latitude must be between -90 and 90 degrees.\n",
        "# Longitude must be between -180 and 180 degrees.\n",
        "# The .between() method returns True for valid values\n",
        "# and False for values outside these bounds (or NaN).\n",
        "\n",
        "valid = (\n",
        "    combined_stops_df[\"stop_lat\"].between(-90, 90)\n",
        "    & combined_stops_df[\"stop_lon\"].between(-180, 180)\n",
        ")\n",
        "\n",
        "# --------------------------------------------\n",
        "# Filter Out Invalid Rows\n",
        "# --------------------------------------------\n",
        "\n",
        "# Keep only rows where both latitude and longitude are valid.\n",
        "# Rows with:\n",
        "#   - Missing coordinates (NaN)\n",
        "#   - Non-numeric values (converted to NaN)\n",
        "#   - Out-of-range geographic values\n",
        "# are removed.\n",
        "#\n",
        "# .copy() ensures we create a clean DataFrame\n",
        "# and avoid modifying a view of the original.\n",
        "combined_stops_df = combined_stops_df.loc[valid].copy()\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# Display Cleaned Dataset\n",
        "# --------------------------------------------\n",
        "\n",
        "# Show the validated stops dataset.\n",
        "# At this point, all rows have:\n",
        "#   - Required coordinate columns\n",
        "#   - Numeric latitude and longitude values\n",
        "#   - Coordinates within real-world geographic bounds\n",
        "display(combined_stops_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vQQvwU3mz_Mw",
        "outputId": "8dc58b95-4ab4-44f4-fe97-1f67465b87e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     stop_id                  stop_name   stop_lat   stop_lon  location_type  \\\n",
              "0        101  Van Cortlandt Park-242 St  40.889248 -73.898583              1   \n",
              "1       101N  Van Cortlandt Park-242 St  40.889248 -73.898583              0   \n",
              "2       101S  Van Cortlandt Park-242 St  40.889248 -73.898583              0   \n",
              "3        103                     238 St  40.884667 -73.900870              1   \n",
              "4       103N                     238 St  40.884667 -73.900870              0   \n",
              "...      ...                        ...        ...        ...            ...   \n",
              "1511  IBX_15            McDonald Avenue  40.625500 -73.977700              1   \n",
              "1512  IBX_16         New Utrecht Avenue  40.620900 -73.990300              1   \n",
              "1513  IBX_17                   8 Avenue  40.637200 -74.001700              1   \n",
              "1514  IBX_18                   4 Avenue  40.645200 -74.011300              1   \n",
              "1515  IBX_19     Brooklyn Army Terminal  40.645800 -74.032000              1   \n",
              "\n",
              "     parent_station  \n",
              "0               NaN  \n",
              "1               101  \n",
              "2               101  \n",
              "3               NaN  \n",
              "4               103  \n",
              "...             ...  \n",
              "1511            NaN  \n",
              "1512            NaN  \n",
              "1513            NaN  \n",
              "1514            NaN  \n",
              "1515            NaN  \n",
              "\n",
              "[1516 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3597ca29-9d93-4386-b091-9d3dbc2a4ca1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>stop_lat</th>\n",
              "      <th>stop_lon</th>\n",
              "      <th>location_type</th>\n",
              "      <th>parent_station</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>40.889248</td>\n",
              "      <td>-73.898583</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101N</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>40.889248</td>\n",
              "      <td>-73.898583</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101S</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>40.889248</td>\n",
              "      <td>-73.898583</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>40.884667</td>\n",
              "      <td>-73.900870</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>103N</td>\n",
              "      <td>238 St</td>\n",
              "      <td>40.884667</td>\n",
              "      <td>-73.900870</td>\n",
              "      <td>0</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>IBX_15</td>\n",
              "      <td>McDonald Avenue</td>\n",
              "      <td>40.625500</td>\n",
              "      <td>-73.977700</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>IBX_16</td>\n",
              "      <td>New Utrecht Avenue</td>\n",
              "      <td>40.620900</td>\n",
              "      <td>-73.990300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>IBX_17</td>\n",
              "      <td>8 Avenue</td>\n",
              "      <td>40.637200</td>\n",
              "      <td>-74.001700</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>IBX_18</td>\n",
              "      <td>4 Avenue</td>\n",
              "      <td>40.645200</td>\n",
              "      <td>-74.011300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>40.645800</td>\n",
              "      <td>-74.032000</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1516 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3597ca29-9d93-4386-b091-9d3dbc2a4ca1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3597ca29-9d93-4386-b091-9d3dbc2a4ca1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3597ca29-9d93-4386-b091-9d3dbc2a4ca1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_8aade01e-84ac-4d63-9a73-3079b463b356\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('combined_stops_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8aade01e-84ac-4d63-9a73-3079b463b356 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('combined_stops_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_stops_df",
              "summary": "{\n  \"name\": \"combined_stops_df\",\n  \"rows\": 1516,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1516,\n        \"samples\": [\n          \"120\",\n          \"220\",\n          \"S22S\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 399,\n        \"samples\": [\n          \"Bay Pkwy\",\n          \"Whitehall St-South Ferry\",\n          \"Franklin St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08236298740253709,\n        \"min\": 40.512764,\n        \"max\": 40.903125,\n        \"num_unique_values\": 514,\n        \"samples\": [\n          40.666271,\n          40.7255,\n          40.764811\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0696454624188553,\n        \"min\": -74.251961,\n        \"max\": -73.755405,\n        \"num_unique_values\": 514,\n        \"samples\": [\n          -73.980305,\n          -73.8792,\n          -73.973347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_station\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 499,\n        \"samples\": [\n          \"R29\",\n          \"238\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GTFS also allows `stop_lat/stop_lon` to be optional for some `location_type` values; robust code should allow nulls for those rows if I keep them. citeturn7view0\n",
        "\n",
        "### Creating a GeoDataFrame from `stop_lon/stop_lat`\n"
      ],
      "metadata": {
        "id": "-i-27Jo40N4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "# --------------------------------------------\n",
        "# Create Station Subset FROM the cleaned dataset\n",
        "# --------------------------------------------\n",
        "\n",
        "# GTFS defines location_type = 1 as a station.\n",
        "# Use the already cleaned combined_stops_df to ensure\n",
        "# coordinates are valid before creating geometry.\n",
        "loc = combined_stops_df.get(\"location_type\", 0)\n",
        "loc = pd.to_numeric(loc, errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# Filter only station-level records (location_type == 1)\n",
        "stations_df = combined_stops_df.loc[loc.eq(1)].copy()\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# Convert to GeoDataFrame\n",
        "# --------------------------------------------\n",
        "\n",
        "# GeoPandas points_from_xy expects:\n",
        "#   x = longitude\n",
        "#   y = latitude\n",
        "# CRS \"EPSG:4326\" corresponds to standard WGS84 lat/lon.\n",
        "stations_gdf = gpd.GeoDataFrame(\n",
        "    stations_df,\n",
        "    geometry=gpd.points_from_xy(\n",
        "        stations_df[\"stop_lon\"],\n",
        "        stations_df[\"stop_lat\"],\n",
        "        crs=\"EPSG:4326\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Display the spatial station dataset\n",
        "display(stations_gdf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FkIDUvkk-aHU",
        "outputId": "58999926-b4fb-4ad1-f7c7-ed45347f1410"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     stop_id                  stop_name   stop_lat   stop_lon  location_type  \\\n",
              "0        101  Van Cortlandt Park-242 St  40.889248 -73.898583              1   \n",
              "3        103                     238 St  40.884667 -73.900870              1   \n",
              "6        104                     231 St  40.878856 -73.904834              1   \n",
              "9        106         Marble Hill-225 St  40.874561 -73.909831              1   \n",
              "12       107                     215 St  40.869444 -73.915279              1   \n",
              "...      ...                        ...        ...        ...            ...   \n",
              "1511  IBX_15            McDonald Avenue  40.625500 -73.977700              1   \n",
              "1512  IBX_16         New Utrecht Avenue  40.620900 -73.990300              1   \n",
              "1513  IBX_17                   8 Avenue  40.637200 -74.001700              1   \n",
              "1514  IBX_18                   4 Avenue  40.645200 -74.011300              1   \n",
              "1515  IBX_19     Brooklyn Army Terminal  40.645800 -74.032000              1   \n",
              "\n",
              "     parent_station                    geometry  \n",
              "0               NaN  POINT (-73.89858 40.88925)  \n",
              "3               NaN  POINT (-73.90087 40.88467)  \n",
              "6               NaN  POINT (-73.90483 40.87886)  \n",
              "9               NaN  POINT (-73.90983 40.87456)  \n",
              "12              NaN  POINT (-73.91528 40.86944)  \n",
              "...             ...                         ...  \n",
              "1511            NaN    POINT (-73.9777 40.6255)  \n",
              "1512            NaN    POINT (-73.9903 40.6209)  \n",
              "1513            NaN    POINT (-74.0017 40.6372)  \n",
              "1514            NaN    POINT (-74.0113 40.6452)  \n",
              "1515            NaN     POINT (-74.032 40.6458)  \n",
              "\n",
              "[518 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2996057-9185-488b-8214-c43eeb4980c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>stop_lat</th>\n",
              "      <th>stop_lon</th>\n",
              "      <th>location_type</th>\n",
              "      <th>parent_station</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>40.889248</td>\n",
              "      <td>-73.898583</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-73.89858 40.88925)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>40.884667</td>\n",
              "      <td>-73.900870</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-73.90087 40.88467)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>40.878856</td>\n",
              "      <td>-73.904834</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-73.90483 40.87886)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>40.874561</td>\n",
              "      <td>-73.909831</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-73.90983 40.87456)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>40.869444</td>\n",
              "      <td>-73.915279</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-73.91528 40.86944)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>IBX_15</td>\n",
              "      <td>McDonald Avenue</td>\n",
              "      <td>40.625500</td>\n",
              "      <td>-73.977700</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-73.9777 40.6255)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>IBX_16</td>\n",
              "      <td>New Utrecht Avenue</td>\n",
              "      <td>40.620900</td>\n",
              "      <td>-73.990300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-73.9903 40.6209)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>IBX_17</td>\n",
              "      <td>8 Avenue</td>\n",
              "      <td>40.637200</td>\n",
              "      <td>-74.001700</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-74.0017 40.6372)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>IBX_18</td>\n",
              "      <td>4 Avenue</td>\n",
              "      <td>40.645200</td>\n",
              "      <td>-74.011300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-74.0113 40.6452)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>40.645800</td>\n",
              "      <td>-74.032000</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (-74.032 40.6458)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>518 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2996057-9185-488b-8214-c43eeb4980c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2996057-9185-488b-8214-c43eeb4980c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2996057-9185-488b-8214-c43eeb4980c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_a92e3d21-06e5-4f5d-a4ac-a6c65c7c1ec6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('stations_gdf')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a92e3d21-06e5-4f5d-a4ac-a6c65c7c1ec6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('stations_gdf');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stations_gdf",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reprojecting Station Data to a Local Coordinate System\n",
        "\n",
        "This code is transforming the station GeoDataFrame from one coordinate reference system (CRS) to another.\n",
        "\n",
        "Your `stations_gdf` was originally created using **EPSG:4326**, which is the standard WGS84 geographic coordinate system. In this system, locations are stored as latitude and longitude in decimal degrees. While this format is ideal for web maps and GPS, it is not well suited for measuring distances or areas because degrees are not consistent linear units.\n",
        "\n",
        "The `.to_crs(\"EPSG:2263\")` step converts the dataset into a projected coordinate system. EPSG:2263 is the New York State Plane coordinate system (Long Island zone), and its units are in feet. Projected systems use linear units like feet or meters, which makes them appropriate for spatial analysis tasks such as calculating distances between stations, buffering, clustering, or performing spatial joins.\n",
        "\n",
        "Importantly, `.to_crs()` does not just relabel the data—it mathematically transforms the coordinate values into the new projection. That transformation requires that the original GeoDataFrame already has a defined CRS (which yours does: EPSG:4326).\n",
        "\n",
        "The resulting `stations_proj` GeoDataFrame contains the same station records, but the geometry coordinates are now expressed in feet rather than degrees. This makes the data more suitable for accurate distance calculations and local spatial analysis in the New York City area.\n"
      ],
      "metadata": {
        "id": "SmgVzHPN-w-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Reproject GeoDataFrame to a Different Coordinate System\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# The original stations_gdf is in EPSG:4326 (WGS84),\n",
        "# which stores coordinates as latitude/longitude in degrees.\n",
        "# While this CRS is ideal for web maps and GPS,\n",
        "# it is NOT ideal for measuring distances or areas because\n",
        "# degrees are not linear units.\n",
        "\n",
        "# The .to_crs() method transforms the geometry coordinates\n",
        "# from their current CRS into a new coordinate reference system.\n",
        "# IMPORTANT: The input GeoDataFrame must already have a defined CRS.\n",
        "\n",
        "# Here we convert to EPSG:2263.\n",
        "# EPSG:2263 = NAD83 / New York Long Island (State Plane)\n",
        "# Units are in feet, making it suitable for:\n",
        "#   - Distance calculations\n",
        "#   - Buffer analysis\n",
        "#   - Spatial clustering\n",
        "#   - Local NYC mapping and analysis\n",
        "\n",
        "stations_proj = stations_gdf.to_crs(\"EPSG:2263\")  # NYC State Plane (feet)\n",
        "\n",
        "# After transformation:\n",
        "# - Geometry coordinates are no longer latitude/longitude\n",
        "# - Coordinates are now projected X/Y values in feet\n",
        "# - Attribute data (columns) remain unchanged\n",
        "# - Only the geometry column is mathematically transformed\n",
        "\n",
        "# Display the projected GeoDataFrame\n",
        "# This allows inspection of the new projected coordinate values.\n",
        "display(stations_proj)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zAzM1-u---eN",
        "outputId": "a1f50a9f-d033-4acf-ad97-eb00e6ce07fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     stop_id                  stop_name   stop_lat   stop_lon  location_type  \\\n",
              "0        101  Van Cortlandt Park-242 St  40.889248 -73.898583              1   \n",
              "3        103                     238 St  40.884667 -73.900870              1   \n",
              "6        104                     231 St  40.878856 -73.904834              1   \n",
              "9        106         Marble Hill-225 St  40.874561 -73.909831              1   \n",
              "12       107                     215 St  40.869444 -73.915279              1   \n",
              "...      ...                        ...        ...        ...            ...   \n",
              "1511  IBX_15            McDonald Avenue  40.625500 -73.977700              1   \n",
              "1512  IBX_16         New Utrecht Avenue  40.620900 -73.990300              1   \n",
              "1513  IBX_17                   8 Avenue  40.637200 -74.001700              1   \n",
              "1514  IBX_18                   4 Avenue  40.645200 -74.011300              1   \n",
              "1515  IBX_19     Brooklyn Army Terminal  40.645800 -74.032000              1   \n",
              "\n",
              "     parent_station                        geometry  \n",
              "0               NaN  POINT (1012291.156 263271.208)  \n",
              "3               NaN  POINT (1011660.704 261601.442)  \n",
              "6               NaN  POINT (1010566.908 259483.047)  \n",
              "9               NaN  POINT (1009186.665 257916.747)  \n",
              "12              NaN  POINT (1007681.798 256050.919)  \n",
              "...             ...                             ...  \n",
              "1511            NaN   POINT (990440.272 167163.683)  \n",
              "1512            NaN   POINT (986942.815 165487.143)  \n",
              "1513            NaN   POINT (983778.179 171425.523)  \n",
              "1514            NaN   POINT (981114.151 174340.339)  \n",
              "1515            NaN     POINT (975369.8 174560.355)  \n",
              "\n",
              "[518 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd41fe92-f77a-496b-ad2d-6fb9a4ba865a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>stop_lat</th>\n",
              "      <th>stop_lon</th>\n",
              "      <th>location_type</th>\n",
              "      <th>parent_station</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>40.889248</td>\n",
              "      <td>-73.898583</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (1012291.156 263271.208)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>40.884667</td>\n",
              "      <td>-73.900870</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (1011660.704 261601.442)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>40.878856</td>\n",
              "      <td>-73.904834</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (1010566.908 259483.047)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>40.874561</td>\n",
              "      <td>-73.909831</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (1009186.665 257916.747)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>40.869444</td>\n",
              "      <td>-73.915279</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (1007681.798 256050.919)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>IBX_15</td>\n",
              "      <td>McDonald Avenue</td>\n",
              "      <td>40.625500</td>\n",
              "      <td>-73.977700</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (990440.272 167163.683)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>IBX_16</td>\n",
              "      <td>New Utrecht Avenue</td>\n",
              "      <td>40.620900</td>\n",
              "      <td>-73.990300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (986942.815 165487.143)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>IBX_17</td>\n",
              "      <td>8 Avenue</td>\n",
              "      <td>40.637200</td>\n",
              "      <td>-74.001700</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (983778.179 171425.523)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>IBX_18</td>\n",
              "      <td>4 Avenue</td>\n",
              "      <td>40.645200</td>\n",
              "      <td>-74.011300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (981114.151 174340.339)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>40.645800</td>\n",
              "      <td>-74.032000</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT (975369.8 174560.355)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>518 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd41fe92-f77a-496b-ad2d-6fb9a4ba865a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd41fe92-f77a-496b-ad2d-6fb9a4ba865a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd41fe92-f77a-496b-ad2d-6fb9a4ba865a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_1d99129d-8c95-4a6c-8bd5-5610f9206448\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('stations_proj')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d99129d-8c95-4a6c-8bd5-5610f9206448 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('stations_proj');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stations_proj",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Load 2020 TIGER/Line Block Groups for New York State\n",
        "# ---------------------------------------------------------\n",
        "# NY State FIPS = 36. TIGER/Line 2020 block groups for NY are available as a zipped shapefile.\n",
        "# GeoPandas can read zipped shapefiles directly from a URL.\n",
        "tiger_bg_ny_url = \"https://www2.census.gov/geo/tiger/TIGER2020/BG/tl_2020_36_bg.zip\"  # NY block groups (2020) :contentReference[oaicite:0]{index=0}\n",
        "\n",
        "bg_ny = gpd.read_file(tiger_bg_ny_url)\n",
        "\n",
        "# Quick validation: inspect columns and CRS\n",
        "print(\"Loaded rows:\", len(bg_ny))\n",
        "print(\"CRS:\", bg_ny.crs)\n",
        "print(\"Columns:\", list(bg_ny.columns))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) Filter to NYC (Five Borough Counties) using COUNTYFP\n",
        "# ---------------------------------------------------------\n",
        "# NYC counties (boroughs) by county FIPS:\n",
        "# 005 Bronx, 047 Kings (Brooklyn), 061 New York (Manhattan), 081 Queens, 085 Richmond (Staten Island)\n",
        "nyc_countyfps = {\"005\", \"047\", \"061\", \"081\", \"085\"}\n",
        "\n",
        "# TIGER 2020 block group fields commonly include:\n",
        "# STATEFP, COUNTYFP, TRACTCE, BLKGRPCE, and GEOID (often GEOID/ GEOID20 depending on vintage)\n",
        "# For TIGER2020 BG, fields are typically STATEFP and COUNTYFP (no '20' suffix), but we guard anyway.\n",
        "state_col = \"STATEFP\" if \"STATEFP\" in bg_ny.columns else \"STATEFP20\"\n",
        "county_col = \"COUNTYFP\" if \"COUNTYFP\" in bg_ny.columns else \"COUNTYFP20\"\n",
        "\n",
        "# Keep only New York State (36) and NYC counties\n",
        "bg_nyc = bg_ny.loc[\n",
        "    (bg_ny[state_col].astype(str) == \"36\") &\n",
        "    (bg_ny[county_col].astype(str).isin(nyc_countyfps))\n",
        "].copy()\n",
        "\n",
        "print(\"NYC block groups:\", len(bg_nyc))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) (Optional but recommended) Reproject to match stations\n",
        "# ---------------------------------------------------------\n",
        "# If you plan to buffer stations and do distance-based calculations,\n",
        "# you should work in a projected CRS (your stations_proj is EPSG:2263 in feet).\n",
        "# Reproject block groups to the SAME CRS for spatial joins/overlays.\n",
        "#\n",
        "# NOTE: stations_proj.crs should be EPSG:2263 if you followed your earlier step.\n",
        "bg_nyc_proj = bg_nyc.to_crs(stations_proj.crs)\n",
        "\n",
        "# Preview the NYC block group GeoDataFrames\n",
        "display(bg_nyc.head())\n",
        "display(bg_nyc_proj.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "gHD5i3MFDEAo",
        "outputId": "3f62f91a-9e00-45a7-ce41-5e7235369ac7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded rows: 16070\n",
            "CRS: EPSG:4269\n",
            "Columns: ['STATEFP', 'COUNTYFP', 'TRACTCE', 'BLKGRPCE', 'GEOID', 'NAMELSAD', 'MTFCC', 'FUNCSTAT', 'ALAND', 'AWATER', 'INTPTLAT', 'INTPTLON', 'geometry']\n",
            "NYC block groups: 6807\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   STATEFP COUNTYFP TRACTCE BLKGRPCE         GEOID       NAMELSAD  MTFCC  \\\n",
              "24      36      061  023900        1  360610239001  Block Group 1  G5030   \n",
              "25      36      061  013900        1  360610139001  Block Group 1  G5030   \n",
              "26      36      061  007800        2  360610078002  Block Group 2  G5030   \n",
              "27      36      061  008900        1  360610089001  Block Group 1  G5030   \n",
              "28      36      061  008900        4  360610089004  Block Group 4  G5030   \n",
              "\n",
              "   FUNCSTAT  ALAND  AWATER     INTPTLAT      INTPTLON  \\\n",
              "24        S  27517       0  +40.8322236  -073.9404112   \n",
              "25        S  23621       0  +40.7688543  -073.9868884   \n",
              "26        S  33890       0  +40.7471571  -073.9756186   \n",
              "27        S  20377       0  +40.7443158  -074.0010568   \n",
              "28        S  42006       0  +40.7458221  -074.0036736   \n",
              "\n",
              "                                             geometry  \n",
              "24  POLYGON ((-73.94112 40.83166, -73.94088 40.832...  \n",
              "25  POLYGON ((-73.98806 40.76979, -73.98666 40.769...  \n",
              "26  POLYGON ((-73.97673 40.74763, -73.97635 40.748...  \n",
              "27  POLYGON ((-74.00226 40.74521, -73.99942 40.744...  \n",
              "28  POLYGON ((-74.00511 40.7464, -74.00465 40.7470...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07cb11d6-7774-45be-8827-b6c10aad6f97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATEFP</th>\n",
              "      <th>COUNTYFP</th>\n",
              "      <th>TRACTCE</th>\n",
              "      <th>BLKGRPCE</th>\n",
              "      <th>GEOID</th>\n",
              "      <th>NAMELSAD</th>\n",
              "      <th>MTFCC</th>\n",
              "      <th>FUNCSTAT</th>\n",
              "      <th>ALAND</th>\n",
              "      <th>AWATER</th>\n",
              "      <th>INTPTLAT</th>\n",
              "      <th>INTPTLON</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>023900</td>\n",
              "      <td>1</td>\n",
              "      <td>360610239001</td>\n",
              "      <td>Block Group 1</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>27517</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.8322236</td>\n",
              "      <td>-073.9404112</td>\n",
              "      <td>POLYGON ((-73.94112 40.83166, -73.94088 40.832...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>013900</td>\n",
              "      <td>1</td>\n",
              "      <td>360610139001</td>\n",
              "      <td>Block Group 1</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>23621</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.7688543</td>\n",
              "      <td>-073.9868884</td>\n",
              "      <td>POLYGON ((-73.98806 40.76979, -73.98666 40.769...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>007800</td>\n",
              "      <td>2</td>\n",
              "      <td>360610078002</td>\n",
              "      <td>Block Group 2</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>33890</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.7471571</td>\n",
              "      <td>-073.9756186</td>\n",
              "      <td>POLYGON ((-73.97673 40.74763, -73.97635 40.748...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>008900</td>\n",
              "      <td>1</td>\n",
              "      <td>360610089001</td>\n",
              "      <td>Block Group 1</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>20377</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.7443158</td>\n",
              "      <td>-074.0010568</td>\n",
              "      <td>POLYGON ((-74.00226 40.74521, -73.99942 40.744...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>008900</td>\n",
              "      <td>4</td>\n",
              "      <td>360610089004</td>\n",
              "      <td>Block Group 4</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>42006</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.7458221</td>\n",
              "      <td>-074.0036736</td>\n",
              "      <td>POLYGON ((-74.00511 40.7464, -74.00465 40.7470...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07cb11d6-7774-45be-8827-b6c10aad6f97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07cb11d6-7774-45be-8827-b6c10aad6f97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07cb11d6-7774-45be-8827-b6c10aad6f97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   STATEFP COUNTYFP TRACTCE BLKGRPCE         GEOID       NAMELSAD  MTFCC  \\\n",
              "24      36      061  023900        1  360610239001  Block Group 1  G5030   \n",
              "25      36      061  013900        1  360610139001  Block Group 1  G5030   \n",
              "26      36      061  007800        2  360610078002  Block Group 2  G5030   \n",
              "27      36      061  008900        1  360610089001  Block Group 1  G5030   \n",
              "28      36      061  008900        4  360610089004  Block Group 4  G5030   \n",
              "\n",
              "   FUNCSTAT  ALAND  AWATER     INTPTLAT      INTPTLON  \\\n",
              "24        S  27517       0  +40.8322236  -073.9404112   \n",
              "25        S  23621       0  +40.7688543  -073.9868884   \n",
              "26        S  33890       0  +40.7471571  -073.9756186   \n",
              "27        S  20377       0  +40.7443158  -074.0010568   \n",
              "28        S  42006       0  +40.7458221  -074.0036736   \n",
              "\n",
              "                                             geometry  \n",
              "24  POLYGON ((1000544.606 242277.459, 1000609.46 2...  \n",
              "25  POLYGON ((987556.436 219732.621, 987946.195 21...  \n",
              "26  POLYGON ((990696.33 211658.547, 990801.847 211...  \n",
              "27  POLYGON ((983622.385 210775.651, 984410.163 21...  \n",
              "28  POLYGON ((982834.912 211211.061, 982960.722 21...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff92ccf1-01b8-4c78-963b-f133c7848cde\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATEFP</th>\n",
              "      <th>COUNTYFP</th>\n",
              "      <th>TRACTCE</th>\n",
              "      <th>BLKGRPCE</th>\n",
              "      <th>GEOID</th>\n",
              "      <th>NAMELSAD</th>\n",
              "      <th>MTFCC</th>\n",
              "      <th>FUNCSTAT</th>\n",
              "      <th>ALAND</th>\n",
              "      <th>AWATER</th>\n",
              "      <th>INTPTLAT</th>\n",
              "      <th>INTPTLON</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>023900</td>\n",
              "      <td>1</td>\n",
              "      <td>360610239001</td>\n",
              "      <td>Block Group 1</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>27517</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.8322236</td>\n",
              "      <td>-073.9404112</td>\n",
              "      <td>POLYGON ((1000544.606 242277.459, 1000609.46 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>013900</td>\n",
              "      <td>1</td>\n",
              "      <td>360610139001</td>\n",
              "      <td>Block Group 1</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>23621</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.7688543</td>\n",
              "      <td>-073.9868884</td>\n",
              "      <td>POLYGON ((987556.436 219732.621, 987946.195 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>007800</td>\n",
              "      <td>2</td>\n",
              "      <td>360610078002</td>\n",
              "      <td>Block Group 2</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>33890</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.7471571</td>\n",
              "      <td>-073.9756186</td>\n",
              "      <td>POLYGON ((990696.33 211658.547, 990801.847 211...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>008900</td>\n",
              "      <td>1</td>\n",
              "      <td>360610089001</td>\n",
              "      <td>Block Group 1</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>20377</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.7443158</td>\n",
              "      <td>-074.0010568</td>\n",
              "      <td>POLYGON ((983622.385 210775.651, 984410.163 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>36</td>\n",
              "      <td>061</td>\n",
              "      <td>008900</td>\n",
              "      <td>4</td>\n",
              "      <td>360610089004</td>\n",
              "      <td>Block Group 4</td>\n",
              "      <td>G5030</td>\n",
              "      <td>S</td>\n",
              "      <td>42006</td>\n",
              "      <td>0</td>\n",
              "      <td>+40.7458221</td>\n",
              "      <td>-074.0036736</td>\n",
              "      <td>POLYGON ((982834.912 211211.061, 982960.722 21...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff92ccf1-01b8-4c78-963b-f133c7848cde')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff92ccf1-01b8-4c78-963b-f133c7848cde button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff92ccf1-01b8-4c78-963b-f133c7848cde');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimate Population Within 0.5 Miles of Each Station (Area-Weighted Method)\n",
        "\n",
        "Below is a complete workflow that:\n",
        "\n",
        "1. Creates 0.5-mile station buffers (in feet, using EPSG:2263),\n",
        "2. Loads 2020 ACS 5-year total population for block groups (B01003),\n",
        "3. Joins ACS population to NYC block-group geometries,\n",
        "4. Intersects buffers with block groups,\n",
        "5. Applies area-weighted population allocation,\n",
        "6. Produces population within 0.5 miles of each station.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rvO_sBXA05Oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Station 0.5-mile buffers + NYC Block Group intersections\n",
        "# + Area-weighted population within 0.5 miles\n",
        "# (FIXED: pop_density_0p5mi uses pandas Series, not numpy array)\n",
        "# =========================================================\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "# -----------------------------\n",
        "# User config\n",
        "# -----------------------------\n",
        "ACS_YEAR = 2020  # ACS 2020 5-year\n",
        "STATEFP = \"36\"\n",
        "NYC_COUNTYFPS = [\"005\", \"047\", \"061\", \"081\", \"085\"]  # Bronx, Kings, New York, Queens, Richmond\n",
        "\n",
        "FT_PER_MILE = 5280.0\n",
        "BUFFER_DIST_FT = 0.5 * FT_PER_MILE  # 2,640 feet\n",
        "SQFT_PER_SQMI = FT_PER_MILE ** 2\n",
        "\n",
        "TIGER_BG_NY_URL = \"https://www2.census.gov/geo/tiger/TIGER2020/BG/tl_2020_36_bg.zip\"\n",
        "ACS_BASE = f\"https://api.census.gov/data/{ACS_YEAR}/acs/acs5\"\n",
        "\n",
        "# -----------------------------\n",
        "# 0) Preconditions\n",
        "# -----------------------------\n",
        "if \"stations_proj\" not in globals():\n",
        "    raise NameError(\n",
        "        \"stations_proj is not defined. You need a GeoDataFrame named stations_proj \"\n",
        "        \"with columns ['stop_id','stop_name','geometry'] and a projected CRS (e.g., EPSG:2263).\"\n",
        "    )\n",
        "\n",
        "required_cols = {\"stop_id\", \"stop_name\", \"geometry\"}\n",
        "missing = required_cols - set(stations_proj.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"stations_proj is missing required columns: {sorted(missing)}\")\n",
        "\n",
        "if stations_proj.crs is None:\n",
        "    raise ValueError(\"stations_proj.crs is None. Set a CRS (ideally EPSG:2263) before buffering.\")\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Load TIGER block groups for NY (2020)\n",
        "# -----------------------------\n",
        "bg_ny = gpd.read_file(TIGER_BG_NY_URL)\n",
        "print(\"Loaded TIGER BG rows:\", len(bg_ny))\n",
        "print(\"TIGER CRS:\", bg_ny.crs)\n",
        "\n",
        "state_col = \"STATEFP\" if \"STATEFP\" in bg_ny.columns else \"STATEFP20\"\n",
        "county_col = \"COUNTYFP\" if \"COUNTYFP\" in bg_ny.columns else \"COUNTYFP20\"\n",
        "geoid_col = \"GEOID\" if \"GEOID\" in bg_ny.columns else (\"GEOID20\" if \"GEOID20\" in bg_ny.columns else None)\n",
        "if geoid_col is None:\n",
        "    raise ValueError(\"Could not find GEOID column in TIGER BG file (expected GEOID or GEOID20).\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Filter to NYC block groups\n",
        "# -----------------------------\n",
        "bg_nyc = bg_ny.loc[\n",
        "    (bg_ny[state_col].astype(str) == STATEFP) &\n",
        "    (bg_ny[county_col].astype(str).isin(NYC_COUNTYFPS))\n",
        "].copy()\n",
        "\n",
        "print(\"NYC TIGER BG rows:\", len(bg_nyc))\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Reproject BGs to match stations CRS\n",
        "# -----------------------------\n",
        "bg_nyc_proj = bg_nyc.to_crs(stations_proj.crs)\n",
        "print(\"Reprojected NYC BG CRS:\", bg_nyc_proj.crs)\n",
        "\n",
        "bg_nyc_proj[\"GEOID\"] = bg_nyc_proj[geoid_col].astype(str)\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Fetch ACS population for NYC BGs (B01003_001E)\n",
        "# -----------------------------\n",
        "def fetch_acs_bg_population_for_county(county_fips: str) -> pd.DataFrame:\n",
        "    url = (\n",
        "        f\"{ACS_BASE}?get=B01003_001E&for=block%20group:*\"\n",
        "        f\"&in=state:{STATEFP}%20county:{county_fips}%20tract:*\"\n",
        "    )\n",
        "    r = requests.get(url, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    if not isinstance(data, list) or len(data) < 2:\n",
        "        raise RuntimeError(f\"Bad ACS payload for county {county_fips}: {str(data)[:200]}\")\n",
        "\n",
        "    df = pd.DataFrame(data[1:], columns=data[0])\n",
        "    df[\"GEOID\"] = (\n",
        "        df[\"state\"].astype(str).str.zfill(2) +\n",
        "        df[\"county\"].astype(str).str.zfill(3) +\n",
        "        df[\"tract\"].astype(str).str.zfill(6) +\n",
        "        df[\"block group\"].astype(str).str.zfill(1)\n",
        "    )\n",
        "    df[\"population\"] = pd.to_numeric(df[\"B01003_001E\"], errors=\"coerce\").fillna(0)\n",
        "    return df[[\"GEOID\", \"population\"]]\n",
        "\n",
        "acs_pop = pd.concat(\n",
        "    [fetch_acs_bg_population_for_county(c) for c in NYC_COUNTYFPS],\n",
        "    ignore_index=True\n",
        ").drop_duplicates(subset=[\"GEOID\"])\n",
        "\n",
        "print(\"ACS BG pop rows:\", len(acs_pop))\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Build bg_pop (BG geometry + population)\n",
        "# -----------------------------\n",
        "bg_pop = bg_nyc_proj.merge(acs_pop, on=\"GEOID\", how=\"left\")\n",
        "bg_pop[\"population\"] = bg_pop[\"population\"].fillna(0)\n",
        "\n",
        "bg_pop[\"bg_area\"] = bg_pop.geometry.area\n",
        "bg_pop = bg_pop.loc[bg_pop[\"bg_area\"] > 0].copy()\n",
        "\n",
        "print(\"bg_pop rows (NYC BGs with geometry):\", len(bg_pop))\n",
        "print(\"bg_pop population > 0 share:\", (bg_pop[\"population\"] > 0).mean())\n",
        "\n",
        "# -----------------------------\n",
        "# 6) Build 0.5-mile station buffers (feet)\n",
        "# -----------------------------\n",
        "station_buffers = stations_proj[[\"stop_id\", \"stop_name\", \"geometry\"]].copy()\n",
        "station_buffers[\"geometry\"] = station_buffers.geometry.buffer(BUFFER_DIST_FT)\n",
        "\n",
        "# -----------------------------\n",
        "# 7) Intersect buffers with BGs\n",
        "# -----------------------------\n",
        "intersections = gpd.overlay(\n",
        "    station_buffers,\n",
        "    bg_pop[[\"GEOID\", \"population\", \"bg_area\", \"geometry\"]],\n",
        "    how=\"intersection\"\n",
        ")\n",
        "\n",
        "print(\"Intersections rows:\", len(intersections))\n",
        "\n",
        "# -----------------------------\n",
        "# 8) Area-weighted population within buffer\n",
        "# -----------------------------\n",
        "intersections[\"intersect_area\"] = intersections.geometry.area\n",
        "intersections[\"area_ratio\"] = np.where(\n",
        "    intersections[\"bg_area\"] > 0,\n",
        "    intersections[\"intersect_area\"] / intersections[\"bg_area\"],\n",
        "    0.0\n",
        ").astype(float).clip(0, 1)\n",
        "\n",
        "intersections[\"pop_within\"] = intersections[\"population\"] * intersections[\"area_ratio\"]\n",
        "\n",
        "pop_by_station = (\n",
        "    intersections.groupby([\"stop_id\", \"stop_name\"], as_index=False)[\"pop_within\"]\n",
        "    .sum()\n",
        "    .round()\n",
        "    .astype({\"pop_within\": int})\n",
        "    .rename(columns={\"pop_within\": \"population_0p5mi\"})\n",
        ")\n",
        "\n",
        "station_buffers = station_buffers.merge(pop_by_station, on=[\"stop_id\", \"stop_name\"], how=\"left\")\n",
        "station_buffers[\"population_0p5mi\"] = station_buffers[\"population_0p5mi\"].fillna(0).astype(int)\n",
        "\n",
        "# -----------------------------\n",
        "# 9) Derived metrics + ranking  (FIXED)\n",
        "# -----------------------------\n",
        "station_buffers[\"buffer_area_sqmi\"] = station_buffers.geometry.area / SQFT_PER_SQMI\n",
        "\n",
        "# ✅ compute density in pandas so we can safely fillna/astype\n",
        "station_buffers[\"pop_density_0p5mi\"] = (\n",
        "    station_buffers[\"population_0p5mi\"]\n",
        "    .div(station_buffers[\"buffer_area_sqmi\"].replace({0: np.nan}))\n",
        "    .round(0)\n",
        "    .fillna(0)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "station_buffers[\"pop_rank\"] = (\n",
        "    station_buffers[\"population_0p5mi\"]\n",
        "    .rank(ascending=False, method=\"min\")\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "station_buffers_sorted = station_buffers.sort_values(\"population_0p5mi\", ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 stations by population within 0.5 miles:\")\n",
        "display(\n",
        "    station_buffers_sorted[\n",
        "        [\"stop_id\", \"stop_name\", \"population_0p5mi\", \"pop_density_0p5mi\", \"pop_rank\"]\n",
        "    ].tail(10)\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 10) Preserve BG detail table for later features\n",
        "# -----------------------------\n",
        "station_bg_detail = intersections.copy()\n",
        "\n",
        "detail_cols = [c for c in [\n",
        "    \"stop_id\", \"stop_name\",\n",
        "    \"GEOID\",\n",
        "    \"population\", \"bg_area\", \"intersect_area\", \"area_ratio\", \"pop_within\"\n",
        "] if c in station_bg_detail.columns]\n",
        "\n",
        "display(station_bg_detail[detail_cols].tail())\n",
        "\n",
        "# -----------------------------\n",
        "# 11) Save outputs\n",
        "# -----------------------------\n",
        "station_buffers.to_csv(\"station_population_analysis_0p5mi.csv\", index=False)\n",
        "station_bg_detail.to_csv(\"station_blockgroup_detail_0p5mi.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved: station_population_analysis_0p5mi.csv\")\n",
        "print(\"Saved: station_blockgroup_detail_0p5mi.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "u6lUAWtn1TgT",
        "outputId": "303c89e0-4339-4548-b8bc-5ee46a4299c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded TIGER BG rows: 16070\n",
            "TIGER CRS: EPSG:4269\n",
            "NYC TIGER BG rows: 6807\n",
            "Reprojected NYC BG CRS: EPSG:2263\n",
            "ACS BG pop rows: 6807\n",
            "bg_pop rows (NYC BGs with geometry): 6807\n",
            "bg_pop population > 0 share: 0.9390333480240929\n",
            "Intersections rows: 23421\n",
            "\n",
            "Top 10 stations by population within 0.5 miles:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    stop_id               stop_name  population_0p5mi  pop_density_0p5mi  \\\n",
              "498     S31               St George              5746               7328   \n",
              "482     S15            Prince's Bay              4538               5787   \n",
              "479     S11             Arthur Kill              4521               5766   \n",
              "478     S09             Tottenville              4095               5222   \n",
              "156     702      Mets-Willets Point              3443               4391   \n",
              "481     S14         Pleasant Plains              3319               4233   \n",
              "480     S13         Richmond Valley              2429               3098   \n",
              "517  IBX_19  Brooklyn Army Terminal              1640               2091   \n",
              "351     H04           Broad Channel              1200               1530   \n",
              "362     H19           Broad Channel              1187               1514   \n",
              "\n",
              "     pop_rank  \n",
              "498       509  \n",
              "482       510  \n",
              "479       511  \n",
              "478       512  \n",
              "156       513  \n",
              "481       514  \n",
              "480       515  \n",
              "517       516  \n",
              "351       517  \n",
              "362       518  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ccaf7aa-f564-4a2e-863b-08f75c7b0ba0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>population_0p5mi</th>\n",
              "      <th>pop_density_0p5mi</th>\n",
              "      <th>pop_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>S31</td>\n",
              "      <td>St George</td>\n",
              "      <td>5746</td>\n",
              "      <td>7328</td>\n",
              "      <td>509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>S15</td>\n",
              "      <td>Prince's Bay</td>\n",
              "      <td>4538</td>\n",
              "      <td>5787</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>S11</td>\n",
              "      <td>Arthur Kill</td>\n",
              "      <td>4521</td>\n",
              "      <td>5766</td>\n",
              "      <td>511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>S09</td>\n",
              "      <td>Tottenville</td>\n",
              "      <td>4095</td>\n",
              "      <td>5222</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>702</td>\n",
              "      <td>Mets-Willets Point</td>\n",
              "      <td>3443</td>\n",
              "      <td>4391</td>\n",
              "      <td>513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>S14</td>\n",
              "      <td>Pleasant Plains</td>\n",
              "      <td>3319</td>\n",
              "      <td>4233</td>\n",
              "      <td>514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>S13</td>\n",
              "      <td>Richmond Valley</td>\n",
              "      <td>2429</td>\n",
              "      <td>3098</td>\n",
              "      <td>515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>1640</td>\n",
              "      <td>2091</td>\n",
              "      <td>516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>H04</td>\n",
              "      <td>Broad Channel</td>\n",
              "      <td>1200</td>\n",
              "      <td>1530</td>\n",
              "      <td>517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>H19</td>\n",
              "      <td>Broad Channel</td>\n",
              "      <td>1187</td>\n",
              "      <td>1514</td>\n",
              "      <td>518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ccaf7aa-f564-4a2e-863b-08f75c7b0ba0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ccaf7aa-f564-4a2e-863b-08f75c7b0ba0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ccaf7aa-f564-4a2e-863b-08f75c7b0ba0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Saved: station_blockgroup_detail_0p5mi\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"H04\",\n          \"S15\",\n          \"S14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Brooklyn Army Terminal\",\n          \"Prince's Bay\",\n          \"Pleasant Plains\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1562,\n        \"min\": 1187,\n        \"max\": 5746,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1200,\n          4538,\n          3319\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pop_density_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1992,\n        \"min\": 1514,\n        \"max\": 7328,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1530,\n          5787,\n          4233\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pop_rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 509,\n        \"max\": 518,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          517,\n          510,\n          514\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      stop_id               stop_name         GEOID  population       bg_area  \\\n",
              "23416  IBX_19  Brooklyn Army Terminal  360470022003         940  1.031276e+06   \n",
              "23417  IBX_19  Brooklyn Army Terminal  360470030002         620  4.768618e+05   \n",
              "23418  IBX_19  Brooklyn Army Terminal  360470030001         925  7.091931e+05   \n",
              "23419  IBX_19  Brooklyn Army Terminal  360470022001        1038  1.293441e+06   \n",
              "23420  IBX_19  Brooklyn Army Terminal  360470034001         874  3.747025e+06   \n",
              "\n",
              "       intersect_area  area_ratio  pop_within  \n",
              "23416    8.673770e+04    0.084107   79.060772  \n",
              "23417    1.429062e+04    0.029968   18.580190  \n",
              "23418    5.502170e+05    0.775835  717.647586  \n",
              "23419    1.308070e+05    0.101131  104.974005  \n",
              "23420    2.976980e+06    0.794491  694.385557  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e3faaf3-afc1-48ff-a80c-b645392f15fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>GEOID</th>\n",
              "      <th>population</th>\n",
              "      <th>bg_area</th>\n",
              "      <th>intersect_area</th>\n",
              "      <th>area_ratio</th>\n",
              "      <th>pop_within</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23416</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>360470022003</td>\n",
              "      <td>940</td>\n",
              "      <td>1.031276e+06</td>\n",
              "      <td>8.673770e+04</td>\n",
              "      <td>0.084107</td>\n",
              "      <td>79.060772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23417</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>360470030002</td>\n",
              "      <td>620</td>\n",
              "      <td>4.768618e+05</td>\n",
              "      <td>1.429062e+04</td>\n",
              "      <td>0.029968</td>\n",
              "      <td>18.580190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23418</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>360470030001</td>\n",
              "      <td>925</td>\n",
              "      <td>7.091931e+05</td>\n",
              "      <td>5.502170e+05</td>\n",
              "      <td>0.775835</td>\n",
              "      <td>717.647586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23419</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>360470022001</td>\n",
              "      <td>1038</td>\n",
              "      <td>1.293441e+06</td>\n",
              "      <td>1.308070e+05</td>\n",
              "      <td>0.101131</td>\n",
              "      <td>104.974005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23420</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>360470034001</td>\n",
              "      <td>874</td>\n",
              "      <td>3.747025e+06</td>\n",
              "      <td>2.976980e+06</td>\n",
              "      <td>0.794491</td>\n",
              "      <td>694.385557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e3faaf3-afc1-48ff-a80c-b645392f15fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e3faaf3-afc1-48ff-a80c-b645392f15fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e3faaf3-afc1-48ff-a80c-b645392f15fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Saved: station_blockgroup_detail_0p5mi\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"IBX_19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Brooklyn Army Terminal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GEOID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"360470030002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 156,\n        \"min\": 620,\n        \"max\": 1038,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          620\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bg_area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1320222.31839518,\n        \"min\": 476861.77911250707,\n        \"max\": 3747025.499188935,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          476861.77911250707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intersect_area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1261340.6903162308,\n        \"min\": 14290.616609791237,\n        \"max\": 2976979.8493402465,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14290.616609791237\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.39169854396326614,\n        \"min\": 0.02996804784058741,\n        \"max\": 0.7944914839743233,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.02996804784058741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pop_within\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 351.2075691465813,\n        \"min\": 18.580189661164194,\n        \"max\": 717.647585607624,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          18.580189661164194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved: station_population_analysis_0p5mi.csv\n",
            "Saved: station_blockgroup_detail_0p5mi.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section B — Variables"
      ],
      "metadata": {
        "id": "a1IfPBQw2qbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 1: Population within 0.5 mile (already built)\n",
        "# Source: ACS 5-year B01003 Total Population (block group)\n",
        "# Method: Area-weighted allocation using station_bg_detail area_ratio\n",
        "# =========================================================\n",
        "\n",
        "# Assumes you already computed:\n",
        "# - bg_pop: NYC block groups with \"GEOID\", \"population\", \"bg_area\", geometry\n",
        "# - station_buffers: buffer polygons with stop_id, stop_name, geometry\n",
        "# - station_bg_detail (aka intersections): overlay(station_buffers, bg_pop), with area_ratio\n",
        "#\n",
        "# If your \"population_0p5mi\" is already in station_buffers, this is just a quick validation.\n",
        "\n",
        "# 1) Validate required columns exist\n",
        "required_cols = {\"stop_id\", \"stop_name\", \"population\", \"area_ratio\"}\n",
        "missing = required_cols - set(station_bg_detail.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"station_bg_detail missing columns: {missing}\")\n",
        "\n",
        "# 2) Recompute pop_within from stored block-group population and area weights\n",
        "station_bg_detail[\"pop_within\"] = station_bg_detail[\"population\"] * station_bg_detail[\"area_ratio\"]\n",
        "\n",
        "# 3) Aggregate to station level (sum area-weighted population pieces)\n",
        "pop_by_station = (\n",
        "    station_bg_detail.groupby([\"stop_id\", \"stop_name\"])[\"pop_within\"]\n",
        "    .sum()\n",
        "    .round()\n",
        "    .astype(int)\n",
        "    .reset_index()\n",
        "    .rename(columns={\"pop_within\": \"population_0p5mi\"})\n",
        ")\n",
        "\n",
        "# 4) Attach back to station_buffers\n",
        "station_buffers = station_buffers.drop(columns=[\"population_0p5mi\"], errors=\"ignore\").merge(\n",
        "    pop_by_station, on=[\"stop_id\", \"stop_name\"], how=\"left\"\n",
        ")\n",
        "station_buffers[\"population_0p5mi\"] = station_buffers[\"population_0p5mi\"].fillna(0).astype(int)\n",
        "\n",
        "display(station_buffers[[\"stop_id\", \"stop_name\", \"population_0p5mi\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TbnuoNCFO7p3",
        "outputId": "d050d758-0b59-452d-b506-3267bf765c58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  population_0p5mi\n",
              "0     101  Van Cortlandt Park-242 St             16751\n",
              "1     103                     238 St             30765\n",
              "2     104                     231 St             43760\n",
              "3     106         Marble Hill-225 St             38704\n",
              "4     107                     215 St             29362"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c310412-8ee2-4f1b-8771-06a70851dc48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>population_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>16751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>30765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>43760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>38704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>29362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c310412-8ee2-4f1b-8771-06a70851dc48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c310412-8ee2-4f1b-8771-06a70851dc48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c310412-8ee2-4f1b-8771-06a70851dc48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(station_buffers[[\\\"stop_id\\\", \\\"stop_name\\\", \\\"population_0p5mi\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10297,\n        \"min\": 16751,\n        \"max\": 43760,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          30765,\n          29362,\n          43760\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 2: Employment within 0.5 mile (LODES jobs)\n",
        "# FIX: Auto-detect a working LODES WAC URL instead of using a placeholder.\n",
        "# =========================================================\n",
        "\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# --- SETTINGS ---\n",
        "LODES_STATE = \"ny\"\n",
        "LODES_YEAR = 2019          # try 2020 first; if not found, try 2019/2021/etc.\n",
        "LODES_VERSIONS = [\"LODES8\", \"LODES7\"]  # try newest first, then fallback\n",
        "SEGMENT = \"S000\"           # all segments (all workers)\n",
        "JOBTYPE = \"JT00\"           # all jobs\n",
        "TIMEOUT = 120\n",
        "\n",
        "def find_lodes_wac_url(state: str, year: int) -> str:\n",
        "    \"\"\"\n",
        "    Try common LODES WAC file name patterns across LODES versions and return the first working URL.\n",
        "    This avoids relying on directory listings (which can be hard to fetch in some environments).\n",
        "    \"\"\"\n",
        "    # Known base path format for LODES downloads\n",
        "    bases = [f\"https://lehd.ces.census.gov/data/lodes/{v}/{state}/wac/\" for v in LODES_VERSIONS]\n",
        "\n",
        "    # Common filename patterns seen in LODES releases\n",
        "    # Pattern A (very common): <st>_wac_<seg>_<jt>_<year>.csv.gz\n",
        "    # Pattern B (sometimes):   <st>_wac_<jt>_<seg>_<year>.csv.gz\n",
        "    # Pattern C (rare):        <st>_wac_<seg>_<year>.csv.gz  (less detailed)\n",
        "    candidates = [\n",
        "        f\"{state}_wac_{SEGMENT}_{JOBTYPE}_{year}.csv.gz\",\n",
        "        f\"{state}_wac_{JOBTYPE}_{SEGMENT}_{year}.csv.gz\",\n",
        "        f\"{state}_wac_{SEGMENT}_{year}.csv.gz\",\n",
        "    ]\n",
        "\n",
        "    # Try each candidate; accept first HTTP 200\n",
        "    for base in bases:\n",
        "        for fname in candidates:\n",
        "            url = base + fname\n",
        "            try:\n",
        "                r = requests.get(url, timeout=TIMEOUT, stream=True)\n",
        "                if r.status_code == 200:\n",
        "                    return url\n",
        "            except requests.RequestException:\n",
        "                # Try next candidate\n",
        "                pass\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find a working WAC URL for state={state}, year={year}. \"\n",
        "        \"Try a different year (e.g., 2019, 2021) or verify the LODES version available.\"\n",
        "    )\n",
        "\n",
        "# 1) Find a working WAC URL automatically\n",
        "wac_url = find_lodes_wac_url(LODES_STATE, LODES_YEAR)\n",
        "print(\"Using WAC URL:\", wac_url)\n",
        "\n",
        "# 2) Download and load the gzipped CSV\n",
        "r = requests.get(wac_url, timeout=TIMEOUT)\n",
        "r.raise_for_status()\n",
        "wac = pd.read_csv(BytesIO(r.content), compression=\"gzip\", dtype={\"w_geocode\": str})\n",
        "\n",
        "# 3) Validate expected columns and keep total jobs\n",
        "# In WAC, total jobs is typically \"C000\"\n",
        "if \"w_geocode\" not in wac.columns or \"C000\" not in wac.columns:\n",
        "    raise ValueError(f\"Expected columns 'w_geocode' and 'C000'. Found: {list(wac.columns)[:40]}\")\n",
        "\n",
        "wac = wac[[\"w_geocode\", \"C000\"]].rename(columns={\"w_geocode\": \"block_geoid\", \"C000\": \"jobs\"})\n",
        "wac[\"jobs\"] = pd.to_numeric(wac[\"jobs\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Load NYC Census blocks (2020 TIGER), create centroids,\n",
        "#    and attach LODES jobs to each workplace block\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# TIGER 2020 blocks for NY State\n",
        "blocks_url = \"https://www2.census.gov/geo/tiger/TIGER2020/TABBLOCK20/tl_2020_36_tabblock20.zip\"\n",
        "blocks = gpd.read_file(blocks_url)\n",
        "\n",
        "# Filter to NYC counties using the same nyc_countyfps you used for block groups\n",
        "blocks = blocks.loc[blocks[\"COUNTYFP20\"].astype(str).isin(nyc_countyfps)].copy()\n",
        "\n",
        "# Normalize GEOID field name to 'block_geoid' (15-digit block id)\n",
        "blocks = blocks.rename(columns={\"GEOID20\": \"block_geoid\"})\n",
        "\n",
        "# Keep only what we need and create centroid points for spatial join\n",
        "blocks = blocks[[\"block_geoid\", \"geometry\"]].copy()\n",
        "blocks[\"geometry\"] = blocks.geometry.centroid\n",
        "\n",
        "# Reproject to match station buffers CRS (EPSG:2263)\n",
        "blocks = blocks.to_crs(station_buffers.crs)\n",
        "\n",
        "# Join LODES jobs onto blocks (inner keeps blocks that exist in WAC)\n",
        "blocks_jobs = blocks.merge(wac, on=\"block_geoid\", how=\"inner\")\n",
        "blocks_jobs[\"jobs\"] = pd.to_numeric(blocks_jobs[\"jobs\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5) Spatial join: workplace blocks within station buffers\n",
        "# ---------------------------------------------------------\n",
        "join_jobs = gpd.sjoin(\n",
        "    blocks_jobs[[\"block_geoid\", \"jobs\", \"geometry\"]],\n",
        "    station_buffers[[\"stop_id\", \"stop_name\", \"geometry\"]],\n",
        "    how=\"inner\",\n",
        "    predicate=\"within\",\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6) Aggregate jobs per station buffer and attach to stations\n",
        "# ---------------------------------------------------------\n",
        "jobs_by_station = (\n",
        "    join_jobs.groupby([\"stop_id\", \"stop_name\"])[\"jobs\"]\n",
        "    .sum()\n",
        "    .round()\n",
        "    .astype(int)\n",
        "    .reset_index()\n",
        "    .rename(columns={\"jobs\": \"jobs_0p5mi\"})\n",
        ")\n",
        "\n",
        "station_buffers = station_buffers.merge(jobs_by_station, on=[\"stop_id\", \"stop_name\"], how=\"left\")\n",
        "station_buffers[\"jobs_0p5mi\"] = station_buffers[\"jobs_0p5mi\"].fillna(0).astype(int)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 7) Display output\n",
        "# ---------------------------------------------------------\n",
        "display(\n",
        "    station_buffers.sort_values(\"jobs_0p5mi\", ascending=False)[\n",
        "        [\"stop_id\", \"stop_name\", \"jobs_0p5mi\"]\n",
        "    ].head(10)\n",
        ")\n",
        "\n",
        "display(station_buffers[\"jobs_0p5mi\"].describe())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "zMyQvAUxQJhK",
        "outputId": "c5c28b6a-e255-46ad-d659-d289a7d167b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using WAC URL: https://lehd.ces.census.gov/data/lodes/LODES8/ny/wac/ny_wac_S000_JT00_2019.csv.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2556053195.py:88: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  blocks[\"geometry\"] = blocks.geometry.centroid\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    stop_id                  stop_name  jobs_0p5mi\n",
              "261     D16            42 St-Bryant Pk      642321\n",
              "174     724                       5 Av      615870\n",
              "447     R16             Times Sq-42 St      589011\n",
              "178     902             Times Sq-42 St      570084\n",
              "260     D15  47-50 Sts-Rockefeller Ctr      567866\n",
              "177     901        Grand Central-42 St      551165\n",
              "175     725             Times Sq-42 St      549469\n",
              "24      127             Times Sq-42 St      547419\n",
              "262     D17            34 St-Herald Sq      524997\n",
              "448     R17            34 St-Herald Sq      508278"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2936ce7-88b7-49b9-b7ff-9adb1b84beaf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>jobs_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>D16</td>\n",
              "      <td>42 St-Bryant Pk</td>\n",
              "      <td>642321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>724</td>\n",
              "      <td>5 Av</td>\n",
              "      <td>615870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>R16</td>\n",
              "      <td>Times Sq-42 St</td>\n",
              "      <td>589011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>902</td>\n",
              "      <td>Times Sq-42 St</td>\n",
              "      <td>570084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>D15</td>\n",
              "      <td>47-50 Sts-Rockefeller Ctr</td>\n",
              "      <td>567866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>901</td>\n",
              "      <td>Grand Central-42 St</td>\n",
              "      <td>551165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>725</td>\n",
              "      <td>Times Sq-42 St</td>\n",
              "      <td>549469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>127</td>\n",
              "      <td>Times Sq-42 St</td>\n",
              "      <td>547419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>D17</td>\n",
              "      <td>34 St-Herald Sq</td>\n",
              "      <td>524997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>R17</td>\n",
              "      <td>34 St-Herald Sq</td>\n",
              "      <td>508278</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2936ce7-88b7-49b9-b7ff-9adb1b84beaf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2936ce7-88b7-49b9-b7ff-9adb1b84beaf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2936ce7-88b7-49b9-b7ff-9adb1b84beaf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(station_buffers[\\\"jobs_0p5mi\\\"]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"D17\",\n          \"724\",\n          \"901\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"42 St-Bryant Pk\",\n          \"5 Av\",\n          \"34 St-Herald Sq\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jobs_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40426,\n        \"min\": 508278,\n        \"max\": 642321,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          524997,\n          615870,\n          551165\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count       518.000000\n",
              "mean      58844.708494\n",
              "std      112725.034329\n",
              "min         474.000000\n",
              "25%        6393.500000\n",
              "50%       11738.000000\n",
              "75%       35362.750000\n",
              "max      642321.000000\n",
              "Name: jobs_0p5mi, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jobs_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>518.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>58844.708494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>112725.034329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>474.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6393.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11738.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35362.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>642321.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install osmnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rllBhtxCaQD4",
        "outputId": "c85607bc-ba0b-46c8-b2fa-05cbbd5219b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osmnx\n",
            "  Downloading osmnx-2.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: geopandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from osmnx) (1.1.2)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.12/dist-packages (from osmnx) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.32.4)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.1.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (0.12.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (26.0)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (3.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2026.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
            "Downloading osmnx-2.0.7-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: osmnx\n",
            "Successfully installed osmnx-2.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 4: Street Intersection Density (TIGER Roads)\n",
        "# Corrected: TIGER roads are county-level, not statewide\n",
        "# =========================================================\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# NYC county FIPS codes\n",
        "nyc_countyfps = {\n",
        "    \"005\",  # Bronx\n",
        "    \"047\",  # Kings (Brooklyn)\n",
        "    \"061\",  # New York (Manhattan)\n",
        "    \"081\",  # Queens\n",
        "    \"085\",  # Richmond (Staten Island)\n",
        "}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Download TIGER 2020 roads by county and combine\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "roads_list = []\n",
        "\n",
        "for county in nyc_countyfps:\n",
        "    roads_url = f\"https://www2.census.gov/geo/tiger/TIGER2020/ROADS/tl_2020_36{county}_roads.zip\"\n",
        "    print(\"Downloading:\", roads_url)\n",
        "    roads_c = gpd.read_file(roads_url)\n",
        "    roads_list.append(roads_c)\n",
        "\n",
        "roads = pd.concat(roads_list, ignore_index=True)\n",
        "\n",
        "print(\"Total NYC road segments:\", len(roads))\n",
        "\n",
        "# Reproject to match station buffers (EPSG:2263 feet)\n",
        "roads = roads.to_crs(station_buffers.crs)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) Compute intersection points\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Spatial self-join to find intersecting road segments\n",
        "road_pairs = gpd.sjoin(\n",
        "    roads[[\"geometry\"]],\n",
        "    roads[[\"geometry\"]],\n",
        "    how=\"inner\",\n",
        "    predicate=\"intersects\"\n",
        ")\n",
        "\n",
        "# --- After sjoin ---\n",
        "road_pairs = gpd.sjoin(\n",
        "    roads[[\"geometry\"]],\n",
        "    roads[[\"geometry\"]],\n",
        "    how=\"inner\",\n",
        "    predicate=\"intersects\"\n",
        ")\n",
        "\n",
        "# GeoPandas keeps the LEFT index as the dataframe index\n",
        "road_pairs = road_pairs.reset_index().rename(columns={\"index\": \"index_left\"})\n",
        "\n",
        "# RIGHT index is stored in \"index_right\"\n",
        "if \"index_right\" not in road_pairs.columns:\n",
        "    raise ValueError(f\"sjoin did not create 'index_right'. Columns: {list(road_pairs.columns)}\")\n",
        "\n",
        "# Remove self matches (same feature intersecting itself)\n",
        "road_pairs = road_pairs[road_pairs[\"index_left\"] != road_pairs[\"index_right\"]].copy()\n",
        "\n",
        "# Compute intersection geometry pairwise\n",
        "left_geom = roads.geometry.iloc[road_pairs[\"index_left\"]].values\n",
        "right_geom = roads.geometry.iloc[road_pairs[\"index_right\"]].values\n",
        "road_pairs[\"intersect_geom\"] = left_geom.intersection(right_geom)\n",
        "\n",
        "# Keep only point intersections\n",
        "road_pairs = road_pairs[road_pairs[\"intersect_geom\"].geom_type == \"Point\"].copy()\n",
        "\n",
        "intersection_gdf = gpd.GeoDataFrame(\n",
        "    geometry=road_pairs[\"intersect_geom\"],\n",
        "    crs=station_buffers.crs\n",
        ").drop_duplicates(subset=\"geometry\")\n",
        "\n",
        "\n",
        "print(\"Total unique intersections:\", len(intersection_gdf))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Count intersections within each station buffer\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "nodes_join = gpd.sjoin(\n",
        "    intersection_gdf,\n",
        "    station_buffers[[\"stop_id\", \"stop_name\", \"geometry\"]],\n",
        "    how=\"inner\",\n",
        "    predicate=\"within\"\n",
        ")\n",
        "\n",
        "node_counts = (\n",
        "    nodes_join.groupby([\"stop_id\", \"stop_name\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"intersection_count_0p5mi\")\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Compute buffer area (sq miles)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "SQFT_PER_SQMI = 5280.0 ** 2\n",
        "\n",
        "if \"buffer_area_sqmi\" not in station_buffers.columns:\n",
        "    station_buffers[\"buffer_area_sqmi\"] = (\n",
        "        station_buffers.geometry.area / SQFT_PER_SQMI\n",
        "    )\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5) Attach counts and compute density\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "station_buffers = station_buffers.merge(\n",
        "    node_counts,\n",
        "    on=[\"stop_id\", \"stop_name\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "station_buffers[\"intersection_count_0p5mi\"] = (\n",
        "    station_buffers[\"intersection_count_0p5mi\"]\n",
        "    .fillna(0)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "station_buffers[\"intersection_density_0p5mi\"] = (\n",
        "    station_buffers[\"intersection_count_0p5mi\"]\n",
        "    / station_buffers[\"buffer_area_sqmi\"]\n",
        ")\n",
        "\n",
        "station_buffers[\"intersection_density_0p5mi\"] = (\n",
        "    station_buffers[\"intersection_density_0p5mi\"]\n",
        "    .replace([np.inf, -np.inf], 0)\n",
        "    .fillna(0)\n",
        ")\n",
        "\n",
        "display(\n",
        "    station_buffers[\n",
        "        [\"stop_id\", \"stop_name\",\n",
        "         \"intersection_count_0p5mi\",\n",
        "         \"intersection_density_0p5mi\"]\n",
        "    ].head()\n",
        ")\n",
        "\n",
        "print(\"Intersection density summary:\")\n",
        "display(station_buffers[\"intersection_density_0p5mi\"].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "xpslr9nUcvEt",
        "outputId": "e4971ee6-fc64-4eb6-c3a9-5bfb18ccdd12"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: https://www2.census.gov/geo/tiger/TIGER2020/ROADS/tl_2020_36081_roads.zip\n",
            "Downloading: https://www2.census.gov/geo/tiger/TIGER2020/ROADS/tl_2020_36047_roads.zip\n",
            "Downloading: https://www2.census.gov/geo/tiger/TIGER2020/ROADS/tl_2020_36085_roads.zip\n",
            "Downloading: https://www2.census.gov/geo/tiger/TIGER2020/ROADS/tl_2020_36005_roads.zip\n",
            "Downloading: https://www2.census.gov/geo/tiger/TIGER2020/ROADS/tl_2020_36061_roads.zip\n",
            "Total NYC road segments: 22097\n",
            "Total unique intersections: 51574\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  intersection_count_0p5mi  \\\n",
              "0     101  Van Cortlandt Park-242 St                       104   \n",
              "1     103                     238 St                       142   \n",
              "2     104                     231 St                       140   \n",
              "3     106         Marble Hill-225 St                       125   \n",
              "4     107                     215 St                        79   \n",
              "\n",
              "   intersection_density_0p5mi  \n",
              "0                  132.629864  \n",
              "1                  181.090776  \n",
              "2                  178.540202  \n",
              "3                  159.410894  \n",
              "4                  100.747685  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9695c9e5-21e8-4525-86f5-85273231c377\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>intersection_count_0p5mi</th>\n",
              "      <th>intersection_density_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>104</td>\n",
              "      <td>132.629864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>142</td>\n",
              "      <td>181.090776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>140</td>\n",
              "      <td>178.540202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>125</td>\n",
              "      <td>159.410894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>79</td>\n",
              "      <td>100.747685</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9695c9e5-21e8-4525-86f5-85273231c377')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9695c9e5-21e8-4525-86f5-85273231c377 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9695c9e5-21e8-4525-86f5-85273231c377');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(station_buffers[\\\"intersection_density_0p5mi\\\"]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intersection_count_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 79,\n        \"max\": 142,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          142,\n          79,\n          140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intersection_density_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.89721893364062,\n        \"min\": 100.74768521911055,\n        \"max\": 181.09077596346475,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          181.09077596346475,\n          100.74768521911055,\n          178.54020165411998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intersection density summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count    518.000000\n",
              "mean     213.000036\n",
              "std       68.250348\n",
              "min       36.983327\n",
              "25%      169.613192\n",
              "50%      202.770658\n",
              "75%      241.029272\n",
              "max      419.569474\n",
              "Name: intersection_density_0p5mi, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intersection_density_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>518.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>213.000036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>68.250348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>36.983327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>169.613192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>202.770658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>241.029272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>419.569474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 4: Street Intersection Density (LION Nodes)\n",
        "# Fix: avoid MergeError by overwriting existing columns safely\n",
        "# =========================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Load LION nodes (local .gdb on Drive)\n",
        "# ---------------------------------------------------------\n",
        "lion_gdb_path = \"/content/drive/MyDrive/capstone/lion.gdb\"  # your path\n",
        "lion_nodes = gpd.read_file(lion_gdb_path, layer=\"node\")\n",
        "\n",
        "print(\"Loaded nodes:\", len(lion_nodes))\n",
        "print(\"CRS:\", lion_nodes.crs)\n",
        "\n",
        "# Remove virtual intersections (recommended)\n",
        "if \"VIntersect\" in lion_nodes.columns:\n",
        "    lion_nodes = lion_nodes[lion_nodes[\"VIntersect\"] != \"VirtualIntersection\"].copy()\n",
        "\n",
        "print(\"Physical intersections:\", len(lion_nodes))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) Align CRS to station buffers\n",
        "# ---------------------------------------------------------\n",
        "lion_nodes = lion_nodes.to_crs(station_buffers.crs)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Spatial join: nodes within each station buffer\n",
        "# ---------------------------------------------------------\n",
        "nodes_join = gpd.sjoin(\n",
        "    lion_nodes[[\"geometry\"]],\n",
        "    station_buffers[[\"stop_id\", \"stop_name\", \"geometry\"]],\n",
        "    how=\"inner\",\n",
        "    predicate=\"within\",\n",
        ")\n",
        "\n",
        "# Count nodes per station\n",
        "node_counts = (\n",
        "    nodes_join.groupby(\"stop_id\")\n",
        "    .size()\n",
        "    .rename(\"intersection_count_0p5mi\")\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Compute buffer area (sq mi) if needed\n",
        "# ---------------------------------------------------------\n",
        "SQFT_PER_SQMI = 5280.0 ** 2\n",
        "\n",
        "if \"buffer_area_sqmi\" not in station_buffers.columns:\n",
        "    station_buffers[\"buffer_area_sqmi\"] = station_buffers.geometry.area / SQFT_PER_SQMI\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5) Overwrite (or create) intersection columns WITHOUT merge\n",
        "# ---------------------------------------------------------\n",
        "# Drop old columns if they exist to avoid confusion\n",
        "for col in [\"intersection_count_0p5mi\", \"intersection_density_0p5mi\"]:\n",
        "    if col in station_buffers.columns:\n",
        "        station_buffers = station_buffers.drop(columns=[col])\n",
        "\n",
        "# Attach counts by stop_id (keeps all original station columns)\n",
        "station_buffers = station_buffers.join(node_counts, on=\"stop_id\")\n",
        "\n",
        "# Fill stations with no intersections counted\n",
        "station_buffers[\"intersection_count_0p5mi\"] = (\n",
        "    station_buffers[\"intersection_count_0p5mi\"].fillna(0).astype(int)\n",
        ")\n",
        "\n",
        "# Density per sq mi\n",
        "station_buffers[\"intersection_density_0p5mi\"] = (\n",
        "    station_buffers[\"intersection_count_0p5mi\"] / station_buffers[\"buffer_area_sqmi\"]\n",
        ").replace([np.inf, -np.inf], 0).fillna(0)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6) Preview + quick summary\n",
        "# ---------------------------------------------------------\n",
        "display(\n",
        "    station_buffers[\n",
        "        [\"stop_id\", \"stop_name\", \"intersection_count_0p5mi\", \"intersection_density_0p5mi\"]\n",
        "    ].head()\n",
        ")\n",
        "\n",
        "display(station_buffers[\"intersection_density_0p5mi\"].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "eunCxoDGmjQy",
        "outputId": "1c700eaa-66bd-4bf1-fd43-1a6fbe34804c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loaded nodes: 139493\n",
            "CRS: EPSG:2263\n",
            "Physical intersections: 135669\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  intersection_count_0p5mi  \\\n",
              "0     101  Van Cortlandt Park-242 St                       371   \n",
              "1     103                     238 St                       445   \n",
              "2     104                     231 St                       483   \n",
              "3     106         Marble Hill-225 St                       437   \n",
              "4     107                     215 St                       269   \n",
              "\n",
              "   intersection_density_0p5mi  \n",
              "0                  473.131534  \n",
              "1                  567.502784  \n",
              "2                  615.963696  \n",
              "3                  557.300487  \n",
              "4                  343.052245  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47afc776-d160-414d-a10e-3483ee256c3e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>intersection_count_0p5mi</th>\n",
              "      <th>intersection_density_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>371</td>\n",
              "      <td>473.131534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>445</td>\n",
              "      <td>567.502784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>483</td>\n",
              "      <td>615.963696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>437</td>\n",
              "      <td>557.300487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>269</td>\n",
              "      <td>343.052245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47afc776-d160-414d-a10e-3483ee256c3e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47afc776-d160-414d-a10e-3483ee256c3e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47afc776-d160-414d-a10e-3483ee256c3e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(station_buffers[\\\"intersection_density_0p5mi\\\"]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intersection_count_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 84,\n        \"min\": 269,\n        \"max\": 483,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          445,\n          269,\n          483\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intersection_density_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 107.2303422590173,\n        \"min\": 343.0522446068448,\n        \"max\": 615.9636957067139,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          567.5027838291677,\n          343.0522446068448,\n          615.9636957067139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count     518.000000\n",
              "mean      515.046136\n",
              "std       229.917372\n",
              "min       124.978141\n",
              "25%       341.776957\n",
              "50%       469.305673\n",
              "75%       641.469439\n",
              "max      1309.719908\n",
              "Name: intersection_density_0p5mi, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intersection_density_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>518.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>515.046136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>229.917372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>124.978141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>341.776957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>469.305673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>641.469439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1309.719908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 3: Land Use Mix Diversity (Entropy) within 0.5 mile\n",
        "# Source: NYC Planning MapPLUTO (ArcGIS REST Feature Service)\n",
        "# Output: station_buffers[\"landuse_entropy_0p5mi\"]\n",
        "#\n",
        "# End-to-end steps:\n",
        "#   A) Download MapPLUTO lots intersecting the station buffer extent (ArcGIS REST, paged)\n",
        "#   B) Repair invalid lot geometries safely\n",
        "#   C) Compute land-use entropy per station buffer using:\n",
        "#        sjoin (candidate pairs) + exact intersection area (no accuracy loss)\n",
        "#\n",
        "# Prereq:\n",
        "#   station_buffers GeoDataFrame exists with columns:\n",
        "#     [\"stop_id\", \"stop_name\", \"geometry\"] in EPSG:2263 (feet)\n",
        "# =========================================================\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from shapely.errors import GEOSException\n",
        "\n",
        "# -----------------------------\n",
        "# 0) Shapely geometry repair\n",
        "# -----------------------------\n",
        "try:\n",
        "    from shapely import make_valid  # shapely>=2.0\n",
        "except Exception:\n",
        "    try:\n",
        "        from shapely.validation import make_valid\n",
        "    except Exception:\n",
        "        make_valid = None\n",
        "\n",
        "def safe_make_valid(geom):\n",
        "    \"\"\"\n",
        "    Repair invalid geometries robustly:\n",
        "      1) make_valid() if available\n",
        "      2) buffer(0) fallback\n",
        "      3) drop if still invalid/empty\n",
        "    \"\"\"\n",
        "    if geom is None:\n",
        "        return None\n",
        "    if getattr(geom, \"is_empty\", True):\n",
        "        return None\n",
        "\n",
        "    if make_valid is not None:\n",
        "        try:\n",
        "            g2 = make_valid(geom)\n",
        "            if g2 is None or g2.is_empty:\n",
        "                return None\n",
        "            return g2\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    try:\n",
        "        g2 = geom.buffer(0)\n",
        "        if g2 is None or g2.is_empty:\n",
        "            return None\n",
        "        return g2\n",
        "    except GEOSException:\n",
        "        return None\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) MapPLUTO Feature Service endpoint\n",
        "# ---------------------------------------------------------\n",
        "MAPPLUTO_LAYER_URL = (\n",
        "    \"https://a841-dotweb01.nyc.gov/arcgis/rest/services/GAZETTEER/MapPLUTO/MapServer/0/query\"\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) Robust ArcGIS fetch with pagination (GeoJSON)\n",
        "# ---------------------------------------------------------\n",
        "def fetch_arcgis_geojson(\n",
        "    url: str,\n",
        "    *,\n",
        "    where: str = \"1=1\",\n",
        "    out_fields: str = \"*\",\n",
        "    geom_envelope: tuple[float, float, float, float] | None = None,\n",
        "    in_sr: int | None = None,\n",
        "    out_sr: int | None = None,\n",
        "    page_size: int = 2000,\n",
        "    timeout: int = 180\n",
        ") -> gpd.GeoDataFrame:\n",
        "    \"\"\"\n",
        "    Fetch features from ArcGIS REST as GeoJSON with stable pagination.\n",
        "    \"\"\"\n",
        "    all_features = []\n",
        "    offset = 0\n",
        "\n",
        "    while True:\n",
        "        params = {\n",
        "            \"where\": where,\n",
        "            \"outFields\": out_fields,\n",
        "            \"f\": \"geojson\",\n",
        "            \"returnGeometry\": \"true\",\n",
        "            \"resultOffset\": offset,\n",
        "            \"resultRecordCount\": page_size,\n",
        "            \"orderByFields\": \"OBJECTID\",\n",
        "        }\n",
        "\n",
        "        if geom_envelope is not None:\n",
        "            minx, miny, maxx, maxy = geom_envelope\n",
        "            params.update({\n",
        "                \"geometry\": f\"{minx},{miny},{maxx},{maxy}\",\n",
        "                \"geometryType\": \"esriGeometryEnvelope\",\n",
        "                \"spatialRel\": \"esriSpatialRelIntersects\",\n",
        "            })\n",
        "\n",
        "        if in_sr is not None:\n",
        "            params[\"inSR\"] = in_sr\n",
        "        if out_sr is not None:\n",
        "            params[\"outSR\"] = out_sr\n",
        "\n",
        "        resp = requests.get(url, params=params, timeout=timeout)\n",
        "        resp.raise_for_status()\n",
        "        gj = resp.json()\n",
        "\n",
        "        features = gj.get(\"features\", [])\n",
        "        all_features.extend(features)\n",
        "\n",
        "        exceeded = bool(gj.get(\"exceededTransferLimit\", False))\n",
        "\n",
        "        if (len(features) < page_size and not exceeded) or len(features) == 0:\n",
        "            break\n",
        "\n",
        "        offset += page_size\n",
        "\n",
        "    if not all_features:\n",
        "        return gpd.GeoDataFrame({\"geometry\": []}, geometry=\"geometry\")\n",
        "\n",
        "    return gpd.GeoDataFrame.from_features(all_features)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# A) Download MapPLUTO lots for buffer extent\n",
        "# ---------------------------------------------------------\n",
        "if station_buffers.crs is None:\n",
        "    raise ValueError(\"station_buffers must have a CRS set (expected EPSG:2263).\")\n",
        "\n",
        "minx, miny, maxx, maxy = station_buffers.total_bounds\n",
        "\n",
        "pluto_raw = fetch_arcgis_geojson(\n",
        "    MAPPLUTO_LAYER_URL,\n",
        "    out_fields=\"LandUse\",            # keep payload small\n",
        "    geom_envelope=(minx, miny, maxx, maxy),\n",
        "    in_sr=2263,                      # bbox is in EPSG:2263 feet\n",
        "    out_sr=2263,                     # request EPSG:2263 output\n",
        "    page_size=2000,\n",
        "    timeout=180\n",
        ")\n",
        "\n",
        "print(\"PLUTO rows downloaded:\", len(pluto_raw))\n",
        "\n",
        "# CRS handling: GeoJSON sometimes omits CRS metadata\n",
        "if pluto_raw.crs is None:\n",
        "    pluto_raw = pluto_raw.set_crs(station_buffers.crs, allow_override=True)\n",
        "pluto_raw = pluto_raw.to_crs(station_buffers.crs)\n",
        "\n",
        "# Detect land use field\n",
        "landuse_field = next((c for c in [\"LandUse\", \"LANDUSE\", \"landuse\"] if c in pluto_raw.columns), None)\n",
        "if landuse_field is None:\n",
        "    raise ValueError(\n",
        "        f\"Could not find a land-use field. Columns (sample): {list(pluto_raw.columns)[:40]}\"\n",
        "    )\n",
        "\n",
        "# Keep only needed columns\n",
        "pluto = pluto_raw[[landuse_field, \"geometry\"]].copy()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# B) Repair lot geometries safely\n",
        "# ---------------------------------------------------------\n",
        "pluto = pluto.loc[pluto.geometry.notna() & ~pluto.geometry.is_empty].copy()\n",
        "pluto[\"geometry\"] = pluto[\"geometry\"].apply(safe_make_valid)\n",
        "pluto = pluto.loc[pluto.geometry.notna() & ~pluto.geometry.is_empty].copy()\n",
        "\n",
        "print(\"PLUTO rows after cleaning:\", len(pluto))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# C) FAST entropy computation (accurate)\n",
        "#    sjoin candidate pairs + exact intersection areas\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Ensure CRS match\n",
        "if pluto.crs != station_buffers.crs:\n",
        "    pluto = pluto.to_crs(station_buffers.crs)\n",
        "\n",
        "# 1) Candidate lot-buffer pairs (fast via spatial index)\n",
        "pairs = gpd.sjoin(\n",
        "    pluto[[landuse_field, \"geometry\"]],\n",
        "    station_buffers[[\"stop_id\", \"stop_name\", \"geometry\"]],\n",
        "    how=\"inner\",\n",
        "    predicate=\"intersects\"\n",
        ").reset_index().rename(columns={\"index\": \"lot_idx\", \"index_right\": \"buf_idx\"})\n",
        "\n",
        "print(\"Candidate lot-buffer pairs:\", len(pairs))\n",
        "\n",
        "# 2) Attach buffer geometry to each pair (vectorized lookup)\n",
        "buf_geom = station_buffers.geometry.reset_index(drop=True)\n",
        "pairs = pairs.join(buf_geom.rename(\"buf_geom\"), on=\"buf_idx\")\n",
        "\n",
        "# 3) Exact intersection area for each candidate pair\n",
        "pairs[\"intersect_geom\"] = pairs.geometry.intersection(pairs[\"buf_geom\"])\n",
        "pairs[\"piece_area\"] = pairs[\"intersect_geom\"].area\n",
        "\n",
        "pairs = pairs.loc[pairs[\"piece_area\"] > 0].copy()\n",
        "\n",
        "print(\"Positive-area intersections:\", len(pairs))\n",
        "\n",
        "# 4) Area by station + land use\n",
        "area_by_use = (\n",
        "    pairs.groupby([\"stop_id\", \"stop_name\", landuse_field])[\"piece_area\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# 5) Shares\n",
        "total_area = (\n",
        "    area_by_use.groupby([\"stop_id\", \"stop_name\"])[\"piece_area\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"piece_area\": \"total_lot_area\"})\n",
        ")\n",
        "\n",
        "area_by_use = area_by_use.merge(total_area, on=[\"stop_id\", \"stop_name\"], how=\"left\")\n",
        "area_by_use[\"share\"] = area_by_use[\"piece_area\"] / area_by_use[\"total_lot_area\"]\n",
        "\n",
        "# 6) Vectorized entropy: -sum(p * ln(p))\n",
        "area_by_use[\"p_log_p\"] = area_by_use[\"share\"] * np.log(area_by_use[\"share\"])\n",
        "entropy_by_station = (\n",
        "    area_by_use.groupby([\"stop_id\", \"stop_name\"])[\"p_log_p\"]\n",
        "    .sum()\n",
        "    .mul(-1)\n",
        "    .reset_index()\n",
        "    .rename(columns={\"p_log_p\": \"landuse_entropy_0p5mi\"})\n",
        ")\n",
        "\n",
        "# 7) Attach to stations (retain all)\n",
        "station_buffers = station_buffers.merge(entropy_by_station, on=[\"stop_id\", \"stop_name\"], how=\"left\")\n",
        "station_buffers[\"landuse_entropy_0p5mi\"] = station_buffers[\"landuse_entropy_0p5mi\"].fillna(0.0)\n",
        "\n",
        "# Preview\n",
        "display(station_buffers[[\"stop_id\", \"stop_name\", \"landuse_entropy_0p5mi\"]].head())\n",
        "display(\n",
        "    station_buffers.sort_values(\"landuse_entropy_0p5mi\", ascending=False)[\n",
        "        [\"stop_id\", \"stop_name\", \"landuse_entropy_0p5mi\"]\n",
        "    ].head(10)\n",
        ")\n"
      ],
      "metadata": {
        "id": "AswA0WamXLeZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "494c0856-2ed1-432e-e69f-f8bfb72d8b31"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-102121318.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mminx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstation_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m pluto_raw = fetch_arcgis_geojson(\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mMAPPLUTO_LAYER_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mout_fields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LandUse\"\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0;31m# keep payload small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-102121318.py\u001b[0m in \u001b[0;36mfetch_arcgis_geojson\u001b[0;34m(url, where, out_fields, geom_envelope, in_sr, out_sr, page_size, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outSR\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_sr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mgj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 5: Bike Share Stations Nearby (Citi Bike docks)\n",
        "# Source: Citi Bike GBFS station_information.json\n",
        "# Method: Count stations within buffer\n",
        "# =========================================================\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Citi Bike GBFS endpoint (station locations)\n",
        "gbfs_url = \"https://gbfs.citibikenyc.com/gbfs/en/station_information.json\"\n",
        "\n",
        "r = requests.get(gbfs_url, timeout=60)\n",
        "r.raise_for_status()\n",
        "data = r.json()\n",
        "\n",
        "stations = pd.DataFrame(data[\"data\"][\"stations\"])\n",
        "\n",
        "# Build GeoDataFrame in WGS84 then project to EPSG:2263\n",
        "cb = gpd.GeoDataFrame(\n",
        "    stations,\n",
        "    geometry=gpd.points_from_xy(stations[\"lon\"], stations[\"lat\"]),\n",
        "    crs=\"EPSG:4326\",\n",
        ").to_crs(station_buffers.crs)\n",
        "\n",
        "# Spatial join: Citi Bike stations within subway buffer\n",
        "cb_join = gpd.sjoin(\n",
        "    cb[[\"station_id\", \"name\", \"geometry\"]],\n",
        "    station_buffers[[\"stop_id\", \"stop_name\", \"geometry\"]],\n",
        "    how=\"inner\",\n",
        "    predicate=\"within\",\n",
        ")\n",
        "\n",
        "# Count bike stations per subway station buffer\n",
        "cb_counts = (\n",
        "    cb_join.groupby([\"stop_id\", \"stop_name\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"citibike_count_0p5mi\")\n",
        ")\n",
        "\n",
        "station_buffers = station_buffers.merge(cb_counts, on=[\"stop_id\", \"stop_name\"], how=\"left\")\n",
        "station_buffers[\"citibike_count_0p5mi\"] = station_buffers[\"citibike_count_0p5mi\"].fillna(0).astype(int)\n",
        "\n",
        "display(station_buffers[[\"stop_id\", \"stop_name\", \"citibike_count_0p5mi\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MSKOUFfCPLGB",
        "outputId": "549a1da4-da29-4f45-a109-59152cc54e80"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  citibike_count_0p5mi\n",
              "0     101  Van Cortlandt Park-242 St                     9\n",
              "1     103                     238 St                    18\n",
              "2     104                     231 St                    21\n",
              "3     106         Marble Hill-225 St                    18\n",
              "4     107                     215 St                    13"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-964cebea-5fb9-4ee8-9c62-26b86d0c515f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>citibike_count_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-964cebea-5fb9-4ee8-9c62-26b86d0c515f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-964cebea-5fb9-4ee8-9c62-26b86d0c515f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-964cebea-5fb9-4ee8-9c62-26b86d0c515f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(station_buffers[[\\\"stop_id\\\", \\\"stop_name\\\", \\\"citibike_count_0p5mi\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"citibike_count_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 9,\n        \"max\": 21,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          18,\n          13,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 6 (DETERMINISTIC + NYC-BG OFFSET-DETECTED): % Households with No Vehicle (0.5 mile)\n",
        "# Data source: ACS 2020 5-year Summary File (SEQUENCE-BASED), NY Tracts+Block Groups only\n",
        "#\n",
        "# Output: station_buffers[\"pct_hh_no_vehicle_0p5mi\"]\n",
        "#\n",
        "# Requires:\n",
        "# - station_bg_detail: GEOID (12), area_ratio, stop_id, stop_name\n",
        "# - station_buffers: stop_id, stop_name\n",
        "# - nyc_countyfps: either [\"005\",\"047\",\"061\",\"081\",\"085\"] OR [\"36005\",\"36047\",\"36061\",\"36081\",\"36085\"]\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import zipfile\n",
        "import hashlib\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "ACS_ENDYEAR = 2020\n",
        "STATE_FIPS = \"36\"\n",
        "STATE_ABBR = \"ny\"\n",
        "\n",
        "TABLE_ID = \"B08201\"\n",
        "LINE_TOTAL = 1\n",
        "LINE_NO_VEH = 2  # top-level \"No vehicle available\"\n",
        "OUT_COL = \"pct_hh_no_vehicle_0p5mi\"\n",
        "\n",
        "WORKDIR = \"./acs_sf_cache\"\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "NY_ZIP_URL = (\n",
        "    \"https://www2.census.gov/programs-surveys/acs/summary_file/2020/data/5_year_by_state/\"\n",
        "    \"NewYork_Tracts_Block_Groups_Only.zip\"\n",
        ")\n",
        "LOOKUP_URL = (\n",
        "    \"https://www2.census.gov/programs-surveys/acs/summary_file/2020/documentation/user_tools/\"\n",
        "    \"ACS_5yr_Seq_Table_Number_Lookup.txt\"\n",
        ")\n",
        "\n",
        "NY_ZIP_PATH = os.path.join(WORKDIR, \"NewYork_Tracts_Block_Groups_Only_2020.zip\")\n",
        "\n",
        "DEBUG = True\n",
        "CACHE_VERSION = \"v6_no_vehicle_seq_2020_offsetdetect_on_nyc_bg_v2\"\n",
        "\n",
        "def _cache_path():\n",
        "    key = f\"{ACS_ENDYEAR}|{TABLE_ID}|{STATE_FIPS}|{CACHE_VERSION}\"\n",
        "    h = hashlib.md5(key.encode(\"utf-8\")).hexdigest()[:10]\n",
        "    return os.path.join(WORKDIR, f\"acs{ACS_ENDYEAR}_{STATE_ABBR}_bg_{TABLE_ID}_{h}.parquet\")\n",
        "\n",
        "CACHE_PARQUET = _cache_path()\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def _log(msg: str):\n",
        "    if DEBUG:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "def normalize_nyc_counties(nyc_countyfps, state_fips=\"36\"):\n",
        "    out = set()\n",
        "    for c in nyc_countyfps:\n",
        "        s = re.sub(r\"\\D\", \"\", str(c).strip())\n",
        "        if len(s) == 3:\n",
        "            out.add(state_fips + s)\n",
        "        elif len(s) == 5:\n",
        "            out.add(s)\n",
        "        else:\n",
        "            out.add(state_fips + s[-3:].zfill(3))\n",
        "    return out\n",
        "\n",
        "NYC_COUNTIES = normalize_nyc_counties(nyc_countyfps, STATE_FIPS)\n",
        "_log(f\"NYC_COUNTIES (normalized) = {sorted(NYC_COUNTIES)}\")\n",
        "\n",
        "def clean_geoid12(x) -> str:\n",
        "    s = re.sub(r\"\\D\", \"\", str(x) if x is not None else \"\")\n",
        "    if len(s) >= 12:\n",
        "        s = s[-12:]\n",
        "    else:\n",
        "        s = s.zfill(12)\n",
        "    return s\n",
        "\n",
        "def parse_area_ratio(series: pd.Series) -> pd.Series:\n",
        "    s = series.astype(str).str.strip()\n",
        "    s = s.str.replace(\"%\", \"\", regex=False)\n",
        "    s = s.str.replace(\",\", \".\", regex=False)\n",
        "    x = pd.to_numeric(s, errors=\"coerce\").fillna(0)\n",
        "    try:\n",
        "        if float(x.quantile(0.99)) > 1.5:\n",
        "            _log(\"⚠️ area_ratio appears to be 0-100. Converting to fraction by /100.\")\n",
        "            x = x / 100.0\n",
        "    except Exception:\n",
        "        pass\n",
        "    return x.clip(lower=0, upper=1)\n",
        "\n",
        "def download_if_missing(url: str, path: str, chunk=1024 * 1024):\n",
        "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
        "        _log(f\"✅ Using cached file: {path}\")\n",
        "        return\n",
        "    _log(f\"⬇️ Downloading: {url}\")\n",
        "    with requests.get(url, stream=True, timeout=300) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(path, \"wb\") as f:\n",
        "            for part in r.iter_content(chunk_size=chunk):\n",
        "                if part:\n",
        "                    f.write(part)\n",
        "    _log(f\"✅ Saved: {path} ({os.path.getsize(path)/1e6:.1f} MB)\")\n",
        "\n",
        "def sniff_delimiter(sample: bytes) -> str:\n",
        "    text = sample.decode(\"latin-1\", errors=\"replace\")\n",
        "    candidates = [\",\", \"\\t\", \"|\"]\n",
        "    best = \",\"\n",
        "    best_cols = 0\n",
        "    first = text.splitlines()[0] if text.splitlines() else \"\"\n",
        "    for d in candidates:\n",
        "        cols = len(first.split(d)) if first else 0\n",
        "        if cols > best_cols:\n",
        "            best_cols = cols\n",
        "            best = d\n",
        "    return best\n",
        "\n",
        "def read_lookup_from_web(url: str) -> pd.DataFrame:\n",
        "    _log(f\"🌐 Fetching lookup from web: {url}\")\n",
        "    r = requests.get(url, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    raw = r.content\n",
        "    sep = sniff_delimiter(raw[:2000])\n",
        "    _log(f\"🔎 Lookup delimiter guessed as: {repr(sep)}\")\n",
        "    df = pd.read_csv(io.BytesIO(raw), sep=sep, header=None, dtype=str, encoding=\"latin-1\", engine=\"python\")\n",
        "    df = df.apply(lambda col: col.map(lambda x: x.strip() if isinstance(x, str) else x))\n",
        "    _log(f\"✅ Lookup loaded: {len(df):,} rows, {df.shape[1]} cols\")\n",
        "    return df\n",
        "\n",
        "def get_seq_startpos_cells(lookup_df: pd.DataFrame, table_id: str):\n",
        "    tt = lookup_df[lookup_df[1].astype(str).str.upper() == table_id.upper()].copy()\n",
        "    if tt.empty:\n",
        "        raise RuntimeError(f\"Table {table_id} not found in lookup.\")\n",
        "\n",
        "    header = tt[tt.apply(lambda r: r.astype(str).str.contains(\"CELLS\", case=False, na=False).any(), axis=1)]\n",
        "    if header.empty:\n",
        "        raise RuntimeError(f\"Found rows for {table_id} but none contained 'CELLS'.\")\n",
        "\n",
        "    hr = header.iloc[0].tolist()\n",
        "    seq = str(hr[2]).strip().zfill(4)\n",
        "\n",
        "    cells_idx, cells_val = None, None\n",
        "    for i, v in enumerate(hr):\n",
        "        if isinstance(v, str) and \"CELLS\" in v.upper():\n",
        "            cells_idx, cells_val = i, v\n",
        "            break\n",
        "\n",
        "    m = re.search(r\"(\\d+)\\s*CELLS\", str(cells_val), flags=re.I)\n",
        "    if not m:\n",
        "        raise RuntimeError(f\"Could not parse cells count from '{cells_val}' for {table_id}.\")\n",
        "    cells = int(m.group(1))\n",
        "\n",
        "    startpos = None\n",
        "    for j in range(cells_idx - 1, -1, -1):\n",
        "        v = hr[j]\n",
        "        if isinstance(v, str) and v.strip().isdigit():\n",
        "            startpos = int(v.strip())\n",
        "            break\n",
        "    if startpos is None:\n",
        "        raise RuntimeError(f\"Could not parse startpos for {table_id}.\")\n",
        "\n",
        "    _log(f\"✅ Lookup parse: table={table_id} seq={seq} startpos={startpos} cells={cells}\")\n",
        "    return seq, startpos, cells\n",
        "\n",
        "def get_table_line_map(lookup_df: pd.DataFrame, table_id: str) -> pd.DataFrame:\n",
        "    t = lookup_df[lookup_df[1].astype(str).str.upper() == table_id.upper()].copy()\n",
        "    t[\"line_num\"] = pd.to_numeric(t[3], errors=\"coerce\")\n",
        "\n",
        "    text_cols = [c for c in [6, 7, 8] if c in t.columns]\n",
        "    t[\"label\"] = (\n",
        "        t[text_cols]\n",
        "        .fillna(\"\")\n",
        "        .astype(str)\n",
        "        .agg(\" \".join, axis=1)\n",
        "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "\n",
        "    out = t.loc[t[\"line_num\"].notna(), [\"line_num\", \"label\"]].copy()\n",
        "    out[\"line_num\"] = out[\"line_num\"].astype(int)\n",
        "    out = out[out[\"label\"].ne(\"\")].drop_duplicates(subset=[\"line_num\"]).sort_values(\"line_num\")\n",
        "    return out\n",
        "\n",
        "def find_file_in_zip(z: zipfile.ZipFile, predicate, label=\"file\") -> str:\n",
        "    for name in z.namelist():\n",
        "        if predicate(name):\n",
        "            return name\n",
        "    raise RuntimeError(f\"No matching {label} found in zip.\")\n",
        "\n",
        "def read_csv_from_zip(z: zipfile.ZipFile, member: str, usecols=None, header=None, nrows=None) -> pd.DataFrame:\n",
        "    raw = z.read(member)\n",
        "    sep = sniff_delimiter(raw[:2000])\n",
        "    return pd.read_csv(\n",
        "        io.BytesIO(raw),\n",
        "        sep=sep,\n",
        "        header=header,\n",
        "        dtype=str,\n",
        "        encoding=\"latin-1\",\n",
        "        engine=\"python\",\n",
        "        usecols=usecols,\n",
        "        nrows=nrows,\n",
        "    )\n",
        "\n",
        "def read_geo_from_zip_auto(z: zipfile.ZipFile, member: str) -> pd.DataFrame:\n",
        "    raw = z.read(member)\n",
        "    sep = sniff_delimiter(raw[:2000])\n",
        "\n",
        "    df0 = pd.read_csv(io.BytesIO(raw), sep=sep, header=0, dtype=str, encoding=\"latin-1\", engine=\"python\")\n",
        "    cols = [str(c).strip().upper() for c in df0.columns]\n",
        "    useful = any(c in (\"GEO_ID\", \"GEOID\", \"LOGRECNO\") for c in cols) or any(\"LOGREC\" in c for c in cols)\n",
        "    if useful:\n",
        "        df0.columns = [str(c).strip() for c in df0.columns]\n",
        "        return df0\n",
        "\n",
        "    df = pd.read_csv(io.BytesIO(raw), sep=sep, header=None, dtype=str, encoding=\"latin-1\", engine=\"python\")\n",
        "    df.columns = list(range(df.shape[1]))\n",
        "    return df\n",
        "\n",
        "def build_bg_geoid_from_geofile(geo_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    g = geo_df.copy()\n",
        "\n",
        "    if not isinstance(g.columns[0], (int, np.integer)):\n",
        "        cols_upper = {str(c).strip().upper(): c for c in g.columns}\n",
        "\n",
        "        def pick(*names):\n",
        "            for n in names:\n",
        "                if n in cols_upper:\n",
        "                    return cols_upper[n]\n",
        "            return None\n",
        "\n",
        "        logrec = pick(\"LOGRECNO\") or next((cols_upper[k] for k in cols_upper if \"LOGREC\" in k), None)\n",
        "        geoid_src = pick(\"GEO_ID\", \"GEOID\")\n",
        "        if logrec is None or geoid_src is None:\n",
        "            raise RuntimeError(\"Geo: could not find LOGRECNO and GEO_ID/GEOID.\")\n",
        "\n",
        "        s = g[geoid_src].astype(str).str.strip()\n",
        "        geoid12 = s.str.extract(r\"US(36\\d{10})\", expand=False)\n",
        "\n",
        "        out = pd.DataFrame({\"LOGRECNO\": g[logrec].astype(str).str.strip(), \"GEOID\": geoid12}).dropna(subset=[\"GEOID\"])\n",
        "        out = out[out[\"GEOID\"].str.fullmatch(r\"36\\d{10}\", na=False)].drop_duplicates()\n",
        "        if out.empty:\n",
        "            raise RuntimeError(\"Geo: headered GEO_ID present, but no US36########## extracted.\")\n",
        "        return out\n",
        "\n",
        "    g.columns = list(range(g.shape[1]))\n",
        "\n",
        "    def logrec_score(col):\n",
        "        s = g[col].astype(str).str.strip()\n",
        "        return (s.str.fullmatch(r\"\\d+\").mean(), s.nunique())\n",
        "\n",
        "    scores = {c: logrec_score(c) for c in g.columns}\n",
        "    logrec_col = sorted(scores, key=lambda c: (scores[c][0], scores[c][1]), reverse=True)[0]\n",
        "\n",
        "    best_col, best_hits = None, 0\n",
        "    for c in g.columns:\n",
        "        s = g[c].astype(str).str.strip()\n",
        "        hits = s.str.contains(r\"US36\\d{10}\", regex=True, na=False).sum()\n",
        "        if hits > best_hits:\n",
        "            best_hits, best_col = hits, c\n",
        "    if best_col is None or best_hits < 100:\n",
        "        raise RuntimeError(\"Geo headerless: couldn't find US36########## column.\")\n",
        "\n",
        "    geoid12 = g[best_col].astype(str).str.strip().str.extract(r\"US(36\\d{10})\", expand=False)\n",
        "    out = pd.DataFrame({\"LOGRECNO\": g[logrec_col].astype(str).str.strip(), \"GEOID\": geoid12}).dropna(subset=[\"GEOID\"])\n",
        "    out = out[out[\"GEOID\"].str.fullmatch(r\"36\\d{10}\", na=False)].drop_duplicates()\n",
        "    if out.empty:\n",
        "        raise RuntimeError(\"Geo headerless: extracted no NY BG GEOIDs.\")\n",
        "    return out\n",
        "\n",
        "def detect_offset_on_nyc_bg(est_sample_with_logrec: pd.DataFrame,\n",
        "                           geo_key: pd.DataFrame,\n",
        "                           base_total_col: int,\n",
        "                           base_noveh_col: int,\n",
        "                           window: int = 120):\n",
        "    \"\"\"\n",
        "    Detect offset using only NYC BG rows.\n",
        "    \"\"\"\n",
        "    s = est_sample_with_logrec.copy()\n",
        "    s[\"LOGRECNO\"] = s[\"LOGRECNO\"].astype(str).str.strip()\n",
        "\n",
        "    m = geo_key.merge(s, on=\"LOGRECNO\", how=\"inner\")\n",
        "    m[\"county_prefix\"] = m[\"GEOID\"].astype(str).str[:5]\n",
        "    m = m[m[\"county_prefix\"].isin(NYC_COUNTIES)].copy()\n",
        "\n",
        "    _log(f\"🧪 Offset detect subset: merged NYC rows={len(m):,} (from sample)\")\n",
        "    if len(m) < 500:\n",
        "        _log(\"⚠️ Very few NYC rows in the estimate sample. Increase sample_n.\")\n",
        "\n",
        "    cols = [c for c in m.columns if isinstance(c, (int, np.integer))]\n",
        "    if not cols:\n",
        "        raise RuntimeError(\"Offset detect: no numeric estimate columns found in merged sample.\")\n",
        "\n",
        "    X = m[cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "\n",
        "    candidates = []\n",
        "    for off in range(-window, window + 1):\n",
        "        tc = base_total_col + off\n",
        "        nc = base_noveh_col + off\n",
        "        if tc not in X.columns or nc not in X.columns:\n",
        "            continue\n",
        "\n",
        "        total = X[tc].to_numpy()\n",
        "        noveh = X[nc].to_numpy()\n",
        "\n",
        "        total_pos = (total > 0).mean()\n",
        "        if total_pos < 0.80:\n",
        "            continue\n",
        "\n",
        "        bad = ((total > 0) & (noveh > total)).mean()\n",
        "\n",
        "        # ✅ FIX: force float out array to avoid int casting error\n",
        "        share = np.divide(\n",
        "            noveh.astype(float),\n",
        "            total.astype(float),\n",
        "            out=np.zeros_like(total, dtype=float),\n",
        "            where=total > 0\n",
        "        )\n",
        "\n",
        "        near_one = (share > 0.95).mean()\n",
        "        near_zero = (share < 0.001).mean()\n",
        "\n",
        "        score = (3.0 * total_pos) - (20.0 * bad) - (2.0 * near_one) - (0.25 * near_zero)\n",
        "        candidates.append((score, bad, total_pos, near_one, near_zero, tc, nc, off))\n",
        "\n",
        "    if not candidates:\n",
        "        raise RuntimeError(\n",
        "            \"Offset detect (NYC-only): no viable candidates met total_pos>=0.80. \"\n",
        "            \"Increase sample_n/window or inspect estimate columns.\"\n",
        "        )\n",
        "\n",
        "    candidates.sort(reverse=True, key=lambda x: x[0])\n",
        "    top = candidates[:10]\n",
        "\n",
        "    _log(\"✅ Offset detect (NYC-only): top candidates (score, bad, total_pos, near_one, near_zero, total_col, noveh_col, offset):\")\n",
        "    for i, row in enumerate(top, 1):\n",
        "        score, bad, total_pos, near_one, near_zero, tc, nc, off = row\n",
        "        _log(f\"  {i}. score={score:.4f}, bad={bad:.4%}, total_pos={total_pos:.2%}, \"\n",
        "             f\"near_one={near_one:.2%}, near_zero={near_zero:.2%}, Tcol={tc}, NVcol={nc}, off={off:+d}\")\n",
        "\n",
        "    best = top[0]\n",
        "    _, _, _, _, _, tc, nc, off = best\n",
        "    _log(f\"🏁 Selected columns (NYC-only): total_col={tc} (offset {off:+d}), no_vehicle_col={nc}\")\n",
        "    return tc, nc, off\n",
        "\n",
        "# =========================================================\n",
        "# 0) Load from cache or build BG extract\n",
        "# =========================================================\n",
        "download_if_missing(NY_ZIP_URL, NY_ZIP_PATH)\n",
        "\n",
        "# If you want a hard reset for THIS version:\n",
        "# if os.path.exists(CACHE_PARQUET): os.remove(CACHE_PARQUET)\n",
        "\n",
        "if os.path.exists(CACHE_PARQUET):\n",
        "    _log(f\"✅ Loading cached extract: {CACHE_PARQUET}\")\n",
        "    bg = pd.read_parquet(CACHE_PARQUET)\n",
        "\n",
        "else:\n",
        "    lookup = read_lookup_from_web(LOOKUP_URL)\n",
        "    seq4, startpos, cells = get_seq_startpos_cells(lookup, TABLE_ID)\n",
        "\n",
        "    line_map = get_table_line_map(lookup, TABLE_ID)\n",
        "    _log(\"🧾 B08201 line labels (first 60):\")\n",
        "    _log(line_map.head(60).to_string(index=False))\n",
        "\n",
        "    _log(f\"✅ Using fixed lines: total line={LINE_TOTAL}, no-vehicle line={LINE_NO_VEH}\")\n",
        "\n",
        "    ID_COLS_ASSUMED = 6\n",
        "    cell_total = startpos + (LINE_TOTAL - 1)\n",
        "    cell_noveh = startpos + (LINE_NO_VEH - 1)\n",
        "\n",
        "    base_total_col = ID_COLS_ASSUMED + (cell_total - 1)\n",
        "    base_noveh_col = ID_COLS_ASSUMED + (cell_noveh - 1)\n",
        "\n",
        "    _log(f\"📌 Base columns (pre-offset): line{LINE_TOTAL}->cell{cell_total} base_col{base_total_col}, \"\n",
        "         f\"line{LINE_NO_VEH}->cell{cell_noveh} base_col{base_noveh_col}\")\n",
        "\n",
        "    with zipfile.ZipFile(NY_ZIP_PATH, \"r\") as z:\n",
        "        geo_member = find_file_in_zip(\n",
        "            z,\n",
        "            lambda n: re.search(r\"(^|/)(g).*\" + STATE_ABBR + r\".*\\.(csv|txt)$\", n, flags=re.I) is not None,\n",
        "            label=\"geography file\",\n",
        "        )\n",
        "        _log(f\"🗺️ Geography member: {geo_member}\")\n",
        "\n",
        "        est_member = find_file_in_zip(\n",
        "            z,\n",
        "            lambda n: (\n",
        "                re.search(r\"(^|/)(e).*\" + STATE_ABBR + r\".*\\.(csv|txt)$\", n, flags=re.I) is not None\n",
        "                and seq4 in os.path.basename(n)\n",
        "            ),\n",
        "            label=\"estimate sequence file\",\n",
        "        )\n",
        "        _log(f\"📄 Estimate member: {est_member}\")\n",
        "\n",
        "        _log(\"📥 Reading geography file (can take a bit)...\")\n",
        "        geo_df = read_geo_from_zip_auto(z, geo_member)\n",
        "        geo_key = build_bg_geoid_from_geofile(geo_df)\n",
        "        _log(f\"✅ Geography BG rows: {len(geo_key):,}\")\n",
        "\n",
        "        sample_n = 60000\n",
        "        LOGREC_COL = 5\n",
        "\n",
        "        # read nearly all cols (as you did) + LOGRECNO for robust detection\n",
        "        usecols_sample = [LOGREC_COL] + list(range(0, 202))\n",
        "        _log(f\"🧪 Reading estimate sample (n={sample_n:,}) with cols [0..201] plus LOGRECNO for NYC-only offset detection...\")\n",
        "        est_sample = read_csv_from_zip(z, est_member, usecols=usecols_sample, header=None, nrows=sample_n)\n",
        "        est_sample = est_sample.rename(columns={LOGREC_COL: \"LOGRECNO\"})\n",
        "\n",
        "        total_col, noveh_col, offset = detect_offset_on_nyc_bg(\n",
        "            est_sample_with_logrec=est_sample,\n",
        "            geo_key=geo_key,\n",
        "            base_total_col=base_total_col,\n",
        "            base_noveh_col=base_noveh_col,\n",
        "            window=120,\n",
        "        )\n",
        "\n",
        "        usecols_final = sorted(set([LOGREC_COL, total_col, noveh_col]))\n",
        "        _log(f\"📥 Reading FINAL estimate columns: {usecols_final}\")\n",
        "        est_df = read_csv_from_zip(z, est_member, usecols=usecols_final, header=None)\n",
        "\n",
        "        est_df = est_df.rename(columns={\n",
        "            LOGREC_COL: \"LOGRECNO\",\n",
        "            total_col: \"hh_total_raw\",\n",
        "            noveh_col: \"hh_no_vehicle_raw\",\n",
        "        })\n",
        "        est_df[\"LOGRECNO\"] = est_df[\"LOGRECNO\"].astype(str).str.strip()\n",
        "\n",
        "        _log(\"🔬 Raw estimate sample (LOGRECNO, total, no_vehicle):\")\n",
        "        _log(est_df[[\"LOGRECNO\", \"hh_total_raw\", \"hh_no_vehicle_raw\"]].head(10).to_string(index=False))\n",
        "\n",
        "    merged = geo_key.merge(est_df, on=\"LOGRECNO\", how=\"inner\")\n",
        "    _log(f\"✅ Joined rows: {len(merged):,}\")\n",
        "\n",
        "    merged[\"county_prefix\"] = merged[\"GEOID\"].astype(str).str[:5]\n",
        "    merged = merged[merged[\"county_prefix\"].isin(NYC_COUNTIES)].copy()\n",
        "    _log(f\"✅ NYC BG rows retained: {len(merged):,}\")\n",
        "\n",
        "    merged[\"hh_total\"] = pd.to_numeric(merged[\"hh_total_raw\"], errors=\"coerce\").fillna(0)\n",
        "    merged[\"hh_no_vehicle\"] = pd.to_numeric(merged[\"hh_no_vehicle_raw\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "    _log(f\"QA: BG total>0 share = {(merged['hh_total'] > 0).mean():.3%}\")\n",
        "    bad_share = ((merged[\"hh_total\"] > 0) & (merged[\"hh_no_vehicle\"] > merged[\"hh_total\"])).mean()\n",
        "    _log(f\"QA: BG no_vehicle > total share = {bad_share:.3%}\")\n",
        "\n",
        "    if (merged[\"hh_total\"] > 0).mean() < 0.80:\n",
        "        raise RuntimeError(\"Totals not present for most NYC BGs — still wrong columns. Check top candidates output.\")\n",
        "\n",
        "    bg = merged[[\"GEOID\", \"hh_total\", \"hh_no_vehicle\"]].copy()\n",
        "    bg[\"GEOID\"] = bg[\"GEOID\"].map(clean_geoid12)\n",
        "\n",
        "    bg.to_parquet(CACHE_PARQUET, index=False)\n",
        "    _log(f\"💾 Cached extracted table to: {CACHE_PARQUET}\")\n",
        "\n",
        "# =========================================================\n",
        "# Area-weight into station buffers\n",
        "# =========================================================\n",
        "detail = station_bg_detail.copy()\n",
        "detail[\"GEOID\"] = detail[\"GEOID\"].map(clean_geoid12)\n",
        "detail[\"area_ratio\"] = parse_area_ratio(detail[\"area_ratio\"])\n",
        "\n",
        "bg = bg.copy()\n",
        "bg[\"GEOID\"] = bg[\"GEOID\"].map(clean_geoid12)\n",
        "\n",
        "detail = detail.merge(bg, on=\"GEOID\", how=\"left\")\n",
        "_log(f\"✅ Merge match rate (rows with hh_total): {detail['hh_total'].notna().mean():.2%}\")\n",
        "\n",
        "detail[[\"hh_total\", \"hh_no_vehicle\"]] = detail[[\"hh_total\", \"hh_no_vehicle\"]].fillna(0)\n",
        "\n",
        "detail[\"hh_total_within\"] = detail[\"hh_total\"] * detail[\"area_ratio\"]\n",
        "detail[\"hh_no_vehicle_within\"] = detail[\"hh_no_vehicle\"] * detail[\"area_ratio\"]\n",
        "\n",
        "agg = detail.groupby([\"stop_id\", \"stop_name\"], as_index=False)[[\"hh_total_within\", \"hh_no_vehicle_within\"]].sum()\n",
        "\n",
        "agg[OUT_COL] = np.where(\n",
        "    agg[\"hh_total_within\"] > 0,\n",
        "    100.0 * agg[\"hh_no_vehicle_within\"] / agg[\"hh_total_within\"],\n",
        "    np.nan,\n",
        ")\n",
        "\n",
        "_log(f\"🧪 Station-level {OUT_COL} summary:\")\n",
        "print(agg[OUT_COL].describe(percentiles=[.01, .05, .1, .25, .5, .75, .9, .95, .99]))\n",
        "\n",
        "if OUT_COL in station_buffers.columns:\n",
        "    station_buffers = station_buffers.drop(columns=[OUT_COL])\n",
        "\n",
        "station_buffers = station_buffers.merge(\n",
        "    agg[[\"stop_id\", \"stop_name\", OUT_COL]],\n",
        "    on=[\"stop_id\", \"stop_name\"],\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "_log(\"✅ Variable 6 complete.\")\n",
        "display(station_buffers[[\"stop_id\", \"stop_name\", OUT_COL]].head())\n",
        "print(\"✅ Variable 6 output column:\", OUT_COL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ACKNb3esu49i",
        "outputId": "95ae0e37-3c01-4f94-8aba-be8f43b1d969"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NYC_COUNTIES (normalized) = ['36005', '36047', '36061', '36081', '36085']\n",
            "⬇️ Downloading: https://www2.census.gov/programs-surveys/acs/summary_file/2020/data/5_year_by_state/NewYork_Tracts_Block_Groups_Only.zip\n",
            "✅ Saved: ./acs_sf_cache/NewYork_Tracts_Block_Groups_Only_2020.zip (278.7 MB)\n",
            "🌐 Fetching lookup from web: https://www2.census.gov/programs-surveys/acs/summary_file/2020/documentation/user_tools/ACS_5yr_Seq_Table_Number_Lookup.txt\n",
            "🔎 Lookup delimiter guessed as: ','\n",
            "✅ Lookup loaded: 30,327 rows, 9 cols\n",
            "✅ Lookup parse: table=B08201 seq=0027 startpos=75 cells=30\n",
            "🧾 B08201 line labels (first 60):\n",
            " line_num                        label\n",
            "        1                       Total:\n",
            "        2         No vehicle available\n",
            "        3          1 vehicle available\n",
            "        4         2 vehicles available\n",
            "        5         3 vehicles available\n",
            "        6 4 or more vehicles available\n",
            "        7          1-person household:\n",
            "        8         No vehicle available\n",
            "        9          1 vehicle available\n",
            "       10         2 vehicles available\n",
            "       11         3 vehicles available\n",
            "       12 4 or more vehicles available\n",
            "       13          2-person household:\n",
            "       14         No vehicle available\n",
            "       15          1 vehicle available\n",
            "       16         2 vehicles available\n",
            "       17         3 vehicles available\n",
            "       18 4 or more vehicles available\n",
            "       19          3-person household:\n",
            "       20         No vehicle available\n",
            "       21          1 vehicle available\n",
            "       22         2 vehicles available\n",
            "       23         3 vehicles available\n",
            "       24 4 or more vehicles available\n",
            "       25  4-or-more-person household:\n",
            "       26         No vehicle available\n",
            "       27          1 vehicle available\n",
            "       28         2 vehicles available\n",
            "       29         3 vehicles available\n",
            "       30 4 or more vehicles available\n",
            "✅ Using fixed lines: total line=1, no-vehicle line=2\n",
            "📌 Base columns (pre-offset): line1->cell75 base_col80, line2->cell76 base_col81\n",
            "🗺️ Geography member: g20205ny.csv\n",
            "📄 Estimate member: e20205ny0027000.txt\n",
            "📥 Reading geography file (can take a bit)...\n",
            "✅ Geography BG rows: 18,534\n",
            "🧪 Reading estimate sample (n=60,000) with cols [0..201] plus LOGRECNO for NYC-only offset detection...\n",
            "🧪 Offset detect subset: merged NYC rows=6,807 (from sample)\n",
            "✅ Offset detect (NYC-only): top candidates (score, bad, total_pos, near_one, near_zero, total_col, noveh_col, offset):\n",
            "  1. score=2.7729, bad=0.0000%, total_pos=93.52%, near_one=0.15%, near_zero=11.93%, Tcol=156, NVcol=157, off=+76\n",
            "  2. score=2.7500, bad=0.0000%, total_pos=100.00%, near_one=0.00%, near_zero=100.00%, Tcol=1, NVcol=2, off=-79\n",
            "  3. score=2.7004, bad=0.0000%, total_pos=92.99%, near_one=1.56%, near_zero=23.28%, Tcol=165, NVcol=166, off=+85\n",
            "  4. score=2.6739, bad=0.0000%, total_pos=93.48%, near_one=0.04%, near_zero=51.80%, Tcol=177, NVcol=178, off=+97\n",
            "  5. score=2.6100, bad=0.0000%, total_pos=93.48%, near_one=0.00%, near_zero=77.74%, Tcol=192, NVcol=193, off=+112\n",
            "  6. score=2.2283, bad=1.3369%, total_pos=90.27%, near_one=1.47%, near_zero=73.29%, Tcol=167, NVcol=168, off=+87\n",
            "  7. score=1.9408, bad=0.0000%, total_pos=88.07%, near_one=33.32%, near_zero=13.99%, Tcol=157, NVcol=158, off=+77\n",
            "  8. score=1.2558, bad=5.6853%, total_pos=88.07%, near_one=6.38%, near_zero=48.71%, Tcol=199, NVcol=200, off=+119\n",
            "  9. score=1.2456, bad=5.5237%, total_pos=86.01%, near_one=6.16%, near_zero=42.81%, Tcol=158, NVcol=159, off=+78\n",
            "  10. score=-0.4854, bad=12.7369%, total_pos=81.67%, near_one=13.82%, near_zero=44.62%, Tcol=187, NVcol=188, off=+107\n",
            "🏁 Selected columns (NYC-only): total_col=156 (offset +76), no_vehicle_col=157\n",
            "📥 Reading FINAL estimate columns: [5, 156, 157]\n",
            "🔬 Raw estimate sample (LOGRECNO, total, no_vehicle):\n",
            "LOGRECNO hh_total_raw hh_no_vehicle_raw\n",
            " 0003507          852               763\n",
            " 0003508         1861               958\n",
            " 0003509          896               585\n",
            " 0003510         1377               806\n",
            " 0003511         1517              1268\n",
            " 0003512         1117              1044\n",
            " 0003513         2359              1835\n",
            " 0003514         1443               557\n",
            " 0003515         1572              1111\n",
            " 0003516         1802              1148\n",
            "✅ Joined rows: 16,070\n",
            "✅ NYC BG rows retained: 6,807\n",
            "QA: BG total>0 share = 93.521%\n",
            "QA: BG no_vehicle > total share = 0.000%\n",
            "💾 Cached extracted table to: ./acs_sf_cache/acs2020_ny_bg_B08201_1775e4be41.parquet\n",
            "✅ Merge match rate (rows with hh_total): 100.00%\n",
            "🧪 Station-level pct_hh_no_vehicle_0p5mi summary:\n",
            "count    518.000000\n",
            "mean      19.557715\n",
            "std       15.146954\n",
            "min        2.578677\n",
            "1%         3.590410\n",
            "5%         4.098777\n",
            "10%        5.236279\n",
            "25%        7.612493\n",
            "50%       16.416586\n",
            "75%       26.956734\n",
            "90%       37.767665\n",
            "95%       48.948558\n",
            "99%       73.111740\n",
            "max       82.388483\n",
            "Name: pct_hh_no_vehicle_0p5mi, dtype: float64\n",
            "✅ Variable 6 complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  pct_hh_no_vehicle_0p5mi\n",
              "0     101  Van Cortlandt Park-242 St                34.697480\n",
              "1     103                     238 St                30.753513\n",
              "2     104                     231 St                25.197863\n",
              "3     106         Marble Hill-225 St                20.724292\n",
              "4     107                     215 St                14.853057"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb87a31b-eae4-4896-b110-48ba8f8b9b00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>pct_hh_no_vehicle_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>34.697480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>30.753513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>25.197863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>20.724292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>14.853057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb87a31b-eae4-4896-b110-48ba8f8b9b00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb87a31b-eae4-4896-b110-48ba8f8b9b00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb87a31b-eae4-4896-b110-48ba8f8b9b00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\u2705 Variable 6 output column:\\\", OUT_COL)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_hh_no_vehicle_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.875985584701369,\n        \"min\": 14.853057045106967,\n        \"max\": 34.69748032750188,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          30.753512873904583,\n          14.853057045106967,\n          25.19786326155431\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Variable 6 output column: pct_hh_no_vehicle_0p5mi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 6 (DETERMINISTIC + NYC-BG OFFSET-DETECTED): % Households with No Vehicle (0.5 mile)\n",
        "# Data source: ACS 2020 5-year Summary File (SEQUENCE-BASED), NY Tracts+Block Groups only\n",
        "#\n",
        "# Output: station_buffers[\"pct_hh_no_vehicle_0p5mi\"]\n",
        "#\n",
        "# Requires (inputs already in your notebook):\n",
        "# - station_bg_detail: GEOID (12), area_ratio, stop_id, stop_name\n",
        "# - station_buffers: stop_id, stop_name\n",
        "# - nyc_countyfps: either [\"005\",\"047\",\"061\",\"081\",\"085\"] OR [\"36005\",\"36047\",\"36061\",\"36081\",\"36085\"]\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import zipfile\n",
        "import hashlib\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "ACS_ENDYEAR = 2020\n",
        "STATE_FIPS = \"36\"\n",
        "STATE_ABBR = \"ny\"\n",
        "\n",
        "TABLE_ID = \"B08201\"\n",
        "LINE_TOTAL = 1\n",
        "LINE_NO_VEH = 2  # top-level \"No vehicle available\"\n",
        "OUT_COL = \"pct_hh_no_vehicle_0p5mi\"\n",
        "\n",
        "WORKDIR = \"./acs_sf_cache\"\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "NY_ZIP_URL = (\n",
        "    \"https://www2.census.gov/programs-surveys/acs/summary_file/2020/data/5_year_by_state/\"\n",
        "    \"NewYork_Tracts_Block_Groups_Only.zip\"\n",
        ")\n",
        "LOOKUP_URL = (\n",
        "    \"https://www2.census.gov/programs-surveys/acs/summary_file/2020/documentation/user_tools/\"\n",
        "    \"ACS_5yr_Seq_Table_Number_Lookup.txt\"\n",
        ")\n",
        "\n",
        "NY_ZIP_PATH = os.path.join(WORKDIR, \"NewYork_Tracts_Block_Groups_Only_2020.zip\")\n",
        "\n",
        "DEBUG = True\n",
        "CACHE_VERSION = \"v6_no_vehicle_seq_2020_offsetdetect_on_nyc_bg_clean_v1\"\n",
        "\n",
        "def _cache_path():\n",
        "    key = f\"{ACS_ENDYEAR}|{TABLE_ID}|{STATE_FIPS}|{CACHE_VERSION}\"\n",
        "    h = hashlib.md5(key.encode(\"utf-8\")).hexdigest()[:10]\n",
        "    return os.path.join(WORKDIR, f\"acs{ACS_ENDYEAR}_{STATE_ABBR}_bg_{TABLE_ID}_{h}.parquet\")\n",
        "\n",
        "CACHE_PARQUET = _cache_path()\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def _log(msg: str):\n",
        "    if DEBUG:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "def normalize_nyc_counties(nyc_countyfps, state_fips=\"36\"):\n",
        "    out = set()\n",
        "    for c in nyc_countyfps:\n",
        "        s = re.sub(r\"\\D\", \"\", str(c).strip())\n",
        "        if len(s) == 3:\n",
        "            out.add(state_fips + s)\n",
        "        elif len(s) == 5:\n",
        "            out.add(s)\n",
        "        else:\n",
        "            out.add(state_fips + s[-3:].zfill(3))\n",
        "    return out\n",
        "\n",
        "NYC_COUNTIES = normalize_nyc_counties(nyc_countyfps, STATE_FIPS)\n",
        "_log(f\"NYC_COUNTIES (normalized) = {sorted(NYC_COUNTIES)}\")\n",
        "\n",
        "def clean_geoid12(x) -> str:\n",
        "    s = re.sub(r\"\\D\", \"\", str(x) if x is not None else \"\")\n",
        "    if len(s) >= 12:\n",
        "        s = s[-12:]\n",
        "    else:\n",
        "        s = s.zfill(12)\n",
        "    return s\n",
        "\n",
        "def parse_area_ratio(series: pd.Series) -> pd.Series:\n",
        "    s = series.astype(str).str.strip()\n",
        "    s = s.str.replace(\"%\", \"\", regex=False)\n",
        "    s = s.str.replace(\",\", \".\", regex=False)\n",
        "    x = pd.to_numeric(s, errors=\"coerce\").fillna(0)\n",
        "    # if looks like 0..100, convert to 0..1\n",
        "    try:\n",
        "        if float(x.quantile(0.99)) > 1.5:\n",
        "            _log(\"⚠️ area_ratio appears to be 0-100. Converting to fraction by /100.\")\n",
        "            x = x / 100.0\n",
        "    except Exception:\n",
        "        pass\n",
        "    return x.clip(lower=0, upper=1)\n",
        "\n",
        "def download_if_missing(url: str, path: str, chunk=1024 * 1024):\n",
        "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
        "        _log(f\"✅ Using cached file: {path}\")\n",
        "        return\n",
        "    _log(f\"⬇️ Downloading: {url}\")\n",
        "    with requests.get(url, stream=True, timeout=300) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(path, \"wb\") as f:\n",
        "            for part in r.iter_content(chunk_size=chunk):\n",
        "                if part:\n",
        "                    f.write(part)\n",
        "    _log(f\"✅ Saved: {path} ({os.path.getsize(path)/1e6:.1f} MB)\")\n",
        "\n",
        "def sniff_delimiter(sample: bytes) -> str:\n",
        "    text = sample.decode(\"latin-1\", errors=\"replace\")\n",
        "    candidates = [\",\", \"\\t\", \"|\"]\n",
        "    best = \",\"\n",
        "    best_cols = 0\n",
        "    first = text.splitlines()[0] if text.splitlines() else \"\"\n",
        "    for d in candidates:\n",
        "        cols = len(first.split(d)) if first else 0\n",
        "        if cols > best_cols:\n",
        "            best_cols = cols\n",
        "            best = d\n",
        "    return best\n",
        "\n",
        "def read_lookup_from_web(url: str) -> pd.DataFrame:\n",
        "    _log(f\"🌐 Fetching lookup from web: {url}\")\n",
        "    r = requests.get(url, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    raw = r.content\n",
        "    sep = sniff_delimiter(raw[:2000])\n",
        "    _log(f\"🔎 Lookup delimiter guessed as: {repr(sep)}\")\n",
        "    df = pd.read_csv(io.BytesIO(raw), sep=sep, header=None, dtype=str, encoding=\"latin-1\", engine=\"python\")\n",
        "    df = df.apply(lambda col: col.map(lambda x: x.strip() if isinstance(x, str) else x))\n",
        "    _log(f\"✅ Lookup loaded: {len(df):,} rows, {df.shape[1]} cols\")\n",
        "    return df\n",
        "\n",
        "def get_seq_startpos_cells(lookup_df: pd.DataFrame, table_id: str):\n",
        "    tt = lookup_df[lookup_df[1].astype(str).str.upper() == table_id.upper()].copy()\n",
        "    if tt.empty:\n",
        "        raise RuntimeError(f\"Table {table_id} not found in lookup.\")\n",
        "\n",
        "    header = tt[tt.apply(lambda r: r.astype(str).str.contains(\"CELLS\", case=False, na=False).any(), axis=1)]\n",
        "    if header.empty:\n",
        "        raise RuntimeError(f\"Found rows for {table_id} but none contained 'CELLS'.\")\n",
        "\n",
        "    hr = header.iloc[0].tolist()\n",
        "    seq = str(hr[2]).strip().zfill(4)\n",
        "\n",
        "    cells_idx, cells_val = None, None\n",
        "    for i, v in enumerate(hr):\n",
        "        if isinstance(v, str) and \"CELLS\" in v.upper():\n",
        "            cells_idx, cells_val = i, v\n",
        "            break\n",
        "\n",
        "    m = re.search(r\"(\\d+)\\s*CELLS\", str(cells_val), flags=re.I)\n",
        "    if not m:\n",
        "        raise RuntimeError(f\"Could not parse cells count from '{cells_val}' for {table_id}.\")\n",
        "    cells = int(m.group(1))\n",
        "\n",
        "    startpos = None\n",
        "    for j in range(cells_idx - 1, -1, -1):\n",
        "        v = hr[j]\n",
        "        if isinstance(v, str) and v.strip().isdigit():\n",
        "            startpos = int(v.strip())\n",
        "            break\n",
        "    if startpos is None:\n",
        "        raise RuntimeError(f\"Could not parse startpos for {table_id}.\")\n",
        "\n",
        "    _log(f\"✅ Lookup parse: table={table_id} seq={seq} startpos={startpos} cells={cells}\")\n",
        "    return seq, startpos, cells\n",
        "\n",
        "def get_table_line_map(lookup_df: pd.DataFrame, table_id: str) -> pd.DataFrame:\n",
        "    t = lookup_df[lookup_df[1].astype(str).str.upper() == table_id.upper()].copy()\n",
        "    t[\"line_num\"] = pd.to_numeric(t[3], errors=\"coerce\")\n",
        "\n",
        "    text_cols = [c for c in [6, 7, 8] if c in t.columns]\n",
        "    t[\"label\"] = (\n",
        "        t[text_cols]\n",
        "        .fillna(\"\")\n",
        "        .astype(str)\n",
        "        .agg(\" \".join, axis=1)\n",
        "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "\n",
        "    out = t.loc[t[\"line_num\"].notna(), [\"line_num\", \"label\"]].copy()\n",
        "    out[\"line_num\"] = out[\"line_num\"].astype(int)\n",
        "    out = out[out[\"label\"].ne(\"\")].drop_duplicates(subset=[\"line_num\"]).sort_values(\"line_num\")\n",
        "    return out\n",
        "\n",
        "def find_file_in_zip(z: zipfile.ZipFile, predicate, label=\"file\") -> str:\n",
        "    for name in z.namelist():\n",
        "        if predicate(name):\n",
        "            return name\n",
        "    raise RuntimeError(f\"No matching {label} found in zip.\")\n",
        "\n",
        "def read_csv_from_zip(z: zipfile.ZipFile, member: str, usecols=None, header=None, nrows=None) -> pd.DataFrame:\n",
        "    raw = z.read(member)\n",
        "    sep = sniff_delimiter(raw[:2000])\n",
        "    return pd.read_csv(\n",
        "        io.BytesIO(raw),\n",
        "        sep=sep,\n",
        "        header=header,\n",
        "        dtype=str,\n",
        "        encoding=\"latin-1\",\n",
        "        engine=\"python\",\n",
        "        usecols=usecols,\n",
        "        nrows=nrows,\n",
        "    )\n",
        "\n",
        "def read_geo_from_zip_auto(z: zipfile.ZipFile, member: str) -> pd.DataFrame:\n",
        "    raw = z.read(member)\n",
        "    sep = sniff_delimiter(raw[:2000])\n",
        "\n",
        "    df0 = pd.read_csv(io.BytesIO(raw), sep=sep, header=0, dtype=str, encoding=\"latin-1\", engine=\"python\")\n",
        "    cols = [str(c).strip().upper() for c in df0.columns]\n",
        "    useful = any(c in (\"GEO_ID\", \"GEOID\", \"LOGRECNO\") for c in cols) or any(\"LOGREC\" in c for c in cols)\n",
        "    if useful:\n",
        "        df0.columns = [str(c).strip() for c in df0.columns]\n",
        "        return df0\n",
        "\n",
        "    df = pd.read_csv(io.BytesIO(raw), sep=sep, header=None, dtype=str, encoding=\"latin-1\", engine=\"python\")\n",
        "    df.columns = list(range(df.shape[1]))\n",
        "    return df\n",
        "\n",
        "def build_bg_geoid_from_geofile(geo_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    g = geo_df.copy()\n",
        "\n",
        "    # headered\n",
        "    if not isinstance(g.columns[0], (int, np.integer)):\n",
        "        cols_upper = {str(c).strip().upper(): c for c in g.columns}\n",
        "\n",
        "        def pick(*names):\n",
        "            for n in names:\n",
        "                if n in cols_upper:\n",
        "                    return cols_upper[n]\n",
        "            return None\n",
        "\n",
        "        logrec = pick(\"LOGRECNO\") or next((cols_upper[k] for k in cols_upper if \"LOGREC\" in k), None)\n",
        "        geoid_src = pick(\"GEO_ID\", \"GEOID\")\n",
        "        if logrec is None or geoid_src is None:\n",
        "            raise RuntimeError(\"Geo: could not find LOGRECNO and GEO_ID/GEOID.\")\n",
        "\n",
        "        s = g[geoid_src].astype(str).str.strip()\n",
        "        geoid12 = s.str.extract(r\"US(36\\d{10})\", expand=False)\n",
        "        out = pd.DataFrame({\"LOGRECNO\": g[logrec].astype(str).str.strip(), \"GEOID\": geoid12}).dropna(subset=[\"GEOID\"])\n",
        "        out = out[out[\"GEOID\"].str.fullmatch(r\"36\\d{10}\", na=False)].drop_duplicates()\n",
        "        if out.empty:\n",
        "            raise RuntimeError(\"Geo: headered GEO_ID present, but no US36########## extracted.\")\n",
        "        return out\n",
        "\n",
        "    # headerless\n",
        "    g.columns = list(range(g.shape[1]))\n",
        "\n",
        "    def logrec_score(col):\n",
        "        s = g[col].astype(str).str.strip()\n",
        "        return (s.str.fullmatch(r\"\\d+\").mean(), s.nunique())\n",
        "\n",
        "    scores = {c: logrec_score(c) for c in g.columns}\n",
        "    logrec_col = sorted(scores, key=lambda c: (scores[c][0], scores[c][1]), reverse=True)[0]\n",
        "\n",
        "    best_col, best_hits = None, 0\n",
        "    for c in g.columns:\n",
        "        s = g[c].astype(str).str.strip()\n",
        "        hits = s.str.contains(r\"US36\\d{10}\", regex=True, na=False).sum()\n",
        "        if hits > best_hits:\n",
        "            best_hits, best_col = hits, c\n",
        "    if best_col is None or best_hits < 100:\n",
        "        raise RuntimeError(\"Geo headerless: couldn't find US36########## column.\")\n",
        "\n",
        "    geoid12 = g[best_col].astype(str).str.strip().str.extract(r\"US(36\\d{10})\", expand=False)\n",
        "    out = pd.DataFrame({\"LOGRECNO\": g[logrec_col].astype(str).str.strip(), \"GEOID\": geoid12}).dropna(subset=[\"GEOID\"])\n",
        "    out = out[out[\"GEOID\"].str.fullmatch(r\"36\\d{10}\", na=False)].drop_duplicates()\n",
        "    if out.empty:\n",
        "        raise RuntimeError(\"Geo headerless: extracted no NY BG GEOIDs.\")\n",
        "    return out\n",
        "\n",
        "def detect_offset_on_nyc_bg(est_sample_with_logrec: pd.DataFrame,\n",
        "                           geo_key: pd.DataFrame,\n",
        "                           base_total_col: int,\n",
        "                           base_noveh_col: int,\n",
        "                           window: int = 120):\n",
        "    \"\"\"\n",
        "    Detect offset using only NYC BG rows.\n",
        "    \"\"\"\n",
        "    s = est_sample_with_logrec.copy()\n",
        "    s[\"LOGRECNO\"] = s[\"LOGRECNO\"].astype(str).str.strip()\n",
        "\n",
        "    m = geo_key.merge(s, on=\"LOGRECNO\", how=\"inner\")\n",
        "    m[\"county_prefix\"] = m[\"GEOID\"].astype(str).str[:5]\n",
        "    m = m[m[\"county_prefix\"].isin(NYC_COUNTIES)].copy()\n",
        "\n",
        "    _log(f\"🧪 Offset detect subset: merged NYC rows={len(m):,} (from sample)\")\n",
        "    if len(m) < 500:\n",
        "        _log(\"⚠️ Very few NYC rows in the estimate sample. Increase sample_n.\")\n",
        "\n",
        "    cols = [c for c in m.columns if isinstance(c, (int, np.integer))]\n",
        "    if not cols:\n",
        "        raise RuntimeError(\"Offset detect: no numeric estimate columns found in merged sample.\")\n",
        "\n",
        "    X = m[cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "\n",
        "    candidates = []\n",
        "    for off in range(-window, window + 1):\n",
        "        tc = base_total_col + off\n",
        "        nc = base_noveh_col + off\n",
        "        if tc not in X.columns or nc not in X.columns:\n",
        "            continue\n",
        "\n",
        "        total = X[tc].to_numpy()\n",
        "        noveh = X[nc].to_numpy()\n",
        "\n",
        "        total_pos = (total > 0).mean()\n",
        "        if total_pos < 0.80:\n",
        "            continue\n",
        "\n",
        "        bad = ((total > 0) & (noveh > total)).mean()\n",
        "\n",
        "        share = np.divide(\n",
        "            noveh.astype(float),\n",
        "            total.astype(float),\n",
        "            out=np.zeros_like(total, dtype=float),\n",
        "            where=total > 0\n",
        "        )\n",
        "\n",
        "        near_one = (share > 0.95).mean()\n",
        "        near_zero = (share < 0.001).mean()\n",
        "\n",
        "        score = (3.0 * total_pos) - (20.0 * bad) - (2.0 * near_one) - (0.25 * near_zero)\n",
        "        candidates.append((score, bad, total_pos, near_one, near_zero, tc, nc, off))\n",
        "\n",
        "    if not candidates:\n",
        "        raise RuntimeError(\n",
        "            \"Offset detect (NYC-only): no viable candidates met total_pos>=0.80. \"\n",
        "            \"Increase sample_n/window or inspect estimate columns.\"\n",
        "        )\n",
        "\n",
        "    candidates.sort(reverse=True, key=lambda x: x[0])\n",
        "    top = candidates[:10]\n",
        "\n",
        "    _log(\"✅ Offset detect (NYC-only): top candidates (score, bad, total_pos, near_one, near_zero, total_col, noveh_col, offset):\")\n",
        "    for i, row in enumerate(top, 1):\n",
        "        score, bad, total_pos, near_one, near_zero, tc, nc, off = row\n",
        "        _log(f\"  {i}. score={score:.4f}, bad={bad:.4%}, total_pos={total_pos:.2%}, \"\n",
        "             f\"near_one={near_one:.2%}, near_zero={near_zero:.2%}, Tcol={tc}, NVcol={nc}, off={off:+d}\")\n",
        "\n",
        "    best = top[0]\n",
        "    _, _, _, _, _, tc, nc, off = best\n",
        "    _log(f\"🏁 Selected columns (NYC-only): total_col={tc} (offset {off:+d}), no_vehicle_col={nc}\")\n",
        "    return tc, nc, off\n",
        "\n",
        "# =========================================================\n",
        "# 0) Load from cache or build BG extract\n",
        "# =========================================================\n",
        "download_if_missing(NY_ZIP_URL, NY_ZIP_PATH)\n",
        "\n",
        "# Hard reset for THIS version if you want:\n",
        "# if os.path.exists(CACHE_PARQUET):\n",
        "#     os.remove(CACHE_PARQUET)\n",
        "\n",
        "if os.path.exists(CACHE_PARQUET):\n",
        "    _log(f\"✅ Loading cached extract: {CACHE_PARQUET}\")\n",
        "    bg = pd.read_parquet(CACHE_PARQUET)\n",
        "\n",
        "else:\n",
        "    lookup = read_lookup_from_web(LOOKUP_URL)\n",
        "    seq4, startpos, cells = get_seq_startpos_cells(lookup, TABLE_ID)\n",
        "\n",
        "    line_map = get_table_line_map(lookup, TABLE_ID)\n",
        "    _log(\"🧾 B08201 line labels (first 60):\")\n",
        "    _log(line_map.head(60).to_string(index=False))\n",
        "\n",
        "    _log(f\"✅ Using fixed lines: total line={LINE_TOTAL}, no-vehicle line={LINE_NO_VEH}\")\n",
        "\n",
        "    ID_COLS_ASSUMED = 6\n",
        "    cell_total = startpos + (LINE_TOTAL - 1)\n",
        "    cell_noveh = startpos + (LINE_NO_VEH - 1)\n",
        "\n",
        "    base_total_col = ID_COLS_ASSUMED + (cell_total - 1)\n",
        "    base_noveh_col = ID_COLS_ASSUMED + (cell_noveh - 1)\n",
        "\n",
        "    _log(f\"📌 Base columns (pre-offset): line{LINE_TOTAL}->cell{cell_total} base_col{base_total_col}, \"\n",
        "         f\"line{LINE_NO_VEH}->cell{cell_noveh} base_col{base_noveh_col}\")\n",
        "\n",
        "    with zipfile.ZipFile(NY_ZIP_PATH, \"r\") as z:\n",
        "        geo_member = find_file_in_zip(\n",
        "            z,\n",
        "            lambda n: re.search(r\"(^|/)(g).*\" + STATE_ABBR + r\".*\\.(csv|txt)$\", n, flags=re.I) is not None,\n",
        "            label=\"geography file\",\n",
        "        )\n",
        "        _log(f\"🗺️ Geography member: {geo_member}\")\n",
        "\n",
        "        est_member = find_file_in_zip(\n",
        "            z,\n",
        "            lambda n: (\n",
        "                re.search(r\"(^|/)(e).*\" + STATE_ABBR + r\".*\\.(csv|txt)$\", n, flags=re.I) is not None\n",
        "                and seq4 in os.path.basename(n)\n",
        "            ),\n",
        "            label=\"estimate sequence file\",\n",
        "        )\n",
        "        _log(f\"📄 Estimate member: {est_member}\")\n",
        "\n",
        "        _log(\"📥 Reading geography file (can take a bit)...\")\n",
        "        geo_df = read_geo_from_zip_auto(z, geo_member)\n",
        "        geo_key = build_bg_geoid_from_geofile(geo_df)\n",
        "        _log(f\"✅ Geography BG rows: {len(geo_key):,}\")\n",
        "\n",
        "        # --- dynamic scan width (robust across files) ---\n",
        "        # read 1 row full-width to learn number of columns\n",
        "        one = read_csv_from_zip(z, est_member, usecols=None, header=None, nrows=1)\n",
        "        ncols = one.shape[1]\n",
        "        scan_max = min(ncols, 260)  # scan first 260 columns or fewer if file smaller\n",
        "\n",
        "        sample_n = 60000\n",
        "        LOGREC_COL = 5\n",
        "        usecols_sample = [LOGREC_COL] + list(range(0, scan_max))\n",
        "\n",
        "        _log(f\"🧪 Reading estimate sample (n={sample_n:,}) with cols [0..{scan_max-1}] plus LOGRECNO for NYC-only offset detection...\")\n",
        "        est_sample = read_csv_from_zip(z, est_member, usecols=usecols_sample, header=None, nrows=sample_n)\n",
        "        est_sample = est_sample.rename(columns={LOGREC_COL: \"LOGRECNO\"})\n",
        "\n",
        "        total_col, noveh_col, offset = detect_offset_on_nyc_bg(\n",
        "            est_sample_with_logrec=est_sample,\n",
        "            geo_key=geo_key,\n",
        "            base_total_col=base_total_col,\n",
        "            base_noveh_col=base_noveh_col,\n",
        "            window=120,\n",
        "        )\n",
        "\n",
        "        usecols_final = sorted(set([LOGREC_COL, total_col, noveh_col]))\n",
        "        _log(f\"📥 Reading FINAL estimate columns: {usecols_final}\")\n",
        "        est_df = read_csv_from_zip(z, est_member, usecols=usecols_final, header=None)\n",
        "\n",
        "        est_df = est_df.rename(columns={\n",
        "            LOGREC_COL: \"LOGRECNO\",\n",
        "            total_col: \"hh_total_raw\",\n",
        "            noveh_col: \"hh_no_vehicle_raw\",\n",
        "        })\n",
        "        est_df[\"LOGRECNO\"] = est_df[\"LOGRECNO\"].astype(str).str.strip()\n",
        "\n",
        "        _log(\"🔬 Raw estimate sample (LOGRECNO, total, no_vehicle):\")\n",
        "        _log(est_df[[\"LOGRECNO\", \"hh_total_raw\", \"hh_no_vehicle_raw\"]].head(10).to_string(index=False))\n",
        "\n",
        "    merged = geo_key.merge(est_df, on=\"LOGRECNO\", how=\"inner\")\n",
        "    _log(f\"✅ Joined rows: {len(merged):,}\")\n",
        "\n",
        "    merged[\"county_prefix\"] = merged[\"GEOID\"].astype(str).str[:5]\n",
        "    merged = merged[merged[\"county_prefix\"].isin(NYC_COUNTIES)].copy()\n",
        "    _log(f\"✅ NYC BG rows retained: {len(merged):,}\")\n",
        "\n",
        "    merged[\"hh_total\"] = pd.to_numeric(merged[\"hh_total_raw\"], errors=\"coerce\").fillna(0)\n",
        "    merged[\"hh_no_vehicle\"] = pd.to_numeric(merged[\"hh_no_vehicle_raw\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "    total_pos_share = (merged[\"hh_total\"] > 0).mean()\n",
        "    _log(f\"QA: BG total>0 share = {total_pos_share:.3%}\")\n",
        "\n",
        "    bad_share = ((merged[\"hh_total\"] > 0) & (merged[\"hh_no_vehicle\"] > merged[\"hh_total\"])).mean()\n",
        "    _log(f\"QA: BG no_vehicle > total share = {bad_share:.3%}\")\n",
        "\n",
        "    if total_pos_share < 0.80:\n",
        "        raise RuntimeError(\"Totals not present for most NYC BGs — still wrong columns. Check top candidates output.\")\n",
        "\n",
        "    # --- extra sanity: BG no-vehicle share distribution ---\n",
        "    p_bg = np.where(merged[\"hh_total\"] > 0, 100.0 * merged[\"hh_no_vehicle\"] / merged[\"hh_total\"], np.nan)\n",
        "    med = float(np.nanmedian(p_bg))\n",
        "    p90 = float(np.nanpercentile(p_bg, 90))\n",
        "    _log(f\"QA: BG pct no-vehicle median={med:.2f}%, p90={p90:.2f}%\")\n",
        "    if not (1.0 <= med <= 70.0):\n",
        "        _log(\"⚠️ QA WARNING: median BG no-vehicle share looks unusual. Verify selected columns / inputs.\")\n",
        "\n",
        "    bg = merged[[\"GEOID\", \"hh_total\", \"hh_no_vehicle\"]].copy()\n",
        "    bg[\"GEOID\"] = bg[\"GEOID\"].map(clean_geoid12)\n",
        "\n",
        "    bg.to_parquet(CACHE_PARQUET, index=False)\n",
        "    _log(f\"💾 Cached extracted table to: {CACHE_PARQUET}\")\n",
        "\n",
        "# =========================================================\n",
        "# Area-weight into station buffers\n",
        "# =========================================================\n",
        "detail = station_bg_detail.copy()\n",
        "detail[\"GEOID\"] = detail[\"GEOID\"].map(clean_geoid12)\n",
        "detail[\"area_ratio\"] = parse_area_ratio(detail[\"area_ratio\"])\n",
        "\n",
        "bg = bg.copy()\n",
        "bg[\"GEOID\"] = bg[\"GEOID\"].map(clean_geoid12)\n",
        "\n",
        "detail = detail.merge(bg, on=\"GEOID\", how=\"left\")\n",
        "_log(f\"✅ Merge match rate (rows with hh_total): {detail['hh_total'].notna().mean():.2%}\")\n",
        "\n",
        "detail[[\"hh_total\", \"hh_no_vehicle\"]] = detail[[\"hh_total\", \"hh_no_vehicle\"]].fillna(0)\n",
        "\n",
        "detail[\"hh_total_within\"] = detail[\"hh_total\"] * detail[\"area_ratio\"]\n",
        "detail[\"hh_no_vehicle_within\"] = detail[\"hh_no_vehicle\"] * detail[\"area_ratio\"]\n",
        "\n",
        "agg = detail.groupby([\"stop_id\", \"stop_name\"], as_index=False)[[\"hh_total_within\", \"hh_no_vehicle_within\"]].sum()\n",
        "\n",
        "agg[OUT_COL] = np.where(\n",
        "    agg[\"hh_total_within\"] > 0,\n",
        "    100.0 * agg[\"hh_no_vehicle_within\"] / agg[\"hh_total_within\"],\n",
        "    np.nan,\n",
        ")\n",
        "\n",
        "_log(f\"🧪 Station-level {OUT_COL} summary:\")\n",
        "print(agg[OUT_COL].describe(percentiles=[.01, .05, .1, .25, .5, .75, .9, .95, .99]))\n",
        "\n",
        "if OUT_COL in station_buffers.columns:\n",
        "    station_buffers = station_buffers.drop(columns=[OUT_COL])\n",
        "\n",
        "station_buffers = station_buffers.merge(\n",
        "    agg[[\"stop_id\", \"stop_name\", OUT_COL]],\n",
        "    on=[\"stop_id\", \"stop_name\"],\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "_log(\"✅ Variable 6 complete.\")\n",
        "display(station_buffers[[\"stop_id\", \"stop_name\", OUT_COL]].head())\n",
        "print(\"✅ Variable 6 output column:\", OUT_COL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BpoYuxX5z-Xj",
        "outputId": "b5111054-8064-4a77-c7a6-1242cf6be8a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NYC_COUNTIES (normalized) = ['36005', '36047', '36061', '36081', '36085']\n",
            "✅ Using cached file: ./acs_sf_cache/NewYork_Tracts_Block_Groups_Only_2020.zip\n",
            "🌐 Fetching lookup from web: https://www2.census.gov/programs-surveys/acs/summary_file/2020/documentation/user_tools/ACS_5yr_Seq_Table_Number_Lookup.txt\n",
            "🔎 Lookup delimiter guessed as: ','\n",
            "✅ Lookup loaded: 30,327 rows, 9 cols\n",
            "✅ Lookup parse: table=B08201 seq=0027 startpos=75 cells=30\n",
            "🧾 B08201 line labels (first 60):\n",
            " line_num                        label\n",
            "        1                       Total:\n",
            "        2         No vehicle available\n",
            "        3          1 vehicle available\n",
            "        4         2 vehicles available\n",
            "        5         3 vehicles available\n",
            "        6 4 or more vehicles available\n",
            "        7          1-person household:\n",
            "        8         No vehicle available\n",
            "        9          1 vehicle available\n",
            "       10         2 vehicles available\n",
            "       11         3 vehicles available\n",
            "       12 4 or more vehicles available\n",
            "       13          2-person household:\n",
            "       14         No vehicle available\n",
            "       15          1 vehicle available\n",
            "       16         2 vehicles available\n",
            "       17         3 vehicles available\n",
            "       18 4 or more vehicles available\n",
            "       19          3-person household:\n",
            "       20         No vehicle available\n",
            "       21          1 vehicle available\n",
            "       22         2 vehicles available\n",
            "       23         3 vehicles available\n",
            "       24 4 or more vehicles available\n",
            "       25  4-or-more-person household:\n",
            "       26         No vehicle available\n",
            "       27          1 vehicle available\n",
            "       28         2 vehicles available\n",
            "       29         3 vehicles available\n",
            "       30 4 or more vehicles available\n",
            "✅ Using fixed lines: total line=1, no-vehicle line=2\n",
            "📌 Base columns (pre-offset): line1->cell75 base_col80, line2->cell76 base_col81\n",
            "🗺️ Geography member: g20205ny.csv\n",
            "📄 Estimate member: e20205ny0027000.txt\n",
            "📥 Reading geography file (can take a bit)...\n",
            "✅ Geography BG rows: 18,534\n",
            "🧪 Reading estimate sample (n=60,000) with cols [0..204] plus LOGRECNO for NYC-only offset detection...\n",
            "🧪 Offset detect subset: merged NYC rows=6,807 (from sample)\n",
            "✅ Offset detect (NYC-only): top candidates (score, bad, total_pos, near_one, near_zero, total_col, noveh_col, offset):\n",
            "  1. score=2.7729, bad=0.0000%, total_pos=93.52%, near_one=0.15%, near_zero=11.93%, Tcol=156, NVcol=157, off=+76\n",
            "  2. score=2.7500, bad=0.0000%, total_pos=100.00%, near_one=0.00%, near_zero=100.00%, Tcol=1, NVcol=2, off=-79\n",
            "  3. score=2.7004, bad=0.0000%, total_pos=92.99%, near_one=1.56%, near_zero=23.28%, Tcol=165, NVcol=166, off=+85\n",
            "  4. score=2.6739, bad=0.0000%, total_pos=93.48%, near_one=0.04%, near_zero=51.80%, Tcol=177, NVcol=178, off=+97\n",
            "  5. score=2.6100, bad=0.0000%, total_pos=93.48%, near_one=0.00%, near_zero=77.74%, Tcol=192, NVcol=193, off=+112\n",
            "  6. score=2.2283, bad=1.3369%, total_pos=90.27%, near_one=1.47%, near_zero=73.29%, Tcol=167, NVcol=168, off=+87\n",
            "  7. score=1.9408, bad=0.0000%, total_pos=88.07%, near_one=33.32%, near_zero=13.99%, Tcol=157, NVcol=158, off=+77\n",
            "  8. score=1.2558, bad=5.6853%, total_pos=88.07%, near_one=6.38%, near_zero=48.71%, Tcol=199, NVcol=200, off=+119\n",
            "  9. score=1.2456, bad=5.5237%, total_pos=86.01%, near_one=6.16%, near_zero=42.81%, Tcol=158, NVcol=159, off=+78\n",
            "  10. score=-0.4854, bad=12.7369%, total_pos=81.67%, near_one=13.82%, near_zero=44.62%, Tcol=187, NVcol=188, off=+107\n",
            "🏁 Selected columns (NYC-only): total_col=156 (offset +76), no_vehicle_col=157\n",
            "📥 Reading FINAL estimate columns: [5, 156, 157]\n",
            "🔬 Raw estimate sample (LOGRECNO, total, no_vehicle):\n",
            "LOGRECNO hh_total_raw hh_no_vehicle_raw\n",
            " 0003507          852               763\n",
            " 0003508         1861               958\n",
            " 0003509          896               585\n",
            " 0003510         1377               806\n",
            " 0003511         1517              1268\n",
            " 0003512         1117              1044\n",
            " 0003513         2359              1835\n",
            " 0003514         1443               557\n",
            " 0003515         1572              1111\n",
            " 0003516         1802              1148\n",
            "✅ Joined rows: 16,070\n",
            "✅ NYC BG rows retained: 6,807\n",
            "QA: BG total>0 share = 93.521%\n",
            "QA: BG no_vehicle > total share = 0.000%\n",
            "QA: BG pct no-vehicle median=23.30%, p90=60.36%\n",
            "💾 Cached extracted table to: ./acs_sf_cache/acs2020_ny_bg_B08201_ed6cfd21b2.parquet\n",
            "✅ Merge match rate (rows with hh_total): 100.00%\n",
            "🧪 Station-level pct_hh_no_vehicle_0p5mi summary:\n",
            "count    518.000000\n",
            "mean      19.557715\n",
            "std       15.146954\n",
            "min        2.578677\n",
            "1%         3.590410\n",
            "5%         4.098777\n",
            "10%        5.236279\n",
            "25%        7.612493\n",
            "50%       16.416586\n",
            "75%       26.956734\n",
            "90%       37.767665\n",
            "95%       48.948558\n",
            "99%       73.111740\n",
            "max       82.388483\n",
            "Name: pct_hh_no_vehicle_0p5mi, dtype: float64\n",
            "✅ Variable 6 complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  pct_hh_no_vehicle_0p5mi\n",
              "0     101  Van Cortlandt Park-242 St                34.697480\n",
              "1     103                     238 St                30.753513\n",
              "2     104                     231 St                25.197863\n",
              "3     106         Marble Hill-225 St                20.724292\n",
              "4     107                     215 St                14.853057"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f10c341-3679-4c23-a4aa-cdc03010aa25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>pct_hh_no_vehicle_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>34.697480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>30.753513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>25.197863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>20.724292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>14.853057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f10c341-3679-4c23-a4aa-cdc03010aa25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f10c341-3679-4c23-a4aa-cdc03010aa25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f10c341-3679-4c23-a4aa-cdc03010aa25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\u2705 Variable 6 output column:\\\", OUT_COL)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_hh_no_vehicle_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.875985584701369,\n        \"min\": 14.853057045106967,\n        \"max\": 34.69748032750188,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          30.753512873904583,\n          14.853057045106967,\n          25.19786326155431\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Variable 6 output column: pct_hh_no_vehicle_0p5mi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 7 (CAPSTONE-READY, DETERMINISTIC): Station-level commute mode shares (0.5 mile)\n",
        "# Data source: ACS 2019 5-year Summary File (SEQUENCE-BASED), NY Tracts+Block Groups only\n",
        "#\n",
        "# Keeps ONLY the capstone-useful, non-redundant features (7 columns):\n",
        "#   1) pct_transit_0p5mi\n",
        "#   2) pct_car_truck_van_0p5mi\n",
        "#   3) pct_walked_0p5mi\n",
        "#   4) pct_bicycle_0p5mi\n",
        "#   5) pct_wfh_0p5mi\n",
        "#   6) pct_taxicab_0p5mi\n",
        "#   7) pct_other_means_0p5mi\n",
        "#\n",
        "# Why this subset:\n",
        "# - Interpretable and stable\n",
        "# - Avoids parent/child redundancy (no bus/subway breakdown; no carpool breakdown)\n",
        "# - Captures broad mode split + WFH sanity anchor\n",
        "#\n",
        "# Requires:\n",
        "# - station_bg_detail: GEOID (12), area_ratio, stop_id, stop_name\n",
        "# - station_buffers: stop_id, stop_name\n",
        "# - nyc_countyfps: either [\"005\",\"047\",\"061\",\"081\",\"085\"] OR [\"36005\",\"36047\",\"36061\",\"36081\",\"36085\"]\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import zipfile\n",
        "import hashlib\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "ACS_ENDYEAR = 2019\n",
        "STATE_FIPS = \"36\"\n",
        "STATE_ABBR = \"ny\"\n",
        "\n",
        "TABLE_ID = \"B08301\"\n",
        "CELLS_EXPECTED = 21\n",
        "\n",
        "WORKDIR = \"./acs_sf_cache\"\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "NY_ZIP_URL = (\n",
        "    \"https://www2.census.gov/programs-surveys/acs/summary_file/2019/data/5_year_by_state/\"\n",
        "    \"NewYork_Tracts_Block_Groups_Only.zip\"\n",
        ")\n",
        "LOOKUP_URL = (\n",
        "    \"https://www2.census.gov/programs-surveys/acs/summary_file/2019/documentation/user_tools/\"\n",
        "    \"ACS_5yr_Seq_Table_Number_Lookup.txt\"\n",
        ")\n",
        "\n",
        "NY_ZIP_PATH = os.path.join(WORKDIR, \"NewYork_Tracts_Block_Groups_Only_2019.zip\")\n",
        "\n",
        "DEBUG = True\n",
        "CACHE_VERSION = \"v8_capstone_subset_b08301_block\"\n",
        "def _cache_path():\n",
        "    key = f\"{ACS_ENDYEAR}|{TABLE_ID}|{STATE_FIPS}|{CACHE_VERSION}\"\n",
        "    h = hashlib.md5(key.encode(\"utf-8\")).hexdigest()[:10]\n",
        "    return os.path.join(WORKDIR, f\"acs{ACS_ENDYEAR}_{STATE_ABBR}_bg_{TABLE_ID}_{h}.parquet\")\n",
        "\n",
        "CACHE_PARQUET = _cache_path()\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def _log(msg: str):\n",
        "    if DEBUG:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "def normalize_nyc_counties(nyc_countyfps, state_fips=\"36\"):\n",
        "    out = set()\n",
        "    for c in nyc_countyfps:\n",
        "        s = re.sub(r\"\\D\", \"\", str(c).strip())\n",
        "        if len(s) == 3:\n",
        "            out.add(state_fips + s)\n",
        "        elif len(s) == 5:\n",
        "            out.add(s)\n",
        "        else:\n",
        "            out.add(state_fips + s[-3:].zfill(3))\n",
        "    return out\n",
        "\n",
        "NYC_COUNTIES = normalize_nyc_counties(nyc_countyfps, STATE_FIPS)\n",
        "_log(f\"NYC_COUNTIES (normalized) = {sorted(NYC_COUNTIES)}\")\n",
        "\n",
        "def download_if_missing(url: str, path: str, chunk=1024 * 1024):\n",
        "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
        "        _log(f\"✅ Using cached file: {path}\")\n",
        "        return\n",
        "    _log(f\"⬇️ Downloading: {url}\")\n",
        "    with requests.get(url, stream=True, timeout=300) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(path, \"wb\") as f:\n",
        "            for part in r.iter_content(chunk_size=chunk):\n",
        "                if part:\n",
        "                    f.write(part)\n",
        "    _log(f\"✅ Saved: {path} ({os.path.getsize(path)/1e6:.1f} MB)\")\n",
        "\n",
        "def sniff_delimiter(sample: bytes) -> str:\n",
        "    text = sample.decode(\"latin-1\", errors=\"replace\")\n",
        "    candidates = [\",\", \"\\t\", \"|\"]\n",
        "    best = \",\"\n",
        "    best_cols = 0\n",
        "    first = text.splitlines()[0] if text.splitlines() else \"\"\n",
        "    for d in candidates:\n",
        "        cols = len(first.split(d)) if first else 0\n",
        "        if cols > best_cols:\n",
        "            best_cols = cols\n",
        "            best = d\n",
        "    return best\n",
        "\n",
        "def read_lookup_from_web(url: str) -> pd.DataFrame:\n",
        "    _log(f\"🌐 Fetching lookup from web: {url}\")\n",
        "    r = requests.get(url, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    raw = r.content\n",
        "    sep = sniff_delimiter(raw[:2000])\n",
        "    _log(f\"🔎 Lookup delimiter guessed as: {repr(sep)}\")\n",
        "    df = pd.read_csv(io.BytesIO(raw), sep=sep, header=None, dtype=str, encoding=\"latin-1\", engine=\"python\")\n",
        "    df = df.apply(lambda col: col.map(lambda x: x.strip() if isinstance(x, str) else x))\n",
        "    _log(f\"✅ Lookup loaded: {len(df):,} rows, {df.shape[1]} cols\")\n",
        "    return df\n",
        "\n",
        "def get_seq_startpos_cells(lookup_df: pd.DataFrame, table_id: str):\n",
        "    tt = lookup_df[lookup_df[1].astype(str).str.upper() == table_id.upper()].copy()\n",
        "    if tt.empty:\n",
        "        raise RuntimeError(f\"Table {table_id} not found in lookup.\")\n",
        "\n",
        "    header = tt[tt.apply(lambda r: r.astype(str).str.contains(\"CELLS\", case=False, na=False).any(), axis=1)]\n",
        "    if header.empty:\n",
        "        preview = tt.head(10).to_string(index=False)\n",
        "        raise RuntimeError(f\"Found rows for {table_id} but none contained 'CELLS'. Preview:\\n{preview}\")\n",
        "\n",
        "    hr = header.iloc[0].tolist()\n",
        "    seq = str(hr[2]).strip().zfill(4)\n",
        "\n",
        "    cells_idx, cells_val = None, None\n",
        "    for i, v in enumerate(hr):\n",
        "        if isinstance(v, str) and \"CELLS\" in v.upper():\n",
        "            cells_idx, cells_val = i, v\n",
        "            break\n",
        "\n",
        "    m = re.search(r\"(\\d+)\\s*CELLS\", str(cells_val), flags=re.I)\n",
        "    if not m:\n",
        "        raise RuntimeError(f\"Could not parse cells count from '{cells_val}' for {table_id}.\")\n",
        "    cells = int(m.group(1))\n",
        "\n",
        "    startpos = None\n",
        "    for j in range(cells_idx - 1, -1, -1):\n",
        "        v = hr[j]\n",
        "        if isinstance(v, str) and v.strip().isdigit():\n",
        "            startpos = int(v.strip())\n",
        "            break\n",
        "    if startpos is None:\n",
        "        raise RuntimeError(f\"Could not parse startpos for {table_id} from header row: {hr}\")\n",
        "\n",
        "    _log(f\"✅ Lookup parse: table={table_id} seq={seq} startpos={startpos} cells={cells}\")\n",
        "    return seq, startpos, cells\n",
        "\n",
        "def read_csv_from_zip(z: zipfile.ZipFile, member: str, usecols=None, header=None, nrows=None) -> pd.DataFrame:\n",
        "    raw = z.read(member)\n",
        "    sep = sniff_delimiter(raw[:2000])\n",
        "    return pd.read_csv(\n",
        "        io.BytesIO(raw),\n",
        "        sep=sep,\n",
        "        header=header,\n",
        "        dtype=str,\n",
        "        encoding=\"latin-1\",\n",
        "        engine=\"python\",\n",
        "        usecols=usecols,\n",
        "        nrows=nrows\n",
        "    )\n",
        "\n",
        "def find_file_in_zip(z: zipfile.ZipFile, predicate, label=\"file\") -> str:\n",
        "    for name in z.namelist():\n",
        "        if predicate(name):\n",
        "            return name\n",
        "    raise RuntimeError(f\"No matching {label} found in zip.\")\n",
        "\n",
        "def read_geo_from_zip_auto(z: zipfile.ZipFile, member: str) -> pd.DataFrame:\n",
        "    raw = z.read(member)\n",
        "    sep = sniff_delimiter(raw[:2000])\n",
        "\n",
        "    df0 = pd.read_csv(io.BytesIO(raw), sep=sep, header=0, dtype=str, encoding=\"latin-1\", engine=\"python\")\n",
        "    cols = [str(c).strip().upper() for c in df0.columns]\n",
        "    useful = any(c in (\"GEO_ID\", \"GEOID\", \"LOGRECNO\") for c in cols) or any(\"LOGREC\" in c for c in cols)\n",
        "    if useful:\n",
        "        df0.columns = [str(c).strip() for c in df0.columns]\n",
        "        return df0\n",
        "\n",
        "    df = pd.read_csv(io.BytesIO(raw), sep=sep, header=None, dtype=str, encoding=\"latin-1\", engine=\"python\")\n",
        "    df.columns = list(range(df.shape[1]))\n",
        "    return df\n",
        "\n",
        "def build_bg_geoid_from_geofile(geo_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    g = geo_df.copy()\n",
        "\n",
        "    if not isinstance(g.columns[0], (int, np.integer)):\n",
        "        cols_upper = {str(c).strip().upper(): c for c in g.columns}\n",
        "\n",
        "        def pick(*names):\n",
        "            for n in names:\n",
        "                if n in cols_upper:\n",
        "                    return cols_upper[n]\n",
        "            return None\n",
        "\n",
        "        logrec = pick(\"LOGRECNO\") or next((cols_upper[k] for k in cols_upper if \"LOGREC\" in k), None)\n",
        "        if logrec is None:\n",
        "            raise RuntimeError(\"Geo: could not find LOGRECNO-like column.\")\n",
        "\n",
        "        geoid_src = pick(\"GEO_ID\", \"GEOID\")\n",
        "        if geoid_src is None:\n",
        "            raise RuntimeError(\"Geo: could not find GEO_ID/GEOID column.\")\n",
        "\n",
        "        s = g[geoid_src].astype(str).str.strip()\n",
        "        geoid12 = s.str.extract(r\"US(36\\d{10})\", expand=False)\n",
        "\n",
        "        out = pd.DataFrame({\"LOGRECNO\": g[logrec].astype(str).str.strip(), \"GEOID\": geoid12}).dropna(subset=[\"GEOID\"])\n",
        "        out = out[out[\"GEOID\"].str.fullmatch(r\"36\\d{10}\", na=False)].drop_duplicates()\n",
        "        if out.empty:\n",
        "            raise RuntimeError(\"Geo: couldn't extract any US36##########.\")\n",
        "        return out\n",
        "\n",
        "    g.columns = list(range(g.shape[1]))\n",
        "    def logrec_score(col):\n",
        "        s = g[col].astype(str).str.strip()\n",
        "        return (s.str.fullmatch(r\"\\d+\").mean(), s.nunique())\n",
        "    scores = {c: logrec_score(c) for c in g.columns}\n",
        "    logrec_col = sorted(scores, key=lambda c: (scores[c][0], scores[c][1]), reverse=True)[0]\n",
        "\n",
        "    best_col, best_hits = None, 0\n",
        "    for c in g.columns:\n",
        "        s = g[c].astype(str).str.strip()\n",
        "        hits = s.str.contains(r\"US36\\d{10}\", regex=True, na=False).sum()\n",
        "        if hits > best_hits:\n",
        "            best_hits, best_col = hits, c\n",
        "\n",
        "    if best_col is None or best_hits < 100:\n",
        "        raise RuntimeError(\"Geo headerless: couldn't find a US36########## column.\")\n",
        "\n",
        "    geoid12 = g[best_col].astype(str).str.strip().str.extract(r\"US(36\\d{10})\", expand=False)\n",
        "    out = pd.DataFrame({\"LOGRECNO\": g[logrec_col].astype(str).str.strip(), \"GEOID\": geoid12}).dropna(subset=[\"GEOID\"])\n",
        "    out = out[out[\"GEOID\"].str.fullmatch(r\"36\\d{10}\", na=False)].drop_duplicates()\n",
        "    if out.empty:\n",
        "        raise RuntimeError(\"Geo headerless: extraction produced no NY BG GEOIDs.\")\n",
        "    return out\n",
        "\n",
        "def detect_b08301_block_start(df_sample: pd.DataFrame, cells: int = 21) -> int:\n",
        "    X = df_sample.apply(pd.to_numeric, errors=\"coerce\").fillna(0).to_numpy()\n",
        "    _, ncols = X.shape\n",
        "\n",
        "    # within-block indices (0-based)\n",
        "    i_total = 0\n",
        "    i_car = 1\n",
        "    i_transit = 9\n",
        "    i_taxicab = 15\n",
        "    i_bike = 17\n",
        "    i_walk = 18\n",
        "    i_other = 19\n",
        "    i_wfh = 20\n",
        "    i_moto = 16  # not used in identity? include it to be safe\n",
        "    # identity uses motorcycle too\n",
        "    best_s, best_score = None, -1.0\n",
        "\n",
        "    for s in range(0, ncols - cells + 1):\n",
        "        block = X[:, s : s + cells]\n",
        "        total = block[:, i_total]\n",
        "        if (total > 0).mean() < 0.30:\n",
        "            continue\n",
        "\n",
        "        rhs = (\n",
        "            block[:, i_car]\n",
        "            + block[:, i_transit]\n",
        "            + block[:, i_taxicab]\n",
        "            + block[:, i_moto]\n",
        "            + block[:, i_bike]\n",
        "            + block[:, i_walk]\n",
        "            + block[:, i_other]\n",
        "            + block[:, i_wfh]\n",
        "        )\n",
        "\n",
        "        match = ((total == rhs) & (total > 0)).mean()\n",
        "        share_transit = np.divide(block[:, i_transit], total, out=np.zeros_like(total), where=total > 0)\n",
        "        near_one = (share_transit > 0.90).mean()\n",
        "        score = match - 0.25 * near_one\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_s = s\n",
        "\n",
        "    if best_s is None or best_score < 0.50:\n",
        "        raise RuntimeError(f\"Could not reliably detect B08301 block. Best score={best_score:.3f}.\")\n",
        "    _log(f\"✅ Detected B08301 block start column = {best_s} (score={best_score:.3f})\")\n",
        "    return best_s\n",
        "\n",
        "# -----------------------------\n",
        "# Capstone subset: lines to keep\n",
        "# -----------------------------\n",
        "# B08301 lines:\n",
        "#  2 car/truck/van\n",
        "# 10 public transportation (excluding taxicab)\n",
        "# 16 taxicab\n",
        "# 18 bicycle\n",
        "# 19 walked\n",
        "# 20 other means\n",
        "# 21 worked from home\n",
        "KEEP_LINES = {\n",
        "    2:  \"pct_car_truck_van_0p5mi\",\n",
        "    10: \"pct_transit_0p5mi\",\n",
        "    16: \"pct_taxicab_0p5mi\",\n",
        "    18: \"pct_bicycle_0p5mi\",\n",
        "    19: \"pct_walked_0p5mi\",\n",
        "    20: \"pct_other_means_0p5mi\",\n",
        "    21: \"pct_wfh_0p5mi\",\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "download_if_missing(NY_ZIP_URL, NY_ZIP_PATH)\n",
        "\n",
        "if os.path.exists(CACHE_PARQUET):\n",
        "    _log(f\"✅ Loading cached extract: {CACHE_PARQUET}\")\n",
        "    mode_bg = pd.read_parquet(CACHE_PARQUET)\n",
        "\n",
        "else:\n",
        "    lookup = read_lookup_from_web(LOOKUP_URL)\n",
        "    seq4, startpos, cells = get_seq_startpos_cells(lookup, TABLE_ID)\n",
        "    if cells != CELLS_EXPECTED:\n",
        "        _log(f\"⚠️ Lookup cells={cells} (expected {CELLS_EXPECTED}). Proceeding with lookup value.\")\n",
        "\n",
        "    with zipfile.ZipFile(NY_ZIP_PATH, \"r\") as z:\n",
        "        geo_member = find_file_in_zip(\n",
        "            z,\n",
        "            lambda n: re.search(r\"(^|/)(g).*\" + STATE_ABBR + r\".*\\.(csv|txt)$\", n, flags=re.I) is not None,\n",
        "            label=\"geography file\"\n",
        "        )\n",
        "        _log(f\"🗺️ Geography member: {geo_member}\")\n",
        "\n",
        "        est_member = find_file_in_zip(\n",
        "            z,\n",
        "            lambda n: (\n",
        "                re.search(r\"(^|/)(e).*\" + STATE_ABBR + r\".*\\.(csv|txt)$\", n, flags=re.I) is not None\n",
        "                and seq4 in os.path.basename(n)\n",
        "            ),\n",
        "            label=\"estimate sequence file\"\n",
        "        )\n",
        "        _log(f\"📄 Estimate member: {est_member}\")\n",
        "\n",
        "        sample_n = 12000\n",
        "        _log(f\"🧪 Reading estimate sample (first {sample_n} rows) to detect B08301 block...\")\n",
        "        est_sample = read_csv_from_zip(z, est_member, usecols=None, header=None, nrows=sample_n)\n",
        "        _log(f\"🧪 Sample shape: {est_sample.shape[0]:,} rows x {est_sample.shape[1]} cols\")\n",
        "\n",
        "        block_start = detect_b08301_block_start(est_sample, cells=cells)\n",
        "\n",
        "        LOGREC_COL = 5\n",
        "        table_cols = list(range(block_start, block_start + cells))\n",
        "        usecols = sorted(set([LOGREC_COL] + table_cols))\n",
        "        _log(f\"📥 Reading LOGRECNO + {cells} table columns with usecols (min={min(usecols)}, max={max(usecols)})\")\n",
        "\n",
        "        try:\n",
        "            est_df = read_csv_from_zip(z, est_member, usecols=usecols, header=None)\n",
        "        except Exception as e:\n",
        "            _log(f\"⚠️ usecols failed ({type(e).__name__}: {e}). Falling back to full read then slice.\")\n",
        "            full = read_csv_from_zip(z, est_member, usecols=None, header=None)\n",
        "            est_df = full.iloc[:, usecols].copy()\n",
        "\n",
        "        # rename columns -> LOGRECNO + line_01..line_21\n",
        "        col_map = {}\n",
        "        for c in est_df.columns:\n",
        "            if c == LOGREC_COL:\n",
        "                col_map[c] = \"LOGRECNO\"\n",
        "            else:\n",
        "                line_num = (c - block_start) + 1\n",
        "                col_map[c] = f\"line_{line_num:02d}\"\n",
        "        est_df = est_df.rename(columns=col_map)\n",
        "        est_df[\"LOGRECNO\"] = est_df[\"LOGRECNO\"].astype(str).str.strip()\n",
        "\n",
        "        _log(\"🔬 Raw estimate sample (LOGRECNO, Total, Transit, WFH):\")\n",
        "        _log(est_df[[\"LOGRECNO\", \"line_01\", \"line_10\", \"line_21\"]].head(8).to_string(index=False))\n",
        "\n",
        "        _log(\"📥 Reading geography file (can take a bit)...\")\n",
        "        geo_df = read_geo_from_zip_auto(z, geo_member)\n",
        "        geo_key = build_bg_geoid_from_geofile(geo_df)\n",
        "        _log(f\"✅ Geography BG rows: {len(geo_key):,}\")\n",
        "\n",
        "    merged = geo_key.merge(est_df, on=\"LOGRECNO\", how=\"inner\")\n",
        "    _log(f\"✅ Joined rows: {len(merged):,}\")\n",
        "\n",
        "    merged[\"county_prefix\"] = merged[\"GEOID\"].str[:5]\n",
        "    _log(\"🔎 Top county_prefix counts (before NYC filter):\")\n",
        "    _log(merged[\"county_prefix\"].value_counts().head(15).to_string())\n",
        "\n",
        "    merged = merged[merged[\"county_prefix\"].isin(NYC_COUNTIES)].copy()\n",
        "    _log(f\"✅ NYC BG rows retained: {len(merged):,}\")\n",
        "\n",
        "    # Convert needed lines only\n",
        "    needed_line_cols = [\"line_01\"] + [f\"line_{ln:02d}\" for ln in KEEP_LINES.keys()]\n",
        "    for c in needed_line_cols:\n",
        "        merged[c] = pd.to_numeric(merged[c], errors=\"coerce\").fillna(0)\n",
        "\n",
        "    # QA: transit <= total\n",
        "    bad_share = ((merged[\"line_01\"] > 0) & (merged[\"line_10\"] > merged[\"line_01\"])).mean()\n",
        "    _log(f\"QA: BG transit > total share = {bad_share:.3%}\")\n",
        "    if bad_share > 0.001:\n",
        "        _log(merged.loc[(merged[\"line_01\"] > 0) & (merged[\"line_10\"] > merged[\"line_01\"]),\n",
        "                        [\"GEOID\",\"line_01\",\"line_10\"]].head(10).to_string(index=False))\n",
        "        raise RuntimeError(\"Detected block yields transit>total. Check parsing/detection.\")\n",
        "\n",
        "    mode_bg = merged[[\"GEOID\"] + needed_line_cols].copy()\n",
        "    mode_bg[\"GEOID\"] = mode_bg[\"GEOID\"].astype(str).str.zfill(12)\n",
        "\n",
        "    mode_bg.to_parquet(CACHE_PARQUET, index=False)\n",
        "    _log(f\"💾 Cached BG table to: {CACHE_PARQUET}\")\n",
        "\n",
        "# =========================================================\n",
        "# Area-weight BG into station buffers and compute capstone % columns\n",
        "# =========================================================\n",
        "detail = station_bg_detail.copy()\n",
        "detail[\"GEOID\"] = detail[\"GEOID\"].astype(str).str.zfill(12)\n",
        "detail[\"area_ratio\"] = pd.to_numeric(detail[\"area_ratio\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "mode_bg = mode_bg.copy()\n",
        "mode_bg[\"GEOID\"] = mode_bg[\"GEOID\"].astype(str).str.zfill(12)\n",
        "\n",
        "detail = detail.merge(mode_bg, on=\"GEOID\", how=\"left\")\n",
        "\n",
        "needed_line_cols = [\"line_01\"] + [f\"line_{ln:02d}\" for ln in KEEP_LINES.keys()]\n",
        "detail[needed_line_cols] = detail[needed_line_cols].fillna(0)\n",
        "\n",
        "# Weighted counts\n",
        "detail[\"total_within\"] = detail[\"line_01\"] * detail[\"area_ratio\"]\n",
        "for ln in KEEP_LINES.keys():\n",
        "    c = f\"line_{ln:02d}\"\n",
        "    detail[c + \"_within\"] = detail[c] * detail[\"area_ratio\"]\n",
        "\n",
        "# Aggregate to stops\n",
        "sum_cols = [\"total_within\"] + [f\"line_{ln:02d}_within\" for ln in KEEP_LINES.keys()]\n",
        "agg = detail.groupby([\"stop_id\",\"stop_name\"], as_index=False)[sum_cols].sum()\n",
        "\n",
        "# Compute % columns\n",
        "pct_cols = []\n",
        "for ln, outcol in KEEP_LINES.items():\n",
        "    within_col = f\"line_{ln:02d}_within\"\n",
        "    agg[outcol] = np.where(agg[\"total_within\"] > 0, 100.0 * agg[within_col] / agg[\"total_within\"], np.nan)\n",
        "    pct_cols.append(outcol)\n",
        "\n",
        "# Sanity check: WFH should be single digits/teens for 2019\n",
        "_log(\"🧪 Station-level WFH share summary (pct_wfh_0p5mi):\")\n",
        "print(agg[\"pct_wfh_0p5mi\"].describe(percentiles=[.01,.05,.1,.25,.5,.75,.9,.95,.99]))\n",
        "\n",
        "# Merge into station_buffers (drop old if present)\n",
        "for c in pct_cols:\n",
        "    if c in station_buffers.columns:\n",
        "        station_buffers = station_buffers.drop(columns=[c])\n",
        "\n",
        "station_buffers = station_buffers.merge(\n",
        "    agg[[\"stop_id\",\"stop_name\"] + pct_cols],\n",
        "    on=[\"stop_id\",\"stop_name\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "_log(\"✅ Capstone commute mode shares complete.\")\n",
        "display(station_buffers[[\"stop_id\",\"stop_name\"] + pct_cols].head())\n",
        "display(station_buffers[pct_cols].describe())\n",
        "print(\"✅ Added capstone columns:\", pct_cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eGFUz17cnEP5",
        "outputId": "ce0085c2-1e49-4bdc-88d0-6b3004da365c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NYC_COUNTIES (normalized) = ['36005', '36047', '36061', '36081', '36085']\n",
            "⬇️ Downloading: https://www2.census.gov/programs-surveys/acs/summary_file/2019/data/5_year_by_state/NewYork_Tracts_Block_Groups_Only.zip\n",
            "✅ Saved: ./acs_sf_cache/NewYork_Tracts_Block_Groups_Only_2019.zip (265.6 MB)\n",
            "🌐 Fetching lookup from web: https://www2.census.gov/programs-surveys/acs/summary_file/2019/documentation/user_tools/ACS_5yr_Seq_Table_Number_Lookup.txt\n",
            "🔎 Lookup delimiter guessed as: ','\n",
            "✅ Lookup loaded: 29,502 rows, 9 cols\n",
            "✅ Lookup parse: table=B08301 seq=0027 startpos=157 cells=21\n",
            "🗺️ Geography member: g20195ny.csv\n",
            "📄 Estimate member: e20195ny0027000.txt\n",
            "🧪 Reading estimate sample (first 12000 rows) to detect B08301 block...\n",
            "🧪 Sample shape: 12,000 rows x 205 cols\n",
            "✅ Detected B08301 block start column = 156 (score=0.984)\n",
            "📥 Reading LOGRECNO + 21 table columns with usecols (min=5, max=176)\n",
            "🔬 Raw estimate sample (LOGRECNO, Total, Transit, WFH):\n",
            "LOGRECNO line_01 line_10 line_21\n",
            " 0003392     888      99      14\n",
            " 0003393    2261     646      55\n",
            " 0003394    2693     671      50\n",
            " 0003395     999      20       7\n",
            " 0003396    2608     286      52\n",
            " 0003397    1438     229     100\n",
            " 0003398    1559     308       8\n",
            " 0003399    1716     252      53\n",
            "📥 Reading geography file (can take a bit)...\n",
            "✅ Geography BG rows: 17,812\n",
            "✅ Joined rows: 15,463\n",
            "🔎 Top county_prefix counts (before NYC filter):\n",
            "county_prefix\n",
            "36047    2085\n",
            "36081    1746\n",
            "36061    1170\n",
            "36005    1154\n",
            "36059    1143\n",
            "36103     999\n",
            "36029     779\n",
            "36119     704\n",
            "36055     609\n",
            "36067     380\n",
            "36085     338\n",
            "36071     276\n",
            "36027     248\n",
            "36001     235\n",
            "36007     204\n",
            "✅ NYC BG rows retained: 6,493\n",
            "QA: BG transit > total share = 0.000%\n",
            "💾 Cached BG table to: ./acs_sf_cache/acs2019_ny_bg_B08301_a9f9afc8e5.parquet\n",
            "🧪 Station-level WFH share summary (pct_wfh_0p5mi):\n",
            "count    517.000000\n",
            "mean       4.847267\n",
            "std        2.453330\n",
            "min        0.000000\n",
            "1%         0.589807\n",
            "5%         1.487096\n",
            "10%        2.032729\n",
            "25%        2.947263\n",
            "50%        4.456673\n",
            "75%        6.489859\n",
            "90%        8.232589\n",
            "95%        9.255687\n",
            "99%       11.282010\n",
            "max       12.286622\n",
            "Name: pct_wfh_0p5mi, dtype: float64\n",
            "✅ Capstone commute mode shares complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  pct_car_truck_van_0p5mi  \\\n",
              "0     101  Van Cortlandt Park-242 St                30.543990   \n",
              "1     103                     238 St                26.381776   \n",
              "2     104                     231 St                24.333560   \n",
              "3     106         Marble Hill-225 St                22.956021   \n",
              "4     107                     215 St                14.766364   \n",
              "\n",
              "   pct_transit_0p5mi  pct_taxicab_0p5mi  pct_bicycle_0p5mi  pct_walked_0p5mi  \\\n",
              "0          53.240565           1.119433           0.506095          9.291717   \n",
              "1          58.646856           1.091549           0.452522          8.468014   \n",
              "2          63.181387           0.823569           0.430627          6.818583   \n",
              "3          63.200495           0.990886           0.692038          6.682591   \n",
              "4          66.345185           1.123450           0.617780          8.731441   \n",
              "\n",
              "   pct_other_means_0p5mi  pct_wfh_0p5mi  \n",
              "0               0.359779       4.938422  \n",
              "1               0.866780       4.004387  \n",
              "2               1.224881       3.121919  \n",
              "3               1.180028       3.877528  \n",
              "4               1.075166       6.577047  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-562e22c5-2fb1-4157-afe4-ada98ff9beb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>pct_car_truck_van_0p5mi</th>\n",
              "      <th>pct_transit_0p5mi</th>\n",
              "      <th>pct_taxicab_0p5mi</th>\n",
              "      <th>pct_bicycle_0p5mi</th>\n",
              "      <th>pct_walked_0p5mi</th>\n",
              "      <th>pct_other_means_0p5mi</th>\n",
              "      <th>pct_wfh_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>30.543990</td>\n",
              "      <td>53.240565</td>\n",
              "      <td>1.119433</td>\n",
              "      <td>0.506095</td>\n",
              "      <td>9.291717</td>\n",
              "      <td>0.359779</td>\n",
              "      <td>4.938422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>26.381776</td>\n",
              "      <td>58.646856</td>\n",
              "      <td>1.091549</td>\n",
              "      <td>0.452522</td>\n",
              "      <td>8.468014</td>\n",
              "      <td>0.866780</td>\n",
              "      <td>4.004387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>24.333560</td>\n",
              "      <td>63.181387</td>\n",
              "      <td>0.823569</td>\n",
              "      <td>0.430627</td>\n",
              "      <td>6.818583</td>\n",
              "      <td>1.224881</td>\n",
              "      <td>3.121919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>22.956021</td>\n",
              "      <td>63.200495</td>\n",
              "      <td>0.990886</td>\n",
              "      <td>0.692038</td>\n",
              "      <td>6.682591</td>\n",
              "      <td>1.180028</td>\n",
              "      <td>3.877528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>14.766364</td>\n",
              "      <td>66.345185</td>\n",
              "      <td>1.123450</td>\n",
              "      <td>0.617780</td>\n",
              "      <td>8.731441</td>\n",
              "      <td>1.075166</td>\n",
              "      <td>6.577047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-562e22c5-2fb1-4157-afe4-ada98ff9beb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-562e22c5-2fb1-4157-afe4-ada98ff9beb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-562e22c5-2fb1-4157-afe4-ada98ff9beb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\u2705 Added capstone columns:\\\", pct_cols)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_car_truck_van_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.804103619791228,\n        \"min\": 14.766363820275796,\n        \"max\": 30.54399030265899,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          26.381775801717723,\n          14.766363820275796,\n          24.333560486310862\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_transit_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.096273837885886,\n        \"min\": 53.24056475911787,\n        \"max\": 66.34518496515088,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          58.646855877458464,\n          66.34518496515088,\n          63.18138697105054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_taxicab_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12714457754375574,\n        \"min\": 0.8235685050317799,\n        \"max\": 1.12344961069417,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0915486658418256,\n          1.12344961069417,\n          0.8235685050317799\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_bicycle_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11172465306657266,\n        \"min\": 0.43062674479479934,\n        \"max\": 0.6920379851934899,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4525222217405118,\n          0.6177802877187547,\n          0.43062674479479934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_walked_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1783331784202022,\n        \"min\": 6.682590714186622,\n        \"max\": 9.291716572895782,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8.468013635692978,\n          8.731440953214138,\n          6.818582852746437\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_other_means_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35321724292471296,\n        \"min\": 0.35977863889555317,\n        \"max\": 1.2248808186447722,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8667803623161144,\n          1.075166414069205,\n          1.2248808186447722\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_wfh_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3265063673252975,\n        \"min\": 3.1219188549238956,\n        \"max\": 6.577047303233924,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.004386712664132,\n          6.577047303233924,\n          3.1219188549238956\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       pct_car_truck_van_0p5mi  pct_transit_0p5mi  pct_taxicab_0p5mi  \\\n",
              "count               517.000000         517.000000         517.000000   \n",
              "mean                 19.403600          59.603179           1.166024   \n",
              "std                  15.087383          12.539803           1.163016   \n",
              "min                   2.209194          16.578355           0.000000   \n",
              "25%                   7.361411          51.582249           0.394734   \n",
              "50%                  16.188789          62.506567           0.738188   \n",
              "75%                  26.641323          69.422971           1.523774   \n",
              "max                  79.845722          94.737580           5.965763   \n",
              "\n",
              "       pct_bicycle_0p5mi  pct_walked_0p5mi  pct_other_means_0p5mi  \\\n",
              "count         517.000000        517.000000             517.000000   \n",
              "mean            1.494372         12.786834               0.628998   \n",
              "std             1.244440         10.433874               0.397095   \n",
              "min             0.000000          0.763190               0.000000   \n",
              "25%             0.506095          5.957587               0.356460   \n",
              "50%             1.111548          8.527354               0.583690   \n",
              "75%             2.313493         15.160428               0.837740   \n",
              "max             5.931691         44.990283               2.647126   \n",
              "\n",
              "       pct_wfh_0p5mi  \n",
              "count     517.000000  \n",
              "mean        4.847267  \n",
              "std         2.453330  \n",
              "min         0.000000  \n",
              "25%         2.947263  \n",
              "50%         4.456673  \n",
              "75%         6.489859  \n",
              "max        12.286622  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ee753f6-98bd-4e98-837c-a70e7336ebea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pct_car_truck_van_0p5mi</th>\n",
              "      <th>pct_transit_0p5mi</th>\n",
              "      <th>pct_taxicab_0p5mi</th>\n",
              "      <th>pct_bicycle_0p5mi</th>\n",
              "      <th>pct_walked_0p5mi</th>\n",
              "      <th>pct_other_means_0p5mi</th>\n",
              "      <th>pct_wfh_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>19.403600</td>\n",
              "      <td>59.603179</td>\n",
              "      <td>1.166024</td>\n",
              "      <td>1.494372</td>\n",
              "      <td>12.786834</td>\n",
              "      <td>0.628998</td>\n",
              "      <td>4.847267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15.087383</td>\n",
              "      <td>12.539803</td>\n",
              "      <td>1.163016</td>\n",
              "      <td>1.244440</td>\n",
              "      <td>10.433874</td>\n",
              "      <td>0.397095</td>\n",
              "      <td>2.453330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.209194</td>\n",
              "      <td>16.578355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.763190</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.361411</td>\n",
              "      <td>51.582249</td>\n",
              "      <td>0.394734</td>\n",
              "      <td>0.506095</td>\n",
              "      <td>5.957587</td>\n",
              "      <td>0.356460</td>\n",
              "      <td>2.947263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>16.188789</td>\n",
              "      <td>62.506567</td>\n",
              "      <td>0.738188</td>\n",
              "      <td>1.111548</td>\n",
              "      <td>8.527354</td>\n",
              "      <td>0.583690</td>\n",
              "      <td>4.456673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>26.641323</td>\n",
              "      <td>69.422971</td>\n",
              "      <td>1.523774</td>\n",
              "      <td>2.313493</td>\n",
              "      <td>15.160428</td>\n",
              "      <td>0.837740</td>\n",
              "      <td>6.489859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>79.845722</td>\n",
              "      <td>94.737580</td>\n",
              "      <td>5.965763</td>\n",
              "      <td>5.931691</td>\n",
              "      <td>44.990283</td>\n",
              "      <td>2.647126</td>\n",
              "      <td>12.286622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ee753f6-98bd-4e98-837c-a70e7336ebea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ee753f6-98bd-4e98-837c-a70e7336ebea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ee753f6-98bd-4e98-837c-a70e7336ebea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\u2705 Added capstone columns:\\\", pct_cols)\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"pct_car_truck_van_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 176.01228374484168,\n        \"min\": 2.2091940630534896,\n        \"max\": 517.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          19.403599876953045,\n          16.18878943429233,\n          517.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_transit_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 166.4592010130197,\n        \"min\": 12.539802548599416,\n        \"max\": 517.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          59.60317931989797,\n          62.50656658199313,\n          517.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_taxicab_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 182.24345064896926,\n        \"min\": 0.0,\n        \"max\": 517.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.1660242705597323,\n          0.7381875309983568,\n          517.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_bicycle_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 182.15969198088132,\n        \"min\": 0.0,\n        \"max\": 517.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.4943718307749738,\n          1.1115483914001743,\n          517.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_walked_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 178.30579479805874,\n        \"min\": 0.7631902466102609,\n        \"max\": 517.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12.786833973210522,\n          8.527353942557305,\n          517.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_other_means_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 182.51353563782882,\n        \"min\": 0.0,\n        \"max\": 517.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6289975087232863,\n          0.5836904866497122,\n          517.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_wfh_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 181.1319464055226,\n        \"min\": 0.0,\n        \"max\": 517.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4.84726735418579,\n          4.45667288188199,\n          517.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Added capstone columns: ['pct_car_truck_van_0p5mi', 'pct_transit_0p5mi', 'pct_taxicab_0p5mi', 'pct_bicycle_0p5mi', 'pct_walked_0p5mi', 'pct_other_means_0p5mi', 'pct_wfh_0p5mi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 8: % Workers Working from Home (station catchment)\n",
        "# Source: ACS 2020 5-year (same commute mode table as above)\n",
        "# Method: Area-weighted aggregation using station_bg_detail area_ratio\n",
        "# =========================================================\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "acs_base = \"https://api.census.gov/data/2020/acs/acs5\"\n",
        "meta = requests.get(f\"{acs_base}/variables.json\", timeout=60).json()[\"variables\"]\n",
        "\n",
        "# --- USER MUST CONFIRM THESE VARIABLE IDS FOR 2020 ACS5 ---\n",
        "TOTAL_WORKERS_VAR = \"B08301_001E\"\n",
        "WFH_VAR = \"B08301_021E\"  # verify; \"Worked from home\" code can vary by table/vintage\n",
        "\n",
        "if TOTAL_WORKERS_VAR not in meta or WFH_VAR not in meta:\n",
        "    raise ValueError(\n",
        "        \"WFH variable codes not found in ACS metadata. \"\n",
        "        \"Inspect variables.json to choose correct IDs for total workers and worked-from-home.\"\n",
        "    )\n",
        "\n",
        "acs_parts = []\n",
        "for c in sorted(nyc_countyfps):\n",
        "    url = (\n",
        "        f\"{acs_base}\"\n",
        "        f\"?get=NAME,{TOTAL_WORKERS_VAR},{WFH_VAR}\"\n",
        "        f\"&for=block%20group:*\"\n",
        "        f\"&in=state:36%20county:{c}%20tract:*\"\n",
        "    )\n",
        "    resp = requests.get(url, timeout=120)\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "    acs_parts.append(pd.DataFrame(data[1:], columns=data[0]))\n",
        "\n",
        "wfh = pd.concat(acs_parts, ignore_index=True)\n",
        "\n",
        "wfh[\"GEOID\"] = (\n",
        "    wfh[\"state\"].astype(str).str.zfill(2) +\n",
        "    wfh[\"county\"].astype(str).str.zfill(3) +\n",
        "    wfh[\"tract\"].astype(str).str.zfill(6) +\n",
        "    wfh[\"block group\"].astype(str).str.zfill(1)\n",
        ")\n",
        "\n",
        "wfh[\"workers_total\"] = pd.to_numeric(wfh[TOTAL_WORKERS_VAR], errors=\"coerce\").fillna(0)\n",
        "wfh[\"workers_wfh\"] = pd.to_numeric(wfh[WFH_VAR], errors=\"coerce\").fillna(0)\n",
        "wfh = wfh[[\"GEOID\", \"workers_total\", \"workers_wfh\"]]\n",
        "\n",
        "detail = station_bg_detail.merge(wfh, on=\"GEOID\", how=\"left\")\n",
        "detail[[\"workers_total\", \"workers_wfh\"]] = detail[[\"workers_total\", \"workers_wfh\"]].fillna(0)\n",
        "\n",
        "detail[\"workers_total_within\"] = detail[\"workers_total\"] * detail[\"area_ratio\"]\n",
        "detail[\"workers_wfh_within\"] = detail[\"workers_wfh\"] * detail[\"area_ratio\"]\n",
        "\n",
        "agg = (\n",
        "    detail.groupby([\"stop_id\", \"stop_name\"])[[\"workers_total_within\", \"workers_wfh_within\"]]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "agg[\"pct_workers_wfh_0p5mi\"] = (\n",
        "    100.0 * agg[\"workers_wfh_within\"] / agg[\"workers_total_within\"]\n",
        ").replace([pd.NA, pd.NaT, float(\"inf\")], 0).fillna(0)\n",
        "\n",
        "station_buffers = station_buffers.merge(\n",
        "    agg[[\"stop_id\", \"stop_name\", \"pct_workers_wfh_0p5mi\"]],\n",
        "    on=[\"stop_id\", \"stop_name\"],\n",
        "    how=\"left\",\n",
        ")\n",
        "station_buffers[\"pct_workers_wfh_0p5mi\"] = station_buffers[\"pct_workers_wfh_0p5mi\"].fillna(0)\n",
        "\n",
        "display(station_buffers[[\"stop_id\", \"stop_name\", \"pct_workers_wfh_0p5mi\"]].head())\n"
      ],
      "metadata": {
        "id": "5EpdVmbYPfWC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "90733971-e1a8-484d-af71-289c369e5d86"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  pct_workers_wfh_0p5mi\n",
              "0     101  Van Cortlandt Park-242 St               8.004019\n",
              "1     103                     238 St               7.269194\n",
              "2     104                     231 St               5.364991\n",
              "3     106         Marble Hill-225 St               6.247171\n",
              "4     107                     215 St               8.612343"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d97626e5-fd28-498a-8803-5997829aed62\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>pct_workers_wfh_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>8.004019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>7.269194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>5.364991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>6.247171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>8.612343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d97626e5-fd28-498a-8803-5997829aed62')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d97626e5-fd28-498a-8803-5997829aed62 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d97626e5-fd28-498a-8803-5997829aed62');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(station_buffers[[\\\"stop_id\\\", \\\"stop_name\\\", \\\"pct_workers_wfh_0p5mi\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_workers_wfh_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3105943850583646,\n        \"min\": 5.364990593026419,\n        \"max\": 8.612342877937778,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.269193866057911,\n          8.612342877937778,\n          5.364990593026419\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Urban Variable 9: Median Household Income (station catchment) - SAFE VERSION\n",
        "# Source: ACS 2020 5-year (API), B19013_001E (median HH income) + B11001_001E (total households)\n",
        "# NOTE: Medians do not aggregate perfectly.\n",
        "# Practical approximation: household-weighted average of BG medians within station buffer.\n",
        "# =========================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "\n",
        "ACS_YEAR = 2020\n",
        "acs_base = f\"https://api.census.gov/data/{ACS_YEAR}/acs/acs5\"\n",
        "\n",
        "MED_INC_VAR = \"B19013_001E\"   # Median household income (dollars)\n",
        "HH_VAR      = \"B11001_001E\"   # Total households (for weighting)\n",
        "\n",
        "OUT_COL = \"median_hh_income_0p5mi_approx\"\n",
        "\n",
        "# -----------------------------\n",
        "# Small HTTP helper with retries (prevents random API hiccups)\n",
        "# -----------------------------\n",
        "def make_session():\n",
        "    s = requests.Session()\n",
        "    retry = Retry(\n",
        "        total=6,\n",
        "        connect=6,\n",
        "        read=6,\n",
        "        status=6,\n",
        "        backoff_factor=0.8,\n",
        "        status_forcelist=[429, 500, 502, 503, 504],\n",
        "        allowed_methods=[\"GET\"],\n",
        "        respect_retry_after_header=True,\n",
        "        raise_on_status=False,\n",
        "    )\n",
        "    s.mount(\"https://\", HTTPAdapter(max_retries=retry))\n",
        "    return s\n",
        "\n",
        "sess = make_session()\n",
        "\n",
        "def get_json(url: str, timeout=120):\n",
        "    r = sess.get(url, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Pull BG median income + households for NYC counties\n",
        "# -----------------------------\n",
        "acs_parts = []\n",
        "for c in sorted(nyc_countyfps):\n",
        "    url = (\n",
        "        f\"{acs_base}\"\n",
        "        f\"?get=NAME,{MED_INC_VAR},{HH_VAR}\"\n",
        "        f\"&for=block%20group:*\"\n",
        "        f\"&in=state:36%20county:{c}%20tract:*\"\n",
        "    )\n",
        "    data = get_json(url)\n",
        "    acs_parts.append(pd.DataFrame(data[1:], columns=data[0]))\n",
        "\n",
        "inc = pd.concat(acs_parts, ignore_index=True)\n",
        "\n",
        "# Build 12-digit BG GEOID\n",
        "inc[\"GEOID\"] = (\n",
        "    inc[\"state\"].astype(str).str.zfill(2)\n",
        "    + inc[\"county\"].astype(str).str.zfill(3)\n",
        "    + inc[\"tract\"].astype(str).str.zfill(6)\n",
        "    + inc[\"block group\"].astype(str).str.zfill(1)\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Parse + CLEAN values (this is the main fix)\n",
        "# -----------------------------\n",
        "inc[\"median_income_bg\"] = pd.to_numeric(inc[MED_INC_VAR], errors=\"coerce\")\n",
        "inc[\"hh_total\"] = pd.to_numeric(inc[HH_VAR], errors=\"coerce\")\n",
        "\n",
        "# Drop nonsense / sentinel / suppressed values:\n",
        "# - median should be positive\n",
        "# - households should be positive\n",
        "inc = inc[(inc[\"median_income_bg\"].notna()) & (inc[\"hh_total\"].notna())].copy()\n",
        "inc = inc[(inc[\"median_income_bg\"] > 0) & (inc[\"hh_total\"] > 0)].copy()\n",
        "\n",
        "# Optional guardrail: clip to a plausible range so one weird BG can't dominate\n",
        "# (You can remove this if you prefer raw ACS after filtering)\n",
        "inc[\"median_income_bg\"] = inc[\"median_income_bg\"].clip(lower=1, upper=500000)\n",
        "\n",
        "inc = inc[[\"GEOID\", \"median_income_bg\", \"hh_total\"]].copy()\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Join to station_bg_detail and compute household-weighted approximation\n",
        "# -----------------------------\n",
        "detail = station_bg_detail.copy()\n",
        "detail[\"GEOID\"] = detail[\"GEOID\"].astype(str).str.zfill(12)\n",
        "\n",
        "detail = detail.merge(inc, on=\"GEOID\", how=\"left\")\n",
        "\n",
        "# If a BG is missing median/households, exclude it from BOTH numerator/denominator\n",
        "detail[\"hh_total\"] = detail[\"hh_total\"].where(detail[\"median_income_bg\"].notna(), np.nan)\n",
        "\n",
        "# Area-weight households into buffer\n",
        "detail[\"hh_within\"] = detail[\"hh_total\"] * detail[\"area_ratio\"]\n",
        "\n",
        "# Weighted numerator\n",
        "detail[\"inc_weighted\"] = detail[\"median_income_bg\"] * detail[\"hh_within\"]\n",
        "\n",
        "agg = (\n",
        "    detail.groupby([\"stop_id\", \"stop_name\"], as_index=False)[[\"inc_weighted\", \"hh_within\"]]\n",
        "    .sum(min_count=1)\n",
        ")\n",
        "\n",
        "# Safe divide\n",
        "agg[OUT_COL] = np.where(\n",
        "    agg[\"hh_within\"] > 0,\n",
        "    agg[\"inc_weighted\"] / agg[\"hh_within\"],\n",
        "    np.nan\n",
        ")\n",
        "\n",
        "# Format\n",
        "agg[OUT_COL] = agg[OUT_COL].round(0)\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Merge into station_buffers (avoid duplicate columns)\n",
        "# -----------------------------\n",
        "station_buffers = station_buffers.drop(columns=[OUT_COL], errors=\"ignore\")\n",
        "\n",
        "station_buffers = station_buffers.merge(\n",
        "    agg[[\"stop_id\", \"stop_name\", OUT_COL]],\n",
        "    on=[\"stop_id\", \"stop_name\"],\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "# Optional: keep NaN if you want “missingness” visible; otherwise fill with 0\n",
        "# station_buffers[OUT_COL] = station_buffers[OUT_COL].fillna(0).astype(int)\n",
        "station_buffers[OUT_COL] = station_buffers[OUT_COL].astype(\"float\")\n",
        "\n",
        "display(station_buffers[[\"stop_id\", \"stop_name\", OUT_COL]].head())\n",
        "\n",
        "# Quick sanity check\n",
        "print(\"Sanity check (station-level):\")\n",
        "print(station_buffers[OUT_COL].describe(percentiles=[.01,.05,.1,.25,.5,.75,.9,.95,.99]))\n",
        "print(\"Missing share:\", station_buffers[OUT_COL].isna().mean())\n"
      ],
      "metadata": {
        "id": "ndqsWqf3PmKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "096309d0-349c-4797-b408-82ecb75882ab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  median_hh_income_0p5mi_approx\n",
              "0     101  Van Cortlandt Park-242 St                        73618.0\n",
              "1     103                     238 St                        67034.0\n",
              "2     104                     231 St                        56674.0\n",
              "3     106         Marble Hill-225 St                        59890.0\n",
              "4     107                     215 St                        67005.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb8c4bb9-779b-4a7b-9d81-710313100591\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>median_hh_income_0p5mi_approx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>73618.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>67034.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>56674.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>59890.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>67005.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb8c4bb9-779b-4a7b-9d81-710313100591')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb8c4bb9-779b-4a7b-9d81-710313100591 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb8c4bb9-779b-4a7b-9d81-710313100591');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Missing share:\\\", station_buffers[OUT_COL]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_hh_income_0p5mi_approx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6665.960410923545,\n        \"min\": 56674.0,\n        \"max\": 73618.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          67034.0,\n          67005.0,\n          56674.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity check (station-level):\n",
            "count       518.000000\n",
            "mean      86477.841699\n",
            "std       42026.589007\n",
            "min       26214.000000\n",
            "1%        28229.990000\n",
            "5%        36035.300000\n",
            "10%       41486.300000\n",
            "25%       56527.500000\n",
            "50%       70323.500000\n",
            "75%      117781.250000\n",
            "90%      148653.100000\n",
            "95%      165508.200000\n",
            "99%      191512.160000\n",
            "max      201221.000000\n",
            "Name: median_hh_income_0p5mi_approx, dtype: float64\n",
            "Missing share: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Connectivity Variable 1: Number of Connecting Bus Routes (within 0.5 mile buffer)\n",
        "# Source: MTA Bus GTFS static feeds (downloaded from URLs, cached locally)\n",
        "# Output: station_buffers[\"bus_routes_0p5mi\"]\n",
        "#\n",
        "# Assumes:\n",
        "# - station_buffers is a GeoDataFrame with stop_id, stop_name, geometry\n",
        "# - station_buffers.crs is projected (e.g., EPSG:2263)\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "WORKDIR = \"./gtfs_cache\"\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "BUS_GTFS_URLS = [\n",
        "    \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_bx.zip\",\n",
        "    \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_b.zip\",\n",
        "    \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_m.zip\",\n",
        "    \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_q.zip\",\n",
        "    \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_si.zip\",\n",
        "    \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_busco.zip\",\n",
        "]\n",
        "\n",
        "OUT_COL = \"bus_routes_0p5mi\"\n",
        "DEBUG = True\n",
        "\n",
        "def _log(msg: str):\n",
        "    if DEBUG:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Download (cached)\n",
        "# -----------------------------\n",
        "def download_gtfs_zip(url: str, out_dir: str, chunk=1024 * 1024) -> str:\n",
        "    \"\"\"\n",
        "    Download a GTFS zip to out_dir if not already present.\n",
        "    Returns local filepath.\n",
        "    \"\"\"\n",
        "    base = url.split(\"?\")[0]\n",
        "    fname = os.path.join(out_dir, os.path.basename(base) or \"gtfs_bus.zip\")\n",
        "\n",
        "    if os.path.exists(fname) and os.path.getsize(fname) > 0:\n",
        "        _log(f\"✅ Using cached GTFS zip: {fname}\")\n",
        "        return fname\n",
        "\n",
        "    _log(f\"⬇️ Downloading GTFS: {url}\")\n",
        "    with requests.get(url, stream=True, timeout=300) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(fname, \"wb\") as f:\n",
        "            for part in r.iter_content(chunk_size=chunk):\n",
        "                if part:\n",
        "                    f.write(part)\n",
        "\n",
        "    _log(f\"✅ Saved: {fname} ({os.path.getsize(fname)/1e6:.1f} MB)\")\n",
        "    return fname\n",
        "\n",
        "gtfs_zip_paths = [download_gtfs_zip(u, WORKDIR) for u in BUS_GTFS_URLS]\n",
        "_log(f\"✅ Ready GTFS zips: {len(gtfs_zip_paths)}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def _read_gtfs_csv(z: zipfile.ZipFile, name: str, usecols=None, dtype=None) -> pd.DataFrame:\n",
        "    with z.open(name) as f:\n",
        "        return pd.read_csv(f, usecols=usecols, dtype=dtype)\n",
        "\n",
        "def _iter_gtfs_csv_chunks(z: zipfile.ZipFile, name: str, usecols=None, dtype=None, chunksize=600_000):\n",
        "    with z.open(name) as f:\n",
        "        for chunk in pd.read_csv(f, usecols=usecols, dtype=dtype, chunksize=chunksize):\n",
        "            yield chunk\n",
        "\n",
        "def _to_station_crs_points(df_stops: pd.DataFrame, station_crs) -> gpd.GeoDataFrame:\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df_stops,\n",
        "        geometry=gpd.points_from_xy(df_stops[\"stop_lon\"], df_stops[\"stop_lat\"]),\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "    return gdf.to_crs(station_crs)\n",
        "\n",
        "# -----------------------------\n",
        "# Main compute\n",
        "# -----------------------------\n",
        "def compute_bus_routes_for_station_buffers(station_buffers: gpd.GeoDataFrame, gtfs_zip_paths: list) -> pd.DataFrame:\n",
        "    for col in [\"stop_id\", \"stop_name\", \"geometry\"]:\n",
        "        if col not in station_buffers.columns:\n",
        "            raise ValueError(f\"station_buffers missing required column: {col}\")\n",
        "\n",
        "    all_stops = []\n",
        "    feed_trip_to_route = []\n",
        "\n",
        "    for zp in gtfs_zip_paths:\n",
        "        _log(f\"📦 Processing GTFS zip: {zp}\")\n",
        "        with zipfile.ZipFile(zp, \"r\") as z:\n",
        "            names = set(z.namelist())\n",
        "            needed = {\"stops.txt\", \"trips.txt\", \"stop_times.txt\"}\n",
        "            missing = needed - names\n",
        "            if missing:\n",
        "                raise RuntimeError(f\"{os.path.basename(zp)} missing required files: {missing}\")\n",
        "\n",
        "            # Stops: rename stop_id -> bus_stop_id now to avoid sjoin collision\n",
        "            stops = _read_gtfs_csv(\n",
        "                z, \"stops.txt\",\n",
        "                usecols=[\"stop_id\", \"stop_lat\", \"stop_lon\"],\n",
        "                dtype={\"stop_id\": str, \"stop_lat\": float, \"stop_lon\": float}\n",
        "            ).rename(columns={\"stop_id\": \"bus_stop_id\"})\n",
        "\n",
        "            stops[\"bus_stop_id\"] = stops[\"bus_stop_id\"].astype(str)\n",
        "\n",
        "            stops_gdf = _to_station_crs_points(stops, station_buffers.crs)\n",
        "            all_stops.append(stops_gdf[[\"bus_stop_id\", \"geometry\"]])\n",
        "\n",
        "            trips = _read_gtfs_csv(\n",
        "                z, \"trips.txt\",\n",
        "                usecols=[\"trip_id\", \"route_id\"],\n",
        "                dtype={\"trip_id\": str, \"route_id\": str}\n",
        "            ).dropna().drop_duplicates()\n",
        "\n",
        "            feed_trip_to_route.append(trips)\n",
        "\n",
        "    stops_all = pd.concat(all_stops, ignore_index=True).drop_duplicates(subset=[\"bus_stop_id\"])\n",
        "    stops_all = gpd.GeoDataFrame(stops_all, geometry=\"geometry\", crs=station_buffers.crs)\n",
        "    _log(f\"🧾 Unique bus stops loaded: {len(stops_all):,}\")\n",
        "\n",
        "    # Spatial join: bus stops within station buffers\n",
        "    join = gpd.sjoin(\n",
        "        stops_all,\n",
        "        station_buffers[[\"stop_id\", \"stop_name\", \"geometry\"]],\n",
        "        how=\"inner\",\n",
        "        predicate=\"within\"\n",
        "    )\n",
        "\n",
        "    needed_cols = {\"stop_id\", \"stop_name\", \"bus_stop_id\"}\n",
        "    if not needed_cols.issubset(set(join.columns)):\n",
        "        _log(\"⚠️ sjoin columns:\")\n",
        "        _log(str(sorted(join.columns)))\n",
        "        raise RuntimeError(\n",
        "            f\"sjoin did not produce expected columns {needed_cols}. \"\n",
        "            \"Check station_buffers columns or GeoPandas behavior.\"\n",
        "        )\n",
        "\n",
        "    join = join[[\"stop_id\", \"stop_name\", \"bus_stop_id\"]].drop_duplicates()\n",
        "    _log(f\"🔗 Bus stops within station buffers: {len(join):,}\")\n",
        "\n",
        "    if join.empty:\n",
        "        out = station_buffers[[\"stop_id\", \"stop_name\"]].drop_duplicates().copy()\n",
        "        out[OUT_COL] = 0\n",
        "        return out\n",
        "\n",
        "    target_stop_ids = set(join[\"bus_stop_id\"].unique().tolist())\n",
        "    _log(f\"🎯 Target bus stop_ids to map -> routes: {len(target_stop_ids):,}\")\n",
        "\n",
        "    stop_route_pairs = []\n",
        "\n",
        "    for zp, trips in zip(gtfs_zip_paths, feed_trip_to_route):\n",
        "        with zipfile.ZipFile(zp, \"r\") as z:\n",
        "            _log(f\"🧩 Mapping bus_stop_id->route_id (chunked): {os.path.basename(zp)}\")\n",
        "            trip_to_route = trips.set_index(\"trip_id\")[\"route_id\"]\n",
        "\n",
        "            for chunk in _iter_gtfs_csv_chunks(\n",
        "                z, \"stop_times.txt\",\n",
        "                usecols=[\"trip_id\", \"stop_id\"],\n",
        "                dtype={\"trip_id\": str, \"stop_id\": str},\n",
        "                chunksize=600_000\n",
        "            ):\n",
        "                chunk = chunk[chunk[\"stop_id\"].isin(target_stop_ids)]\n",
        "                if chunk.empty:\n",
        "                    continue\n",
        "\n",
        "                chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
        "                chunk = chunk.dropna(subset=[\"route_id\"])[[\"stop_id\", \"route_id\"]]\n",
        "                if chunk.empty:\n",
        "                    continue\n",
        "\n",
        "                stop_route_pairs.append(chunk.drop_duplicates())\n",
        "\n",
        "    if not stop_route_pairs:\n",
        "        out = station_buffers[[\"stop_id\", \"stop_name\"]].drop_duplicates().copy()\n",
        "        out[OUT_COL] = 0\n",
        "        return out\n",
        "\n",
        "    stop_routes_all = pd.concat(stop_route_pairs, ignore_index=True).drop_duplicates()\n",
        "    stop_routes_all = stop_routes_all.rename(columns={\"stop_id\": \"bus_stop_id\"})\n",
        "    _log(f\"🧾 Unique (bus_stop_id, route_id) pairs (within buffers only): {len(stop_routes_all):,}\")\n",
        "\n",
        "    join_routes = join.merge(stop_routes_all, on=\"bus_stop_id\", how=\"left\")\n",
        "\n",
        "    counts = (\n",
        "        join_routes.dropna(subset=[\"route_id\"])\n",
        "        .groupby([\"stop_id\", \"stop_name\"])[\"route_id\"]\n",
        "        .nunique()\n",
        "        .reset_index(name=OUT_COL)\n",
        "    )\n",
        "\n",
        "    return counts\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "bus_counts = compute_bus_routes_for_station_buffers(station_buffers, gtfs_zip_paths)\n",
        "\n",
        "if OUT_COL in station_buffers.columns:\n",
        "    station_buffers = station_buffers.drop(columns=[OUT_COL])\n",
        "\n",
        "station_buffers = station_buffers.merge(bus_counts, on=[\"stop_id\", \"stop_name\"], how=\"left\")\n",
        "station_buffers[OUT_COL] = station_buffers[OUT_COL].fillna(0).astype(int)\n",
        "\n",
        "_log(\"✅ Connectivity Variable 1 complete.\")\n",
        "display(station_buffers[[\"stop_id\", \"stop_name\", OUT_COL]].head())\n",
        "print(station_buffers[OUT_COL].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2tEIYJfPDMtN",
        "outputId": "b10927bc-31aa-49ed-ee42-be3de03114de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Downloading GTFS: https://rrgtfsfeeds.s3.amazonaws.com/gtfs_bx.zip\n",
            "✅ Saved: ./gtfs_cache/gtfs_bx.zip (9.7 MB)\n",
            "⬇️ Downloading GTFS: https://rrgtfsfeeds.s3.amazonaws.com/gtfs_b.zip\n",
            "✅ Saved: ./gtfs_cache/gtfs_b.zip (19.8 MB)\n",
            "⬇️ Downloading GTFS: https://rrgtfsfeeds.s3.amazonaws.com/gtfs_m.zip\n",
            "✅ Saved: ./gtfs_cache/gtfs_m.zip (9.6 MB)\n",
            "⬇️ Downloading GTFS: https://rrgtfsfeeds.s3.amazonaws.com/gtfs_q.zip\n",
            "✅ Saved: ./gtfs_cache/gtfs_q.zip (6.8 MB)\n",
            "⬇️ Downloading GTFS: https://rrgtfsfeeds.s3.amazonaws.com/gtfs_si.zip\n",
            "✅ Saved: ./gtfs_cache/gtfs_si.zip (7.9 MB)\n",
            "⬇️ Downloading GTFS: https://rrgtfsfeeds.s3.amazonaws.com/gtfs_busco.zip\n",
            "✅ Saved: ./gtfs_cache/gtfs_busco.zip (9.9 MB)\n",
            "✅ Ready GTFS zips: 6\n",
            "📦 Processing GTFS zip: ./gtfs_cache/gtfs_bx.zip\n",
            "📦 Processing GTFS zip: ./gtfs_cache/gtfs_b.zip\n",
            "📦 Processing GTFS zip: ./gtfs_cache/gtfs_m.zip\n",
            "📦 Processing GTFS zip: ./gtfs_cache/gtfs_q.zip\n",
            "📦 Processing GTFS zip: ./gtfs_cache/gtfs_si.zip\n",
            "📦 Processing GTFS zip: ./gtfs_cache/gtfs_busco.zip\n",
            "🧾 Unique bus stops loaded: 13,499\n",
            "🔗 Bus stops within station buffers: 31,185\n",
            "🎯 Target bus stop_ids to map -> routes: 8,467\n",
            "🧩 Mapping bus_stop_id->route_id (chunked): gtfs_bx.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧩 Mapping bus_stop_id->route_id (chunked): gtfs_b.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧩 Mapping bus_stop_id->route_id (chunked): gtfs_m.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧩 Mapping bus_stop_id->route_id (chunked): gtfs_q.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧩 Mapping bus_stop_id->route_id (chunked): gtfs_si.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧩 Mapping bus_stop_id->route_id (chunked): gtfs_busco.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧾 Unique (bus_stop_id, route_id) pairs (within buffers only): 13,413\n",
            "✅ Connectivity Variable 1 complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2530795087.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  bus_routes_0p5mi\n",
              "0     101  Van Cortlandt Park-242 St                11\n",
              "1     103                     238 St                10\n",
              "2     104                     231 St                11\n",
              "3     106         Marble Hill-225 St                12\n",
              "4     107                     215 St                 8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61545ce4-19bd-46bb-9692-0410f6214fe3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>bus_routes_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61545ce4-19bd-46bb-9692-0410f6214fe3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61545ce4-19bd-46bb-9692-0410f6214fe3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61545ce4-19bd-46bb-9692-0410f6214fe3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(station_buffers[OUT_COL]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bus_routes_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 8,\n        \"max\": 12,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10,\n          8,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    518.000000\n",
            "mean      15.332046\n",
            "std       16.619585\n",
            "min        1.000000\n",
            "25%        6.000000\n",
            "50%        9.000000\n",
            "75%       15.000000\n",
            "max       81.000000\n",
            "Name: bus_routes_0p5mi, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Connectivity Variable 2 (CONSOLIDATED BEST VERSION):\n",
        "# Number of Connecting Subway Lines (within 0.5 mile buffer)\n",
        "#\n",
        "# Source: MTA Subway GTFS static feed\n",
        "# Feed: https://rrgtfsfeeds.s3.amazonaws.com/gtfs_subway.zip\n",
        "# Output: station_buffers[\"subway_lines_0p5mi\"]\n",
        "#\n",
        "# Counts distinct route_short_name (e.g., A, 1, F) that have >=1 PLATFORM stop\n",
        "# within each station's 0.5-mile buffer.\n",
        "#\n",
        "# Requires:\n",
        "# - station_buffers: GeoDataFrame with [\"stop_id\",\"stop_name\",\"geometry\"] in projected CRS (e.g., EPSG:2263)\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "WORKDIR = \"./gtfs_cache\"\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "SUBWAY_GTFS_URL = \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_subway.zip\"\n",
        "GTFS_ZIP_PATH = os.path.join(WORKDIR, \"gtfs_subway.zip\")\n",
        "\n",
        "OUT_COL = \"subway_lines_0p5mi\"\n",
        "DEBUG = True\n",
        "\n",
        "def _log(msg: str):\n",
        "    if DEBUG:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "def download_if_missing(url: str, path: str, chunk=1024 * 1024):\n",
        "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
        "        _log(f\"✅ Using cached subway GTFS zip: {path}\")\n",
        "        return\n",
        "    _log(f\"⬇️ Downloading subway GTFS: {url}\")\n",
        "    r = requests.get(url, stream=True, timeout=300)\n",
        "    r.raise_for_status()\n",
        "    with open(path, \"wb\") as f:\n",
        "        for part in r.iter_content(chunk_size=chunk):\n",
        "            if part:\n",
        "                f.write(part)\n",
        "    _log(f\"✅ Saved: {path} ({os.path.getsize(path)/1e6:.1f} MB)\")\n",
        "\n",
        "def _read_gtfs_csv(z: zipfile.ZipFile, name: str, usecols=None, dtype=None) -> pd.DataFrame:\n",
        "    with z.open(name) as f:\n",
        "        return pd.read_csv(f, usecols=usecols, dtype=dtype)\n",
        "\n",
        "def _iter_gtfs_csv_chunks(z: zipfile.ZipFile, name: str, usecols=None, dtype=None, chunksize=800_000):\n",
        "    with z.open(name) as f:\n",
        "        for chunk in pd.read_csv(f, usecols=usecols, dtype=dtype, chunksize=chunksize):\n",
        "            yield chunk\n",
        "\n",
        "def _to_station_crs_points(df_stops: pd.DataFrame, station_crs) -> gpd.GeoDataFrame:\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df_stops,\n",
        "        geometry=gpd.points_from_xy(df_stops[\"stop_lon\"], df_stops[\"stop_lat\"]),\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "    return gdf.to_crs(station_crs)\n",
        "\n",
        "def compute_subway_lines_for_station_buffers(station_buffers: gpd.GeoDataFrame, gtfs_zip_path: str) -> pd.DataFrame:\n",
        "    # --- validate inputs ---\n",
        "    for col in [\"stop_id\", \"stop_name\", \"geometry\"]:\n",
        "        if col not in station_buffers.columns:\n",
        "            raise ValueError(f\"station_buffers missing required column: {col}\")\n",
        "\n",
        "    if not os.path.exists(gtfs_zip_path):\n",
        "        raise FileNotFoundError(f\"Subway GTFS zip not found: {gtfs_zip_path}\")\n",
        "\n",
        "    # Ensure station_buffers is projected (not strictly required, but strongly recommended)\n",
        "    if station_buffers.crs is None:\n",
        "        raise ValueError(\"station_buffers.crs is None. Please set/project station_buffers to a projected CRS (e.g., EPSG:2263).\")\n",
        "\n",
        "    with zipfile.ZipFile(gtfs_zip_path, \"r\") as z:\n",
        "        names = set(z.namelist())\n",
        "        needed = {\"stops.txt\", \"stop_times.txt\", \"trips.txt\", \"routes.txt\"}\n",
        "        missing = needed - names\n",
        "        if missing:\n",
        "            raise RuntimeError(f\"GTFS zip missing required files: {missing}\")\n",
        "\n",
        "        # 1) stops: keep PLATFORM stops (location_type blank or 0)\n",
        "        stops = _read_gtfs_csv(\n",
        "            z, \"stops.txt\",\n",
        "            usecols=[\"stop_id\", \"stop_lat\", \"stop_lon\", \"location_type\", \"parent_station\"],\n",
        "            dtype={\"stop_id\": str, \"stop_lat\": float, \"stop_lon\": float, \"location_type\": str, \"parent_station\": str}\n",
        "        )\n",
        "\n",
        "        lt = stops[\"location_type\"].fillna(\"\").astype(str).str.strip()\n",
        "        platform_mask = (lt == \"\") | (lt == \"0\")\n",
        "        stops = stops.loc[platform_mask, [\"stop_id\", \"stop_lat\", \"stop_lon\"]].copy()\n",
        "\n",
        "        # Rename to avoid collision with station stop_id\n",
        "        stops = stops.rename(columns={\"stop_id\": \"subway_stop_id\"})\n",
        "        stops[\"subway_stop_id\"] = stops[\"subway_stop_id\"].astype(str)\n",
        "\n",
        "        stops_gdf = _to_station_crs_points(stops.rename(columns={\"stop_lat\":\"stop_lat\", \"stop_lon\":\"stop_lon\"}), station_buffers.crs)\n",
        "        stops_gdf = stops_gdf[[\"subway_stop_id\", \"geometry\"]]\n",
        "        _log(f\"🧾 Subway platform stops loaded: {len(stops_gdf):,}\")\n",
        "\n",
        "        # 2) spatial join: platform stops within station buffers\n",
        "        sj = gpd.sjoin(\n",
        "            stops_gdf,\n",
        "            station_buffers[[\"stop_id\", \"stop_name\", \"geometry\"]],\n",
        "            how=\"inner\",\n",
        "            predicate=\"within\"\n",
        "        )\n",
        "\n",
        "        needed_cols = {\"stop_id\", \"stop_name\", \"subway_stop_id\"}\n",
        "        if not needed_cols.issubset(set(sj.columns)):\n",
        "            _log(\"⚠️ sjoin columns:\")\n",
        "            _log(str(sorted(sj.columns)))\n",
        "            raise RuntimeError(f\"sjoin did not produce expected columns {needed_cols}\")\n",
        "\n",
        "        sj = sj[[\"stop_id\", \"stop_name\", \"subway_stop_id\"]].drop_duplicates()\n",
        "        _log(f\"🔗 Subway platform stops within station buffers: {len(sj):,}\")\n",
        "\n",
        "        if sj.empty:\n",
        "            out = station_buffers[[\"stop_id\", \"stop_name\"]].drop_duplicates().copy()\n",
        "            out[OUT_COL] = 0\n",
        "            return out\n",
        "\n",
        "        target_stop_ids = set(sj[\"subway_stop_id\"].unique())\n",
        "        _log(f\"🎯 Target subway_stop_ids to map -> lines: {len(target_stop_ids):,}\")\n",
        "\n",
        "        # 3) routes: route_id -> route_short_name (A/1/F)\n",
        "        routes = _read_gtfs_csv(\n",
        "            z, \"routes.txt\",\n",
        "            usecols=[\"route_id\", \"route_short_name\"],\n",
        "            dtype={\"route_id\": str, \"route_short_name\": str}\n",
        "        ).dropna()\n",
        "\n",
        "        routes[\"route_short_name\"] = routes[\"route_short_name\"].astype(str).str.strip()\n",
        "        route_id_to_name = routes.set_index(\"route_id\")[\"route_short_name\"]\n",
        "\n",
        "        # 4) trips: trip_id -> route_id\n",
        "        trips = _read_gtfs_csv(\n",
        "            z, \"trips.txt\",\n",
        "            usecols=[\"trip_id\", \"route_id\"],\n",
        "            dtype={\"trip_id\": str, \"route_id\": str}\n",
        "        ).dropna().drop_duplicates()\n",
        "        trip_to_route = trips.set_index(\"trip_id\")[\"route_id\"]\n",
        "\n",
        "        # 5) stop_times (chunked): stop_id -> trip_id -> route_id -> route_short_name\n",
        "        stop_line_pairs = []\n",
        "        _log(\"🧩 Mapping subway_stop_id -> line (chunked stop_times)...\")\n",
        "\n",
        "        for chunk in _iter_gtfs_csv_chunks(\n",
        "            z, \"stop_times.txt\",\n",
        "            usecols=[\"trip_id\", \"stop_id\"],\n",
        "            dtype={\"trip_id\": str, \"stop_id\": str},\n",
        "            chunksize=800_000\n",
        "        ):\n",
        "            chunk = chunk.rename(columns={\"stop_id\": \"subway_stop_id\"})\n",
        "            chunk = chunk[chunk[\"subway_stop_id\"].isin(target_stop_ids)]\n",
        "            if chunk.empty:\n",
        "                continue\n",
        "\n",
        "            chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
        "            chunk = chunk.dropna(subset=[\"route_id\"])\n",
        "\n",
        "            chunk[\"line\"] = chunk[\"route_id\"].map(route_id_to_name)\n",
        "            chunk = chunk.dropna(subset=[\"line\"])\n",
        "\n",
        "            stop_line_pairs.append(chunk[[\"subway_stop_id\", \"line\"]].drop_duplicates())\n",
        "\n",
        "        if not stop_line_pairs:\n",
        "            out = station_buffers[[\"stop_id\", \"stop_name\"]].drop_duplicates().copy()\n",
        "            out[OUT_COL] = 0\n",
        "            return out\n",
        "\n",
        "        stop_lines = pd.concat(stop_line_pairs, ignore_index=True).drop_duplicates()\n",
        "        _log(f\"🧾 Unique (subway_stop_id, line) pairs (within buffers only): {len(stop_lines):,}\")\n",
        "\n",
        "    # 6) attach lines to stations and count distinct lines per station\n",
        "    joined = sj.merge(stop_lines, on=\"subway_stop_id\", how=\"left\")\n",
        "\n",
        "    counts = (\n",
        "        joined.dropna(subset=[\"line\"])\n",
        "        .groupby([\"stop_id\", \"stop_name\"])[\"line\"]\n",
        "        .nunique()\n",
        "        .reset_index(name=OUT_COL)\n",
        "    )\n",
        "\n",
        "    return counts\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "download_if_missing(SUBWAY_GTFS_URL, GTFS_ZIP_PATH)\n",
        "\n",
        "subway_counts = compute_subway_lines_for_station_buffers(station_buffers, GTFS_ZIP_PATH)\n",
        "\n",
        "# Attach overwrite-safe\n",
        "if OUT_COL in station_buffers.columns:\n",
        "    station_buffers = station_buffers.drop(columns=[OUT_COL])\n",
        "\n",
        "station_buffers = station_buffers.merge(subway_counts, on=[\"stop_id\", \"stop_name\"], how=\"left\")\n",
        "station_buffers[OUT_COL] = station_buffers[OUT_COL].fillna(0).astype(int)\n",
        "\n",
        "_log(\"✅ Connectivity Variable 2 complete.\")\n",
        "display(station_buffers[[\"stop_id\", \"stop_name\", OUT_COL]].tail())\n",
        "print(station_buffers[OUT_COL].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "oQUC77wHJExk",
        "outputId": "19e67d26-9e3e-4f11-ff7b-c7a6b69273c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Downloading subway GTFS: https://rrgtfsfeeds.s3.amazonaws.com/gtfs_subway.zip\n",
            "✅ Saved: ./gtfs_cache/gtfs_subway.zip (5.6 MB)\n",
            "🧾 Subway platform stops loaded: 992\n",
            "🔗 Subway platform stops within station buffers: 5,450\n",
            "🎯 Target subway_stop_ids to map -> lines: 992\n",
            "🧩 Mapping subway_stop_id -> line (chunked stop_times)...\n",
            "🧾 Unique (subway_stop_id, line) pairs (within buffers only): 2,021\n",
            "✅ Connectivity Variable 2 complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    stop_id               stop_name  subway_lines_0p5mi\n",
              "513  IBX_15         McDonald Avenue                   2\n",
              "514  IBX_16      New Utrecht Avenue                   3\n",
              "515  IBX_17                8 Avenue                   3\n",
              "516  IBX_18                4 Avenue                   3\n",
              "517  IBX_19  Brooklyn Army Terminal                   0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d67e545-d117-406c-9478-98cb38996e79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>subway_lines_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>IBX_15</td>\n",
              "      <td>McDonald Avenue</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>IBX_16</td>\n",
              "      <td>New Utrecht Avenue</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>IBX_17</td>\n",
              "      <td>8 Avenue</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>IBX_18</td>\n",
              "      <td>4 Avenue</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d67e545-d117-406c-9478-98cb38996e79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d67e545-d117-406c-9478-98cb38996e79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d67e545-d117-406c-9478-98cb38996e79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(station_buffers[OUT_COL]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"IBX_16\",\n          \"IBX_19\",\n          \"IBX_17\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"New Utrecht Avenue\",\n          \"Brooklyn Army Terminal\",\n          \"8 Avenue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subway_lines_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    518.000000\n",
            "mean       5.735521\n",
            "std        5.238742\n",
            "min        0.000000\n",
            "25%        2.000000\n",
            "50%        4.000000\n",
            "75%        7.000000\n",
            "max       22.000000\n",
            "Name: subway_lines_0p5mi, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Connectivity Variable 3: Number of Connecting Commuter Rail Lines (within 0.5 mile buffer)\n",
        "# Sources: GTFS static feeds (LIRR, Metro-North, optional PATH if feed works)\n",
        "# Output: station_buffers[\"commuter_lines_0p5mi\"]\n",
        "#\n",
        "# UPDATED:\n",
        "# - Returns BOTH (counts_df, stops_all_gdf) so you can reuse GTFS stop points for other vars (e.g., transfer flag)\n",
        "# - Reads GTFS headers once per file (faster/safer than re-reading inside list comp)\n",
        "# - Cleans blank line labels (drops empty strings)\n",
        "#\n",
        "# Requires:\n",
        "# - station_buffers: GeoDataFrame with [\"stop_id\",\"stop_name\",\"geometry\"] in projected CRS (e.g., EPSG:2263)\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "WORKDIR = \"./gtfs_cache\"\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "# GTFS_URLS = [\n",
        "#     \"https://rrgtfsfeeds.s3.amazonaws.com/gtfslirr.zip\",\n",
        "#     \"https://rrgtfsfeeds.s3.amazonaws.com/gtfsmnr.zip\",\n",
        "#     # Optional PATH feed (may fail depending on source availability):\n",
        "#     \"http://gtfs-source-feeds.transit.land/path-nj-us.zip\",\n",
        "# ]\n",
        "\n",
        "GTFS_URLS = [\n",
        "    \"https://rrgtfsfeeds.s3.amazonaws.com/gtfslirr.zip\",\n",
        "    \"https://rrgtfsfeeds.s3.amazonaws.com/gtfsmnr.zip\",\n",
        "    \"http://gtfs-source-feeds.transit.land/path-nj-us.zip\",\n",
        "    \"https://www.njtransit.com/sites/default/files/gtfs/rail/google_transit.zip\"\n",
        "]\n",
        "\n",
        "\n",
        "OUT_COL = \"commuter_lines_0p5mi\"\n",
        "DEBUG = True\n",
        "\n",
        "def _log(msg: str):\n",
        "    if DEBUG:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "def download_if_missing(url: str, out_dir: str, chunk=1024*1024) -> str:\n",
        "    fname = os.path.join(out_dir, os.path.basename(url.split(\"?\")[0]) or \"gtfs.zip\")\n",
        "    if os.path.exists(fname) and os.path.getsize(fname) > 0:\n",
        "        _log(f\"✅ Using cached GTFS zip: {fname}\")\n",
        "        return fname\n",
        "    _log(f\"⬇️ Downloading GTFS: {url}\")\n",
        "    r = requests.get(url, stream=True, timeout=300, allow_redirects=True)\n",
        "    r.raise_for_status()\n",
        "    with open(fname, \"wb\") as f:\n",
        "        for part in r.iter_content(chunk_size=chunk):\n",
        "            if part:\n",
        "                f.write(part)\n",
        "    _log(f\"✅ Saved: {fname} ({os.path.getsize(fname)/1e6:.1f} MB)\")\n",
        "    return fname\n",
        "\n",
        "def _read_header_cols(z: zipfile.ZipFile, name: str):\n",
        "    return pd.read_csv(z.open(name), nrows=0).columns\n",
        "\n",
        "def _read_gtfs_csv(z: zipfile.ZipFile, name: str, usecols=None, dtype=None) -> pd.DataFrame:\n",
        "    with z.open(name) as f:\n",
        "        return pd.read_csv(f, usecols=usecols, dtype=dtype)\n",
        "\n",
        "def _iter_gtfs_csv_chunks(z: zipfile.ZipFile, name: str, usecols=None, dtype=None, chunksize=700_000):\n",
        "    with z.open(name) as f:\n",
        "        for chunk in pd.read_csv(f, usecols=usecols, dtype=dtype, chunksize=chunksize):\n",
        "            yield chunk\n",
        "\n",
        "def _to_station_crs_points(df_stops: pd.DataFrame, station_crs) -> gpd.GeoDataFrame:\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df_stops,\n",
        "        geometry=gpd.points_from_xy(df_stops[\"stop_lon\"], df_stops[\"stop_lat\"]),\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "    return gdf.to_crs(station_crs)\n",
        "\n",
        "def _platform_stop_filter(stops: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Keep platform-level stops (location_type blank/0) when present.\n",
        "    Some commuter rail feeds may omit location_type; in that case keep all.\n",
        "    \"\"\"\n",
        "    if \"location_type\" not in stops.columns:\n",
        "        return stops\n",
        "    lt = stops[\"location_type\"].fillna(\"\").astype(str).str.strip()\n",
        "    return stops[(lt == \"\") | (lt == \"0\")].copy()\n",
        "\n",
        "def compute_commuter_lines_for_station_buffers(\n",
        "    station_buffers: gpd.GeoDataFrame,\n",
        "    gtfs_zip_paths: list\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      counts_df: DataFrame with [\"stop_id\",\"stop_name\", OUT_COL]\n",
        "      stops_all: GeoDataFrame with [\"gtfs_stop_id\",\"feed\",\"geometry\"] for all feeds (projected to station CRS)\n",
        "    \"\"\"\n",
        "    for col in [\"stop_id\", \"stop_name\", \"geometry\"]:\n",
        "        if col not in station_buffers.columns:\n",
        "            raise ValueError(f\"station_buffers missing required column: {col}\")\n",
        "    if station_buffers.crs is None:\n",
        "        raise ValueError(\"station_buffers.crs is None (need a projected CRS).\")\n",
        "\n",
        "    if not gtfs_zip_paths:\n",
        "        raise ValueError(\"No GTFS zips provided.\")\n",
        "\n",
        "    empty_counts = station_buffers[[\"stop_id\",\"stop_name\"]].drop_duplicates().copy()\n",
        "    empty_counts[OUT_COL] = 0\n",
        "    empty_stops = gpd.GeoDataFrame(\n",
        "        {\"gtfs_stop_id\": [], \"feed\": []},\n",
        "        geometry=[],\n",
        "        crs=station_buffers.crs\n",
        "    )\n",
        "\n",
        "    # Collect all GTFS stops across feeds for ONE spatial join\n",
        "    stops_all_list = []\n",
        "    feed_meta = []  # (zip_path, route_id_to_line_series, trip_to_route_series)\n",
        "\n",
        "    for zp in gtfs_zip_paths:\n",
        "        _log(f\"📦 Processing: {zp}\")\n",
        "        try:\n",
        "            with zipfile.ZipFile(zp, \"r\") as z:\n",
        "                names = set(z.namelist())\n",
        "                needed = {\"stops.txt\", \"trips.txt\", \"stop_times.txt\", \"routes.txt\"}\n",
        "                missing = needed - names\n",
        "                if missing:\n",
        "                    raise RuntimeError(f\"Missing files: {missing}\")\n",
        "\n",
        "                # -------- stops --------\n",
        "                stops_cols = _read_header_cols(z, \"stops.txt\")\n",
        "                stop_usecols = [c for c in [\"stop_id\",\"stop_lat\",\"stop_lon\",\"location_type\",\"parent_station\"] if c in stops_cols]\n",
        "\n",
        "                stops = _read_gtfs_csv(z, \"stops.txt\", usecols=stop_usecols, dtype=str)\n",
        "\n",
        "                stops[\"stop_lat\"] = pd.to_numeric(stops[\"stop_lat\"], errors=\"coerce\")\n",
        "                stops[\"stop_lon\"] = pd.to_numeric(stops[\"stop_lon\"], errors=\"coerce\")\n",
        "                stops = stops.dropna(subset=[\"stop_lat\",\"stop_lon\"])\n",
        "\n",
        "                stops = _platform_stop_filter(stops)\n",
        "                stops = stops.rename(columns={\"stop_id\": \"gtfs_stop_id\"}).copy()\n",
        "                stops[\"gtfs_stop_id\"] = stops[\"gtfs_stop_id\"].astype(str)\n",
        "\n",
        "                stops_gdf = _to_station_crs_points(\n",
        "                    stops[[\"gtfs_stop_id\",\"stop_lat\",\"stop_lon\"]],\n",
        "                    station_buffers.crs\n",
        "                )\n",
        "                feed_name = os.path.basename(zp)\n",
        "                stops_gdf[\"feed\"] = feed_name\n",
        "                stops_all_list.append(stops_gdf[[\"gtfs_stop_id\",\"feed\",\"geometry\"]])\n",
        "\n",
        "                # -------- routes --------\n",
        "                routes_cols = _read_header_cols(z, \"routes.txt\")\n",
        "                route_usecols = [c for c in [\"route_id\",\"route_short_name\",\"route_long_name\"] if c in routes_cols]\n",
        "                routes = _read_gtfs_csv(z, \"routes.txt\", usecols=route_usecols, dtype=str).dropna(subset=[\"route_id\"]).drop_duplicates()\n",
        "\n",
        "                if \"route_short_name\" in routes.columns:\n",
        "                    routes[\"line\"] = routes[\"route_short_name\"].astype(str).str.strip()\n",
        "                elif \"route_long_name\" in routes.columns:\n",
        "                    routes[\"line\"] = routes[\"route_long_name\"].astype(str).str.strip()\n",
        "                else:\n",
        "                    routes[\"line\"] = routes[\"route_id\"].astype(str)\n",
        "\n",
        "                # treat blanks as missing\n",
        "                routes[\"line\"] = routes[\"line\"].replace(r\"^\\s*$\", np.nan, regex=True)\n",
        "\n",
        "                route_id_to_line = routes.set_index(\"route_id\")[\"line\"]\n",
        "\n",
        "                # -------- trips --------\n",
        "                trips = _read_gtfs_csv(\n",
        "                    z, \"trips.txt\",\n",
        "                    usecols=[\"trip_id\",\"route_id\"],\n",
        "                    dtype=str\n",
        "                ).dropna().drop_duplicates()\n",
        "\n",
        "                trip_to_route = trips.set_index(\"trip_id\")[\"route_id\"]\n",
        "\n",
        "                feed_meta.append((zp, route_id_to_line, trip_to_route))\n",
        "\n",
        "        except Exception as e:\n",
        "            _log(f\"⚠️ Skipping feed (could not read): {zp} :: {type(e).__name__}: {e}\")\n",
        "\n",
        "    if not stops_all_list:\n",
        "        return empty_counts, empty_stops\n",
        "\n",
        "    stops_all = pd.concat(stops_all_list, ignore_index=True).drop_duplicates(subset=[\"gtfs_stop_id\",\"feed\"])\n",
        "    stops_all = gpd.GeoDataFrame(stops_all, geometry=\"geometry\", crs=station_buffers.crs)\n",
        "    _log(f\"🧾 GTFS platform stops loaded (all feeds): {len(stops_all):,}\")\n",
        "\n",
        "    # Spatial join: GTFS stops within station buffers\n",
        "    sj = gpd.sjoin(\n",
        "        stops_all,\n",
        "        station_buffers[[\"stop_id\",\"stop_name\",\"geometry\"]],\n",
        "        how=\"inner\",\n",
        "        predicate=\"within\"\n",
        "    )\n",
        "\n",
        "    need = {\"stop_id\",\"stop_name\",\"gtfs_stop_id\",\"feed\"}\n",
        "    if not need.issubset(set(sj.columns)):\n",
        "        _log(\"⚠️ sjoin columns:\")\n",
        "        _log(str(sorted(sj.columns)))\n",
        "        raise RuntimeError(f\"sjoin missing expected columns: {need}\")\n",
        "\n",
        "    sj = sj[[\"stop_id\",\"stop_name\",\"gtfs_stop_id\",\"feed\"]].drop_duplicates()\n",
        "    _log(f\"🔗 GTFS stops within station buffers: {len(sj):,}\")\n",
        "\n",
        "    if sj.empty:\n",
        "        return empty_counts, stops_all\n",
        "\n",
        "    # Map gtfs_stop_id -> line, chunking stop_times per feed, filtered to only stops in buffers for that feed\n",
        "    stop_line_pairs_all = []\n",
        "\n",
        "    for (zp, route_id_to_line, trip_to_route) in feed_meta:\n",
        "        feed_name = os.path.basename(zp)\n",
        "        target_stop_ids = set(sj.loc[sj[\"feed\"] == feed_name, \"gtfs_stop_id\"].unique().tolist())\n",
        "        if not target_stop_ids:\n",
        "            continue\n",
        "\n",
        "        _log(f\"🧩 Mapping stop_id -> line (chunked): {feed_name} | target stops: {len(target_stop_ids):,}\")\n",
        "\n",
        "        with zipfile.ZipFile(zp, \"r\") as z:\n",
        "            for chunk in _iter_gtfs_csv_chunks(\n",
        "                z, \"stop_times.txt\",\n",
        "                usecols=[\"trip_id\",\"stop_id\"],\n",
        "                dtype=str,\n",
        "                chunksize=700_000\n",
        "            ):\n",
        "                chunk = chunk.rename(columns={\"stop_id\":\"gtfs_stop_id\"})\n",
        "                chunk = chunk[chunk[\"gtfs_stop_id\"].isin(target_stop_ids)]\n",
        "                if chunk.empty:\n",
        "                    continue\n",
        "\n",
        "                chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
        "                chunk = chunk.dropna(subset=[\"route_id\"])\n",
        "\n",
        "                chunk[\"line\"] = chunk[\"route_id\"].map(route_id_to_line)\n",
        "                chunk = chunk.dropna(subset=[\"line\"])\n",
        "\n",
        "                out = chunk[[\"gtfs_stop_id\",\"line\"]].drop_duplicates()\n",
        "                out[\"feed\"] = feed_name\n",
        "                stop_line_pairs_all.append(out)\n",
        "\n",
        "    if not stop_line_pairs_all:\n",
        "        return empty_counts, stops_all\n",
        "\n",
        "    stop_lines = pd.concat(stop_line_pairs_all, ignore_index=True).drop_duplicates()\n",
        "    _log(f\"🧾 Unique (gtfs_stop_id, line, feed) pairs (within buffers only): {len(stop_lines):,}\")\n",
        "\n",
        "    # Attach lines to stations and count distinct line labels per station\n",
        "    joined = sj.merge(stop_lines, on=[\"gtfs_stop_id\",\"feed\"], how=\"left\")\n",
        "\n",
        "    counts = (\n",
        "        joined.dropna(subset=[\"line\"])\n",
        "        .groupby([\"stop_id\",\"stop_name\"])[\"line\"]\n",
        "        .nunique()\n",
        "        .reset_index(name=OUT_COL)\n",
        "    )\n",
        "\n",
        "    # Ensure every station appears\n",
        "    base = station_buffers[[\"stop_id\",\"stop_name\"]].drop_duplicates()\n",
        "    counts = base.merge(counts, on=[\"stop_id\",\"stop_name\"], how=\"left\")\n",
        "    counts[OUT_COL] = counts[OUT_COL].fillna(0).astype(int)\n",
        "\n",
        "    return counts, stops_all\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "gtfs_zip_paths = []\n",
        "for u in GTFS_URLS:\n",
        "    try:\n",
        "        gtfs_zip_paths.append(download_if_missing(u, WORKDIR))\n",
        "    except Exception as e:\n",
        "        _log(f\"⚠️ Could not download {u} :: {type(e).__name__}: {e}\")\n",
        "\n",
        "commuter_counts, commuter_stops_all = compute_commuter_lines_for_station_buffers(station_buffers, gtfs_zip_paths)\n",
        "\n",
        "# Attach overwrite-safe (counts)\n",
        "if OUT_COL in station_buffers.columns:\n",
        "    station_buffers = station_buffers.drop(columns=[OUT_COL])\n",
        "\n",
        "station_buffers = station_buffers.merge(commuter_counts, on=[\"stop_id\",\"stop_name\"], how=\"left\")\n",
        "station_buffers[OUT_COL] = station_buffers[OUT_COL].fillna(0).astype(int)\n",
        "\n",
        "_log(\"✅ Connectivity Variable 3 complete (updated).\")\n",
        "display(station_buffers[[\"stop_id\",\"stop_name\",OUT_COL]].head())\n",
        "print(station_buffers[OUT_COL].describe())\n",
        "\n",
        "# commuter_stops_all is now available for Connectivity Var 4 (transfer flag)\n",
        "print(\"Commuter stops available for reuse:\", len(commuter_stops_all))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "5lHmZFYPRQuS",
        "outputId": "6b03149c-a0e8-42c7-e823-5c7fd58bccd4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Downloading GTFS: https://rrgtfsfeeds.s3.amazonaws.com/gtfslirr.zip\n",
            "✅ Saved: ./gtfs_cache/gtfslirr.zip (1.9 MB)\n",
            "⬇️ Downloading GTFS: https://rrgtfsfeeds.s3.amazonaws.com/gtfsmnr.zip\n",
            "✅ Saved: ./gtfs_cache/gtfsmnr.zip (1.9 MB)\n",
            "⬇️ Downloading GTFS: http://gtfs-source-feeds.transit.land/path-nj-us.zip\n",
            "⚠️ Could not download http://gtfs-source-feeds.transit.land/path-nj-us.zip :: HTTPError: 401 Client Error: Unauthorized for url: https://gtfs-source-feeds.transit.land/path-nj-us.zip\n",
            "⬇️ Downloading GTFS: https://www.njtransit.com/sites/default/files/gtfs/rail/google_transit.zip\n",
            "⚠️ Could not download https://www.njtransit.com/sites/default/files/gtfs/rail/google_transit.zip :: HTTPError: 404 Client Error: Not Found for url: https://www.njtransit.com/sites/default/files/gtfs/rail/google_transit.zip\n",
            "📦 Processing: ./gtfs_cache/gtfslirr.zip\n",
            "📦 Processing: ./gtfs_cache/gtfsmnr.zip\n",
            "🧾 GTFS platform stops loaded (all feeds): 241\n",
            "🔗 GTFS stops within station buffers: 91\n",
            "🧩 Mapping stop_id -> line (chunked): gtfslirr.zip | target stops: 15\n",
            "🧩 Mapping stop_id -> line (chunked): gtfsmnr.zip | target stops: 11\n",
            "🧾 Unique (gtfs_stop_id, line, feed) pairs (within buffers only): 101\n",
            "✅ Connectivity Variable 3 complete (updated).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  commuter_lines_0p5mi\n",
              "0     101  Van Cortlandt Park-242 St                     0\n",
              "1     103                     238 St                     0\n",
              "2     104                     231 St                     1\n",
              "3     106         Marble Hill-225 St                     1\n",
              "4     107                     215 St                     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7bdfdce-46ea-4953-bef1-dad2234e3cb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>commuter_lines_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7bdfdce-46ea-4953-bef1-dad2234e3cb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7bdfdce-46ea-4953-bef1-dad2234e3cb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7bdfdce-46ea-4953-bef1-dad2234e3cb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Commuter stops available for reuse:\\\", len(commuter_stops_all))\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"commuter_lines_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    518.000000\n",
            "mean       0.953668\n",
            "std        2.693530\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max       11.000000\n",
            "Name: commuter_lines_0p5mi, dtype: float64\n",
            "Commuter stops available for reuse: 241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Connectivity Variable 4 (BEST): Distance to Nearest Commuter Rail / PATH Stop\n",
        "# Sources: GTFS static feeds (LIRR, Metro-North, optional PATH)\n",
        "# Uses: commuter_stops_all produced by Connectivity Var 3\n",
        "#\n",
        "# Output:\n",
        "# - station_buffers[\"dist_to_commuter_stop_ft\"]   (feet)\n",
        "# - station_buffers[\"dist_to_commuter_stop_mi\"]   (miles)\n",
        "#\n",
        "# Requires:\n",
        "# - station_buffers: GeoDataFrame with [\"stop_id\",\"stop_name\",\"geometry\"] in projected CRS (e.g., EPSG:2263 feet)\n",
        "# - commuter_stops_all: GeoDataFrame with point geometries in SAME CRS (from Var 3)\n",
        "# =========================================================\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "DEBUG = True\n",
        "OUT_FT = \"dist_to_commuter_stop_ft\"\n",
        "OUT_MI = \"dist_to_commuter_stop_mi\"\n",
        "FEET_PER_MILE = 5280.0\n",
        "\n",
        "def _log(msg: str):\n",
        "    if DEBUG:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "def compute_nearest_commuter_distance(\n",
        "    station_buffers: gpd.GeoDataFrame,\n",
        "    commuter_stops_all: gpd.GeoDataFrame\n",
        ") -> pd.DataFrame:\n",
        "    # --- checks\n",
        "    for col in [\"stop_id\",\"stop_name\",\"geometry\"]:\n",
        "        if col not in station_buffers.columns:\n",
        "            raise ValueError(f\"station_buffers missing required column: {col}\")\n",
        "    if station_buffers.crs is None:\n",
        "        raise ValueError(\"station_buffers.crs is None (must be projected CRS).\")\n",
        "    if commuter_stops_all is None or len(commuter_stops_all) == 0:\n",
        "        raise ValueError(\"commuter_stops_all is empty. Re-run Connectivity Variable 3 (updated) first.\")\n",
        "    if commuter_stops_all.crs is None:\n",
        "        raise ValueError(\"commuter_stops_all.crs is None.\")\n",
        "    if str(commuter_stops_all.crs) != str(station_buffers.crs):\n",
        "        _log(f\"⚠️ CRS mismatch, projecting commuter stops to {station_buffers.crs}\")\n",
        "        commuter_stops_all = commuter_stops_all.to_crs(station_buffers.crs)\n",
        "\n",
        "    # --- station centroids\n",
        "    station_pts = station_buffers[[\"stop_id\",\"stop_name\",\"geometry\"]].drop_duplicates().copy()\n",
        "    station_pts[\"geometry\"] = station_pts.geometry.centroid\n",
        "    station_pts = gpd.GeoDataFrame(station_pts, geometry=\"geometry\", crs=station_buffers.crs)\n",
        "\n",
        "    # --- commuter stop geometries (dedupe)\n",
        "    commuter_pts = commuter_stops_all[[\"geometry\"]].drop_duplicates().copy()\n",
        "    commuter_pts = gpd.GeoDataFrame(commuter_pts, geometry=\"geometry\", crs=station_buffers.crs)\n",
        "\n",
        "    _log(f\"Stations: {len(station_pts):,} | Commuter/PATH stops: {len(commuter_pts):,}\")\n",
        "\n",
        "    # --- nearest distance (feet, since EPSG:2263 uses feet)\n",
        "    nearest = gpd.sjoin_nearest(\n",
        "        station_pts,\n",
        "        commuter_pts,\n",
        "        how=\"left\",\n",
        "        distance_col=OUT_FT\n",
        "    )\n",
        "\n",
        "    # Keep one row per station\n",
        "    dist_df = nearest[[\"stop_id\",\"stop_name\",OUT_FT]].drop_duplicates()\n",
        "\n",
        "    # Miles version\n",
        "    dist_df[OUT_MI] = dist_df[OUT_FT] / FEET_PER_MILE\n",
        "\n",
        "    return dist_df\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "dist_df = compute_nearest_commuter_distance(station_buffers, commuter_stops_all)\n",
        "\n",
        "# Overwrite-safe attach\n",
        "for col in [OUT_FT, OUT_MI]:\n",
        "    if col in station_buffers.columns:\n",
        "        station_buffers = station_buffers.drop(columns=[col])\n",
        "\n",
        "station_buffers = station_buffers.merge(dist_df, on=[\"stop_id\",\"stop_name\"], how=\"left\")\n",
        "\n",
        "_log(\"✅ Connectivity Variable 4 complete (nearest commuter/PATH distance).\")\n",
        "display(station_buffers[[\"stop_id\",\"stop_name\",OUT_FT,OUT_MI]].head())\n",
        "display(station_buffers[[OUT_FT,OUT_MI]].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "p9SVXU0bSwah",
        "outputId": "ac177197-27ef-4c25-a69a-f8ebec6b4c65"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stations: 518 | Commuter/PATH stops: 241\n",
            "✅ Connectivity Variable 4 complete (nearest commuter/PATH distance).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  stop_id                  stop_name  dist_to_commuter_stop_ft  \\\n",
              "0     101  Van Cortlandt Park-242 St               6419.320827   \n",
              "1     103                     238 St               4683.159876   \n",
              "2     104                     231 St               2359.635421   \n",
              "3     106         Marble Hill-225 St                318.017306   \n",
              "4     107                     215 St               2147.615832   \n",
              "\n",
              "   dist_to_commuter_stop_mi  \n",
              "0                  1.215780  \n",
              "1                  0.886962  \n",
              "2                  0.446901  \n",
              "3                  0.060231  \n",
              "4                  0.406745  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6044ec0-3b94-40bb-9023-fa76c89a0b6f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>dist_to_commuter_stop_ft</th>\n",
              "      <th>dist_to_commuter_stop_mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Van Cortlandt Park-242 St</td>\n",
              "      <td>6419.320827</td>\n",
              "      <td>1.215780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>238 St</td>\n",
              "      <td>4683.159876</td>\n",
              "      <td>0.886962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>231 St</td>\n",
              "      <td>2359.635421</td>\n",
              "      <td>0.446901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>318.017306</td>\n",
              "      <td>0.060231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>215 St</td>\n",
              "      <td>2147.615832</td>\n",
              "      <td>0.406745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6044ec0-3b94-40bb-9023-fa76c89a0b6f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6044ec0-3b94-40bb-9023-fa76c89a0b6f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6044ec0-3b94-40bb-9023-fa76c89a0b6f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(station_buffers[[OUT_FT,OUT_MI]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"103\",\n          \"107\",\n          \"104\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"238 St\",\n          \"215 St\",\n          \"231 St\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dist_to_commuter_stop_ft\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2381.2966571118745,\n        \"min\": 318.0173062066523,\n        \"max\": 6419.320826565934,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4683.159875875085,\n          2147.615832369303,\n          2359.6354212980705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dist_to_commuter_stop_mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4510031547560368,\n        \"min\": 0.06023055041792657,\n        \"max\": 1.2157804595768815,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8869620977036146,\n          0.4067454227972165,\n          0.4469006479731194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       dist_to_commuter_stop_ft  dist_to_commuter_stop_mi\n",
              "count                518.000000                518.000000\n",
              "mean               10770.464844                  2.039861\n",
              "std                13674.686224                  2.589903\n",
              "min                   80.434447                  0.015234\n",
              "25%                 3310.588116                  0.627005\n",
              "50%                 6668.305195                  1.262937\n",
              "75%                12174.045239                  2.305690\n",
              "max                98795.892863                 18.711343"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12561115-0ba9-4689-9f79-730cbc23aa5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dist_to_commuter_stop_ft</th>\n",
              "      <th>dist_to_commuter_stop_mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>518.000000</td>\n",
              "      <td>518.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10770.464844</td>\n",
              "      <td>2.039861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13674.686224</td>\n",
              "      <td>2.589903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>80.434447</td>\n",
              "      <td>0.015234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3310.588116</td>\n",
              "      <td>0.627005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6668.305195</td>\n",
              "      <td>1.262937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12174.045239</td>\n",
              "      <td>2.305690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>98795.892863</td>\n",
              "      <td>18.711343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12561115-0ba9-4689-9f79-730cbc23aa5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12561115-0ba9-4689-9f79-730cbc23aa5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12561115-0ba9-4689-9f79-730cbc23aa5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(station_buffers[[OUT_FT,OUT_MI]]\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"dist_to_commuter_stop_ft\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32957.36127790768,\n        \"min\": 80.43444670702237,\n        \"max\": 98795.89286267674,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          10770.464843719024,\n          6668.305194784329,\n          518.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dist_to_commuter_stop_mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 181.85116292104885,\n        \"min\": 0.015233796724814844,\n        \"max\": 518.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.039860765855876,\n          1.2629365899212743,\n          518.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "station_buffers[[\"stop_id\",\"stop_name\",\"dist_to_commuter_stop_ft\"]].sort_values(\"dist_to_commuter_stop_ft\").head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "QZYWYu2HUE3l",
        "outputId": "ab7d36db-bb73-4198-fa97-38853b4e29b3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    stop_id                           stop_name  dist_to_commuter_stop_ft\n",
              "164     712                      61 St-Woodside                 80.434447\n",
              "398     L24                         Atlantic Av                187.954082\n",
              "3       106                  Marble Hill-225 St                318.017306\n",
              "321     G06  Sutphin Blvd-Archer Av-JFK Airport                355.626955\n",
              "145     631                 Grand Central-42 St                448.928418\n",
              "268     D24            Atlantic Av-Barclays Ctr                461.926007\n",
              "135     621                              125 St                568.469920\n",
              "171     720                    Hunters Point Av                592.552174\n",
              "177     901                 Grand Central-42 St                596.831185\n",
              "70      235            Atlantic Av-Barclays Ctr                619.189632\n",
              "200     A28                  34 St-Penn Station                621.148203\n",
              "173     723                 Grand Central-42 St                636.412827\n",
              "25      128                  34 St-Penn Station                704.566067\n",
              "155     701                    Flushing-Main St                720.408939\n",
              "323     G08                  Forest Hills-71 Av                774.987927\n",
              "462     R31            Atlantic Av-Barclays Ctr                870.938843\n",
              "214     A46                         Nostrand Av                965.360740\n",
              "156     702                  Mets-Willets Point                969.852339\n",
              "337     G24                               21 St               1016.471203\n",
              "71      236                           Bergen St               1020.539066"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36c0587a-8f25-4d0f-80ed-6c6a3282ed96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>dist_to_commuter_stop_ft</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>712</td>\n",
              "      <td>61 St-Woodside</td>\n",
              "      <td>80.434447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>L24</td>\n",
              "      <td>Atlantic Av</td>\n",
              "      <td>187.954082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>Marble Hill-225 St</td>\n",
              "      <td>318.017306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>G06</td>\n",
              "      <td>Sutphin Blvd-Archer Av-JFK Airport</td>\n",
              "      <td>355.626955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>631</td>\n",
              "      <td>Grand Central-42 St</td>\n",
              "      <td>448.928418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>D24</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>461.926007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>621</td>\n",
              "      <td>125 St</td>\n",
              "      <td>568.469920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>720</td>\n",
              "      <td>Hunters Point Av</td>\n",
              "      <td>592.552174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>901</td>\n",
              "      <td>Grand Central-42 St</td>\n",
              "      <td>596.831185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>235</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>619.189632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>A28</td>\n",
              "      <td>34 St-Penn Station</td>\n",
              "      <td>621.148203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>723</td>\n",
              "      <td>Grand Central-42 St</td>\n",
              "      <td>636.412827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>128</td>\n",
              "      <td>34 St-Penn Station</td>\n",
              "      <td>704.566067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>701</td>\n",
              "      <td>Flushing-Main St</td>\n",
              "      <td>720.408939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>G08</td>\n",
              "      <td>Forest Hills-71 Av</td>\n",
              "      <td>774.987927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>R31</td>\n",
              "      <td>Atlantic Av-Barclays Ctr</td>\n",
              "      <td>870.938843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>A46</td>\n",
              "      <td>Nostrand Av</td>\n",
              "      <td>965.360740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>702</td>\n",
              "      <td>Mets-Willets Point</td>\n",
              "      <td>969.852339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>G24</td>\n",
              "      <td>21 St</td>\n",
              "      <td>1016.471203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>236</td>\n",
              "      <td>Bergen St</td>\n",
              "      <td>1020.539066</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36c0587a-8f25-4d0f-80ed-6c6a3282ed96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36c0587a-8f25-4d0f-80ed-6c6a3282ed96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36c0587a-8f25-4d0f-80ed-6c6a3282ed96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"station_buffers[[\\\"stop_id\\\",\\\"stop_name\\\",\\\"dist_to_commuter_stop_ft\\\"]]\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"712\",\n          \"702\",\n          \"R31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Flushing-Main St\",\n          \"Nostrand Av\",\n          \"61 St-Woodside\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dist_to_commuter_stop_ft\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 267.543861069121,\n        \"min\": 80.43444670702237,\n        \"max\": 1020.5390660477506,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          80.43444670702237,\n          969.8523388038338,\n          870.938843162934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "\n",
        "# Use your own existing subway stations subset (non-IBX)\n",
        "is_ibx = station_buffers[\"stop_id\"].astype(str).str.startswith(\"IBX_\")\n",
        "subway_stations = station_buffers.loc[~is_ibx, [\"stop_id\",\"stop_name\",\"geometry\",\"subway_lines_at_station\"]].copy()\n",
        "\n",
        "# If geometry in station_buffers is a 0.5-mile polygon buffer, use centroid for proximity\n",
        "subway_pts = subway_stations.copy()\n",
        "subway_pts[\"pt\"] = subway_pts.geometry.centroid\n",
        "subway_pts = subway_pts.set_geometry(\"pt\")\n",
        "\n",
        "ibx_pts = station_buffers.loc[is_ibx, [\"stop_id\",\"stop_name\",\"geometry\"]].copy()\n",
        "ibx_pts[\"pt\"] = ibx_pts.geometry.centroid\n",
        "ibx_pts = ibx_pts.set_geometry(\"pt\")\n",
        "\n",
        "# Distance thresholds in feet if EPSG:2263 (NY State Plane feet)\n",
        "r_0p25mi_ft = 0.25 * 5280\n",
        "r_0p10mi_ft = 0.10 * 5280\n",
        "\n",
        "def transfer_count_by_radius(ibx_pts, subway_pts, radius_ft, out_col):\n",
        "    buffers = ibx_pts[[\"stop_id\",\"stop_name\",\"pt\"]].copy()\n",
        "    buffers[\"geometry\"] = buffers[\"pt\"].buffer(radius_ft)\n",
        "    buffers = buffers.drop(columns=[\"pt\"])\n",
        "    buffers = gpd.GeoDataFrame(buffers, geometry=\"geometry\", crs=ibx_pts.crs)\n",
        "\n",
        "    sj = gpd.sjoin(subway_pts[[\"stop_id\",\"subway_lines_at_station\",\"pt\"]].set_geometry(\"pt\"),\n",
        "                  buffers[[\"stop_id\",\"geometry\"]],\n",
        "                  predicate=\"within\", how=\"inner\")\n",
        "    # Here: simplest transfer measure = count of distinct subway station stop_ids within radius\n",
        "    counts = sj.groupby(\"stop_id_right\")[\"stop_id_left\"].nunique().rename(out_col).reset_index()\n",
        "    counts = counts.rename(columns={\"stop_id_right\":\"stop_id\"})\n",
        "    return counts\n",
        "\n",
        "t25 = transfer_count_by_radius(ibx_pts, subway_pts, r_0p25mi_ft, \"transfer_subway_stations_0p25mi\")\n",
        "t10 = transfer_count_by_radius(ibx_pts, subway_pts, r_0p10mi_ft, \"transfer_subway_stations_0p10mi\")\n",
        "\n",
        "station_buffers = station_buffers.merge(t25, on=\"stop_id\", how=\"left\").merge(t10, on=\"stop_id\", how=\"left\")\n",
        "station_buffers[[\"transfer_subway_stations_0p25mi\",\"transfer_subway_stations_0p10mi\"]] = (\n",
        "    station_buffers[[\"transfer_subway_stations_0p25mi\",\"transfer_subway_stations_0p10mi\"]].fillna(0).astype(int)\n",
        ")\n"
      ],
      "metadata": {
        "id": "DWikOGbio83J"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1) Create the station-level assumption table (from the report table)\n",
        "ibx_assumptions = pd.DataFrame([\n",
        "    (\"IBX_1\",\"Roosevelt Avenue\",1,12.0,6.0,5),\n",
        "    (\"IBX_2\",\"Grand Avenue\",0,12.0,6.0,0),\n",
        "    (\"IBX_3\",\"Eliot Avenue\",0,12.0,6.0,0),\n",
        "    (\"IBX_4\",\"Metropolitan Avenue\",0,12.0,6.0,1),\n",
        "    (\"IBX_5\",\"Myrtle Avenue\",0,12.0,6.0,0),\n",
        "    (\"IBX_6\",\"Wilson Avenue\",0,12.0,6.0,1),\n",
        "    (\"IBX_7\",\"Atlantic Avenue\",0,12.0,6.0,5),\n",
        "    (\"IBX_8\",\"Sutter Avenue\",0,12.0,6.0,1),\n",
        "    (\"IBX_9\",\"Livonia Avenue\",0,12.0,6.0,2),\n",
        "    (\"IBX_10\",\"Linden Blvd\",0,12.0,6.0,0),\n",
        "    (\"IBX_11\",\"Remsen Avenue\",0,12.0,6.0,0),\n",
        "    (\"IBX_12\",\"Utica Avenue\",0,12.0,6.0,0),\n",
        "    (\"IBX_13\",\"Flatbush–Nostrand Av\",0,12.0,6.0,4),\n",
        "    (\"IBX_14\",\"East 16 Street\",0,12.0,6.0,2),\n",
        "    (\"IBX_15\",\"McDonald Avenue\",0,12.0,6.0,1),\n",
        "    (\"IBX_16\",\"New Utrecht Avenue\",0,12.0,6.0,2),\n",
        "    (\"IBX_17\",\"8 Avenue\",0,12.0,6.0,1),\n",
        "    (\"IBX_18\",\"4 Avenue\",0,12.0,6.0,1),\n",
        "    (\"IBX_19\",\"Brooklyn Army Terminal\",1,12.0,6.0,0),\n",
        "], columns=[\n",
        "    \"stop_id\",\"stop_name\",\"is_terminal\",\n",
        "    \"peak_trains_per_hour\",\"midday_trains_per_hour\",\n",
        "    \"planned_transfer_count\"\n",
        "])\n",
        "\n",
        "# 2) Optional: define a single-column \"subway_lines_at_station\" for IBX as 1 + transfers\n",
        "ibx_assumptions[\"subway_lines_at_station\"] = 1 + ibx_assumptions[\"planned_transfer_count\"]\n",
        "\n",
        "# 3) Merge into station_buffers (preserve any already-computed subway station values)\n",
        "svc_cols = [\"is_terminal\",\"peak_trains_per_hour\",\"midday_trains_per_hour\",\n",
        "            \"planned_transfer_count\",\"subway_lines_at_station\"]\n",
        "\n",
        "station_buffers = station_buffers.merge(\n",
        "    ibx_assumptions[[\"stop_id\"] + svc_cols],\n",
        "    on=\"stop_id\",\n",
        "    how=\"left\",\n",
        "    suffixes=(\"\",\"_ibx\")\n",
        ")\n",
        "\n",
        "# 4) If you want these fields to apply ONLY to IBX and not overwrite subways:\n",
        "is_ibx = station_buffers[\"stop_id\"].astype(str).str.startswith(\"IBX_\")\n",
        "for c in svc_cols:\n",
        "    # keep existing subway values; only fill for IBX\n",
        "    station_buffers.loc[is_ibx, c] = station_buffers.loc[is_ibx, c].fillna(station_buffers.loc[is_ibx, f\"{c}_ibx\"])\n",
        "\n",
        "# 5) Cleanup helper columns\n",
        "drop_cols = [f\"{c}_ibx\" for c in svc_cols if f\"{c}_ibx\" in station_buffers.columns]\n",
        "station_buffers = station_buffers.drop(columns=drop_cols)\n"
      ],
      "metadata": {
        "id": "XX9aYf-eo2lP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# COMBINED TRANSIT SERVICE VARIABLES (Subway GTFS + IBX)\n",
        "#\n",
        "# Computes, in ONE pass:\n",
        "# 1) peak_trains_per_hour   (unique trip_ids stopping at station complex during 08:00–08:59)\n",
        "# 2) midday_trains_per_hour (unique trip_ids stopping at station complex during 13:00–13:59)\n",
        "# 3) subway_lines_serving_station (distinct route_short_name serving station complex on a weekday service day)\n",
        "# 4) is_terminal_subway (station complex is a primary terminal for at least one route; inferred from trip endpoints)\n",
        "#\n",
        "# Then merges into station_buffers, and fills IBX assumptions:\n",
        "# - peak_trains_per_hour: default 12.0 if missing\n",
        "# - midday_trains_per_hour: default 6.0 if missing\n",
        "# - subway_lines_serving_station: 1 + planned_transfer_count (if available) else 1\n",
        "# - is_terminal_subway: from station_buffers[\"is_terminal\"] if present, else 0\n",
        "#\n",
        "# Requires:\n",
        "# - station_buffers: GeoDataFrame/DataFrame with at least [\"stop_id\",\"stop_name\", ...]\n",
        "# - A Subway GTFS zip (downloaded below with fallbacks)\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "WORKDIR = \"./gtfs_cache\"\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "GTFS_SUBWAY_URLS = [\n",
        "    \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_subway.zip\",\n",
        "    \"http://web.mta.info/developers/data/nyct/subway/google_transit.zip\",\n",
        "]\n",
        "GTFS_ZIP_PATH = os.path.join(WORKDIR, \"gtfs_subway.zip\")\n",
        "\n",
        "PEAK_HOUR = 8       # 08:00–08:59\n",
        "MIDDAY_HOUR = 13    # 13:00–13:59 (1–2 PM)\n",
        "\n",
        "DEFAULT_IBX_PEAK_TPH = 12.0\n",
        "DEFAULT_IBX_MIDDAY_TPH = 6.0\n",
        "\n",
        "DEBUG = True\n",
        "def _log(msg: str):\n",
        "    if DEBUG:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def download_first_working(urls, out_path, chunk=1024*1024):\n",
        "    if os.path.exists(out_path) and os.path.getsize(out_path) > 0:\n",
        "        _log(f\"✅ Using cached GTFS zip: {out_path}\")\n",
        "        return out_path\n",
        "\n",
        "    last_err = None\n",
        "    for url in urls:\n",
        "        try:\n",
        "            _log(f\"⬇️ Downloading subway GTFS: {url}\")\n",
        "            r = requests.get(url, stream=True, timeout=300, allow_redirects=True)\n",
        "            r.raise_for_status()\n",
        "            with open(out_path, \"wb\") as f:\n",
        "                for part in r.iter_content(chunk_size=chunk):\n",
        "                    if part:\n",
        "                        f.write(part)\n",
        "            _log(f\"✅ Saved: {out_path} ({os.path.getsize(out_path)/1e6:.1f} MB)\")\n",
        "            return out_path\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            _log(f\"⚠️ Failed: {url} :: {type(e).__name__}: {e}\")\n",
        "\n",
        "    raise RuntimeError(f\"Could not download any subway GTFS feed. Last error: {last_err}\")\n",
        "\n",
        "def _iter_gtfs_csv_chunks(z: zipfile.ZipFile, name: str, usecols=None, dtype=None, chunksize=900_000):\n",
        "    with z.open(name) as f:\n",
        "        for chunk in pd.read_csv(f, usecols=usecols, dtype=dtype, chunksize=chunksize):\n",
        "            yield chunk\n",
        "\n",
        "def _yyyymmdd(dt: datetime) -> int:\n",
        "    return int(dt.strftime(\"%Y%m%d\"))\n",
        "\n",
        "def pick_weekday_date(calendar_df: pd.DataFrame) -> int:\n",
        "    \"\"\"\n",
        "    Pick a reasonable weekday date within the calendar range.\n",
        "    We choose the midpoint of the overlapping weekday-valid range, snapped to Monday.\n",
        "    \"\"\"\n",
        "    c = calendar_df.copy()\n",
        "    c[\"start_date\"] = c[\"start_date\"].astype(int)\n",
        "    c[\"end_date\"] = c[\"end_date\"].astype(int)\n",
        "\n",
        "    wk = c[\n",
        "        (c[\"monday\"]==\"1\") & (c[\"tuesday\"]==\"1\") & (c[\"wednesday\"]==\"1\") &\n",
        "        (c[\"thursday\"]==\"1\") & (c[\"friday\"]==\"1\")\n",
        "    ]\n",
        "    if wk.empty:\n",
        "        wk = c\n",
        "\n",
        "    start = wk[\"start_date\"].max()\n",
        "    end   = wk[\"end_date\"].min()\n",
        "    if start > end:\n",
        "        start = c[\"start_date\"].min()\n",
        "        end   = c[\"end_date\"].max()\n",
        "\n",
        "    start_dt = datetime.strptime(str(start), \"%Y%m%d\")\n",
        "    end_dt   = datetime.strptime(str(end), \"%Y%m%d\")\n",
        "    mid_dt   = start_dt + (end_dt - start_dt)/2\n",
        "\n",
        "    while mid_dt.weekday() != 0:  # Monday\n",
        "        mid_dt += timedelta(days=1)\n",
        "\n",
        "    return _yyyymmdd(mid_dt)\n",
        "\n",
        "def service_ids_active_on_date(calendar_df, calendar_dates_df, target_date_yyyymmdd: int) -> set:\n",
        "    d = str(target_date_yyyymmdd)\n",
        "\n",
        "    base = calendar_df[\n",
        "        (calendar_df[\"start_date\"].astype(int) <= target_date_yyyymmdd) &\n",
        "        (calendar_df[\"end_date\"].astype(int) >= target_date_yyyymmdd)\n",
        "    ].copy()\n",
        "\n",
        "    target_dt = datetime.strptime(d, \"%Y%m%d\")\n",
        "    dow = [\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"sunday\"][target_dt.weekday()]\n",
        "    if dow in base.columns:\n",
        "        base = base[base[dow].astype(str) == \"1\"]\n",
        "\n",
        "    active = set(base[\"service_id\"].astype(str).unique().tolist())\n",
        "\n",
        "    if calendar_dates_df is not None and not calendar_dates_df.empty:\n",
        "        cd = calendar_dates_df[calendar_dates_df[\"date\"].astype(int) == target_date_yyyymmdd].copy()\n",
        "        if not cd.empty:\n",
        "            adds = set(cd.loc[cd[\"exception_type\"].astype(str)==\"1\", \"service_id\"].astype(str))\n",
        "            rems = set(cd.loc[cd[\"exception_type\"].astype(str)==\"2\", \"service_id\"].astype(str))\n",
        "            active |= adds\n",
        "            active -= rems\n",
        "\n",
        "    return active\n",
        "\n",
        "def hour_from_time(t: str):\n",
        "    # GTFS may have >24 (e.g., 25:10:00); that's fine.\n",
        "    try:\n",
        "        return int(str(t).split(\":\")[0])\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# -----------------------------\n",
        "# Core combined computation\n",
        "# -----------------------------\n",
        "def compute_subway_service_variables(\n",
        "    gtfs_zip_path: str,\n",
        "    peak_hour: int = 8,\n",
        "    midday_hour: int = 13,\n",
        "    terminal_mode_top_k: int = 1\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Returns DataFrame keyed by parent_station with:\n",
        "      - peak_trains_per_hour\n",
        "      - midday_trains_per_hour\n",
        "      - subway_lines_serving_station\n",
        "      - is_terminal_subway\n",
        "    \"\"\"\n",
        "\n",
        "    with zipfile.ZipFile(gtfs_zip_path, \"r\") as z:\n",
        "        needed = {\"stops.txt\",\"stop_times.txt\",\"trips.txt\",\"routes.txt\",\"calendar.txt\"}\n",
        "        missing = needed - set(z.namelist())\n",
        "        if missing:\n",
        "            raise RuntimeError(f\"GTFS zip missing required files: {missing}\")\n",
        "\n",
        "        # calendar\n",
        "        calendar = pd.read_csv(z.open(\"calendar.txt\"), dtype=str)\n",
        "        cal_dates = None\n",
        "        if \"calendar_dates.txt\" in z.namelist():\n",
        "            cal_dates = pd.read_csv(z.open(\"calendar_dates.txt\"), dtype=str)\n",
        "\n",
        "        target_date = pick_weekday_date(calendar)\n",
        "        _log(f\"📅 Using representative weekday date: {target_date}\")\n",
        "\n",
        "        active_services = service_ids_active_on_date(calendar, cal_dates, target_date)\n",
        "        _log(f\"✅ Active service_ids on that date: {len(active_services):,}\")\n",
        "\n",
        "        # trips: trip_id -> route_id (filtered to active services)\n",
        "        trips = pd.read_csv(z.open(\"trips.txt\"), dtype=str, usecols=[\"trip_id\",\"service_id\",\"route_id\"])\n",
        "        trips = trips[trips[\"service_id\"].isin(active_services)].dropna(subset=[\"trip_id\",\"route_id\"])\n",
        "        _log(f\"✅ Trips active on that date: {len(trips):,}\")\n",
        "\n",
        "        trip_to_route = trips.set_index(\"trip_id\")[\"route_id\"]\n",
        "        active_trip_ids = set(trips[\"trip_id\"].astype(str).unique())\n",
        "\n",
        "        # routes: route_id -> route_short_name (line label)\n",
        "        routes = pd.read_csv(z.open(\"routes.txt\"), dtype=str, usecols=lambda c: c in {\"route_id\",\"route_short_name\",\"route_long_name\"})\n",
        "        if \"route_short_name\" in routes.columns:\n",
        "            routes[\"line\"] = routes[\"route_short_name\"].astype(str).str.strip()\n",
        "        elif \"route_long_name\" in routes.columns:\n",
        "            routes[\"line\"] = routes[\"route_long_name\"].astype(str).str.strip()\n",
        "        else:\n",
        "            routes[\"line\"] = routes[\"route_id\"].astype(str)\n",
        "\n",
        "        routes[\"line\"] = routes[\"line\"].replace(r\"^\\s*$\", np.nan, regex=True)\n",
        "        route_to_line = routes.set_index(\"route_id\")[\"line\"]\n",
        "\n",
        "        # stops: stop_id -> parent_station\n",
        "        stops = pd.read_csv(z.open(\"stops.txt\"), dtype=str, usecols=lambda c: c in {\"stop_id\",\"parent_station\"})\n",
        "        stops[\"parent_station\"] = stops[\"parent_station\"].fillna(stops[\"stop_id\"])\n",
        "        stop_to_parent = stops.set_index(\"stop_id\")[\"parent_station\"]\n",
        "\n",
        "        # accumulators\n",
        "        peak_tripsets = {}     # parent_station -> set(trip_id)\n",
        "        midday_tripsets = {}   # parent_station -> set(trip_id)\n",
        "        line_sets = {}         # parent_station -> set(line)\n",
        "        trip_endpoints = {}    # trip_id -> (min_seq, min_stop_id, max_seq, max_stop_id)\n",
        "\n",
        "        hours_needed = {peak_hour, midday_hour}\n",
        "\n",
        "        # stream stop_times\n",
        "        for chunk in _iter_gtfs_csv_chunks(\n",
        "            z, \"stop_times.txt\",\n",
        "            usecols=[\"trip_id\",\"stop_id\",\"arrival_time\",\"stop_sequence\"],\n",
        "            dtype={\"trip_id\": str, \"stop_id\": str, \"arrival_time\": str, \"stop_sequence\": str},\n",
        "            chunksize=900_000\n",
        "        ):\n",
        "            # keep only active trips\n",
        "            chunk = chunk[chunk[\"trip_id\"].isin(active_trip_ids)]\n",
        "            if chunk.empty:\n",
        "                continue\n",
        "\n",
        "            # terminal endpoints tracking (needs stop_sequence numeric)\n",
        "            seq = pd.to_numeric(chunk[\"stop_sequence\"], errors=\"coerce\")\n",
        "            chunk = chunk.assign(stop_sequence_num=seq)\n",
        "            chunk = chunk.dropna(subset=[\"stop_sequence_num\"])\n",
        "\n",
        "            # update trip endpoints\n",
        "            # (loop is OK here because active trips are ~few thousands; chunk is large but filtered)\n",
        "            for t_id, grp in chunk.groupby(\"trip_id\"):\n",
        "                mn = grp[\"stop_sequence_num\"].min()\n",
        "                mx = grp[\"stop_sequence_num\"].max()\n",
        "                # stop_id at min/max\n",
        "                mn_stop = grp.loc[grp[\"stop_sequence_num\"].idxmin(), \"stop_id\"]\n",
        "                mx_stop = grp.loc[grp[\"stop_sequence_num\"].idxmax(), \"stop_id\"]\n",
        "\n",
        "                if t_id not in trip_endpoints:\n",
        "                    trip_endpoints[t_id] = (mn, mn_stop, mx, mx_stop)\n",
        "                else:\n",
        "                    prev_mn, prev_mn_stop, prev_mx, prev_mx_stop = trip_endpoints[t_id]\n",
        "                    if mn < prev_mn:\n",
        "                        prev_mn, prev_mn_stop = mn, mn_stop\n",
        "                    if mx > prev_mx:\n",
        "                        prev_mx, prev_mx_stop = mx, mx_stop\n",
        "                    trip_endpoints[t_id] = (prev_mn, prev_mn_stop, prev_mx, prev_mx_stop)\n",
        "\n",
        "            # map to parent_station + line\n",
        "            chunk[\"parent_station\"] = chunk[\"stop_id\"].map(stop_to_parent)\n",
        "            chunk[\"route_id\"] = chunk[\"trip_id\"].map(trip_to_route)\n",
        "            chunk[\"line\"] = chunk[\"route_id\"].map(route_to_line)\n",
        "\n",
        "            # update line sets (weekday service day)\n",
        "            sub = chunk.dropna(subset=[\"parent_station\",\"line\"])\n",
        "            for ps, grp in sub.groupby(\"parent_station\")[\"line\"]:\n",
        "                if ps not in line_sets:\n",
        "                    line_sets[ps] = set()\n",
        "                line_sets[ps].update(grp.dropna().unique().tolist())\n",
        "\n",
        "            # compute hour for peak/midday\n",
        "            hrs = chunk[\"arrival_time\"].map(hour_from_time)\n",
        "            chunk = chunk.assign(hour=hrs)\n",
        "            chunk = chunk[chunk[\"hour\"].isin(hours_needed)]\n",
        "            if chunk.empty:\n",
        "                continue\n",
        "\n",
        "            chunk = chunk.dropna(subset=[\"parent_station\",\"trip_id\",\"hour\"])\n",
        "\n",
        "            # update tripsets per target hour\n",
        "            peak = chunk[chunk[\"hour\"] == peak_hour]\n",
        "            if not peak.empty:\n",
        "                for ps, grp in peak.groupby(\"parent_station\")[\"trip_id\"]:\n",
        "                    peak_tripsets.setdefault(ps, set()).update(grp.unique().tolist())\n",
        "\n",
        "            mid = chunk[chunk[\"hour\"] == midday_hour]\n",
        "            if not mid.empty:\n",
        "                for ps, grp in mid.groupby(\"parent_station\")[\"trip_id\"]:\n",
        "                    midday_tripsets.setdefault(ps, set()).update(grp.unique().tolist())\n",
        "\n",
        "        # Build endpoints DF: infer primary terminals per route (mode endpoints)\n",
        "        # Create per-trip endpoints with route_id\n",
        "        ep_rows = []\n",
        "        for t_id, (mn, mn_stop, mx, mx_stop) in trip_endpoints.items():\n",
        "            r_id = trip_to_route.get(t_id)\n",
        "            if pd.isna(r_id):\n",
        "                continue\n",
        "            start_ps = stop_to_parent.get(mn_stop, mn_stop)\n",
        "            end_ps = stop_to_parent.get(mx_stop, mx_stop)\n",
        "            ep_rows.append((r_id, start_ps, end_ps))\n",
        "\n",
        "        ep = pd.DataFrame(ep_rows, columns=[\"route_id\",\"start_parent\",\"end_parent\"])\n",
        "        # If endpoints empty, no terminals can be inferred\n",
        "        terminal_parents = set()\n",
        "\n",
        "        if not ep.empty:\n",
        "            # For each route, pick the most common start and end parent station as \"primary terminals\"\n",
        "            for r_id, g in ep.groupby(\"route_id\"):\n",
        "                start_mode = g[\"start_parent\"].value_counts().head(terminal_mode_top_k).index.tolist()\n",
        "                end_mode = g[\"end_parent\"].value_counts().head(terminal_mode_top_k).index.tolist()\n",
        "                terminal_parents.update(start_mode)\n",
        "                terminal_parents.update(end_mode)\n",
        "\n",
        "        # Assemble output keyed by parent_station\n",
        "        parents = set()\n",
        "        parents |= set(line_sets.keys())\n",
        "        parents |= set(peak_tripsets.keys())\n",
        "        parents |= set(midday_tripsets.keys())\n",
        "        parents |= terminal_parents\n",
        "\n",
        "        out = pd.DataFrame({\"parent_station\": sorted(parents)})\n",
        "\n",
        "        out[\"peak_trains_per_hour\"] = out[\"parent_station\"].map(lambda ps: len(peak_tripsets.get(ps, set()))).astype(float)\n",
        "        out[\"midday_trains_per_hour\"] = out[\"parent_station\"].map(lambda ps: len(midday_tripsets.get(ps, set()))).astype(float)\n",
        "        out[\"subway_lines_serving_station\"] = out[\"parent_station\"].map(lambda ps: len(line_sets.get(ps, set()))).fillna(0).astype(int)\n",
        "        out[\"is_terminal_subway\"] = out[\"parent_station\"].isin(terminal_parents).astype(int)\n",
        "\n",
        "        return out\n",
        "\n",
        "# -----------------------------\n",
        "# RUN + MERGE INTO station_buffers\n",
        "# -----------------------------\n",
        "gtfs_zip_path = download_first_working(GTFS_SUBWAY_URLS, GTFS_ZIP_PATH)\n",
        "\n",
        "svc = compute_subway_service_variables(\n",
        "    gtfs_zip_path,\n",
        "    peak_hour=PEAK_HOUR,\n",
        "    midday_hour=MIDDAY_HOUR,\n",
        "    terminal_mode_top_k=1  # 1 = most common endpoints only (reduces short-turn noise)\n",
        ")\n",
        "\n",
        "# Merge once\n",
        "cols_to_drop = [\"peak_trains_per_hour\",\"midday_trains_per_hour\",\"subway_lines_serving_station\",\"is_terminal_subway\"]\n",
        "station_buffers = station_buffers.drop(columns=cols_to_drop, errors=\"ignore\")\n",
        "\n",
        "station_buffers = station_buffers.merge(\n",
        "    svc,\n",
        "    left_on=\"stop_id\",\n",
        "    right_on=\"parent_station\",\n",
        "    how=\"left\"\n",
        ").drop(columns=[\"parent_station\"], errors=\"ignore\")\n",
        "\n",
        "# Fill subway (non-IBX) missing values\n",
        "station_buffers[\"peak_trains_per_hour\"] = station_buffers[\"peak_trains_per_hour\"].fillna(0).astype(float)\n",
        "station_buffers[\"midday_trains_per_hour\"] = station_buffers[\"midday_trains_per_hour\"].fillna(0).astype(float)\n",
        "station_buffers[\"subway_lines_serving_station\"] = station_buffers[\"subway_lines_serving_station\"].fillna(0).astype(int)\n",
        "station_buffers[\"is_terminal_subway\"] = station_buffers[\"is_terminal_subway\"].fillna(0).astype(int)\n",
        "\n",
        "# -----------------------------\n",
        "# IBX FILL\n",
        "# -----------------------------\n",
        "# --- IBX defaults should match \"both directions combined\" convention ---\n",
        "DEFAULT_IBX_PEAK_TPH = 24.0    # 12 per direction * 2\n",
        "DEFAULT_IBX_MIDDAY_TPH = 12.0  # 6 per direction * 2\n",
        "\n",
        "is_ibx = station_buffers[\"stop_id\"].astype(str).str.startswith(\"IBX_\")\n",
        "\n",
        "# overwrite IBX values (don’t depend on GTFS for IBX)\n",
        "station_buffers.loc[is_ibx, \"peak_trains_per_hour\"] = DEFAULT_IBX_PEAK_TPH\n",
        "station_buffers.loc[is_ibx, \"midday_trains_per_hour\"] = DEFAULT_IBX_MIDDAY_TPH\n",
        "\n",
        "# if you want to keep terminals from your planning field (already correct)\n",
        "if \"is_terminal\" in station_buffers.columns:\n",
        "    station_buffers.loc[is_ibx, \"is_terminal_subway\"] = (\n",
        "        station_buffers.loc[is_ibx, \"is_terminal\"].fillna(0).astype(int)\n",
        "    )\n",
        "\n",
        "display(\n",
        "    station_buffers.loc[is_ibx, [\"stop_id\",\"stop_name\",\"peak_trains_per_hour\",\"midday_trains_per_hour\",\n",
        "                                 \"subway_lines_serving_station\",\"is_terminal_subway\"]]\n",
        ")\n",
        "\n",
        "\n",
        "_log(\"✅ Combined service variables merged into station_buffers.\")\n",
        "display(station_buffers[[\"stop_id\",\"stop_name\",\"peak_trains_per_hour\",\"midday_trains_per_hour\",\n",
        "                        \"subway_lines_serving_station\",\"is_terminal_subway\"]].tail(19))\n",
        "print(station_buffers[[\"peak_trains_per_hour\",\"midday_trains_per_hour\",\n",
        "                       \"subway_lines_serving_station\",\"is_terminal_subway\"]].describe())\n"
      ],
      "metadata": {
        "id": "X7GWPoFz2YCT",
        "outputId": "799cada7-c7aa-47d6-ed1c-a395d130e69c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using cached GTFS zip: ./gtfs_cache/gtfs_subway.zip\n",
            "📅 Using representative weekday date: 20260302\n",
            "✅ Active service_ids on that date: 1\n",
            "✅ Trips active on that date: 8,492\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    stop_id               stop_name  peak_trains_per_hour  \\\n",
              "499   IBX_1        Roosevelt Avenue                  24.0   \n",
              "500   IBX_2            Grand Avenue                  24.0   \n",
              "501   IBX_3            Eliot Avenue                  24.0   \n",
              "502   IBX_4     Metropolitan Avenue                  24.0   \n",
              "503   IBX_5           Myrtle Avenue                  24.0   \n",
              "504   IBX_6           Wilson Avenue                  24.0   \n",
              "505   IBX_7         Atlantic Avenue                  24.0   \n",
              "506   IBX_8           Sutter Avenue                  24.0   \n",
              "507   IBX_9          Livonia Avenue                  24.0   \n",
              "508  IBX_10             Linden Blvd                  24.0   \n",
              "509  IBX_11           Remsen Avenue                  24.0   \n",
              "510  IBX_12            Utica Avenue                  24.0   \n",
              "511  IBX_13       Flatbush–Nostrand                  24.0   \n",
              "512  IBX_14          East 16 Street                  24.0   \n",
              "513  IBX_15         McDonald Avenue                  24.0   \n",
              "514  IBX_16      New Utrecht Avenue                  24.0   \n",
              "515  IBX_17                8 Avenue                  24.0   \n",
              "516  IBX_18                4 Avenue                  24.0   \n",
              "517  IBX_19  Brooklyn Army Terminal                  24.0   \n",
              "\n",
              "     midday_trains_per_hour  subway_lines_serving_station  is_terminal_subway  \n",
              "499                    12.0                             0                   1  \n",
              "500                    12.0                             0                   0  \n",
              "501                    12.0                             0                   0  \n",
              "502                    12.0                             0                   0  \n",
              "503                    12.0                             0                   0  \n",
              "504                    12.0                             0                   0  \n",
              "505                    12.0                             0                   0  \n",
              "506                    12.0                             0                   0  \n",
              "507                    12.0                             0                   0  \n",
              "508                    12.0                             0                   0  \n",
              "509                    12.0                             0                   0  \n",
              "510                    12.0                             0                   0  \n",
              "511                    12.0                             0                   0  \n",
              "512                    12.0                             0                   0  \n",
              "513                    12.0                             0                   0  \n",
              "514                    12.0                             0                   0  \n",
              "515                    12.0                             0                   0  \n",
              "516                    12.0                             0                   0  \n",
              "517                    12.0                             0                   1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b2e0ed6-fd84-4952-9463-c1910d606904\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>peak_trains_per_hour</th>\n",
              "      <th>midday_trains_per_hour</th>\n",
              "      <th>subway_lines_serving_station</th>\n",
              "      <th>is_terminal_subway</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>IBX_1</td>\n",
              "      <td>Roosevelt Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>IBX_2</td>\n",
              "      <td>Grand Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>IBX_3</td>\n",
              "      <td>Eliot Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>IBX_4</td>\n",
              "      <td>Metropolitan Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>IBX_5</td>\n",
              "      <td>Myrtle Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>IBX_6</td>\n",
              "      <td>Wilson Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>IBX_7</td>\n",
              "      <td>Atlantic Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>IBX_8</td>\n",
              "      <td>Sutter Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>IBX_9</td>\n",
              "      <td>Livonia Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>IBX_10</td>\n",
              "      <td>Linden Blvd</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>IBX_11</td>\n",
              "      <td>Remsen Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>IBX_12</td>\n",
              "      <td>Utica Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>IBX_13</td>\n",
              "      <td>Flatbush–Nostrand</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>IBX_14</td>\n",
              "      <td>East 16 Street</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>IBX_15</td>\n",
              "      <td>McDonald Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>IBX_16</td>\n",
              "      <td>New Utrecht Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>IBX_17</td>\n",
              "      <td>8 Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>IBX_18</td>\n",
              "      <td>4 Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b2e0ed6-fd84-4952-9463-c1910d606904')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b2e0ed6-fd84-4952-9463-c1910d606904 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b2e0ed6-fd84-4952-9463-c1910d606904');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"                       \\\"subway_lines_serving_station\\\",\\\"is_terminal_subway\\\"]]\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"IBX_1\",\n          \"IBX_6\",\n          \"IBX_12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Roosevelt Avenue\",\n          \"Wilson Avenue\",\n          \"Utica Avenue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"peak_trains_per_hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 24.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          24.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"midday_trains_per_hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 12.0,\n        \"max\": 12.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          12.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subway_lines_serving_station\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_terminal_subway\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Combined service variables merged into station_buffers.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    stop_id               stop_name  peak_trains_per_hour  \\\n",
              "499   IBX_1        Roosevelt Avenue                  24.0   \n",
              "500   IBX_2            Grand Avenue                  24.0   \n",
              "501   IBX_3            Eliot Avenue                  24.0   \n",
              "502   IBX_4     Metropolitan Avenue                  24.0   \n",
              "503   IBX_5           Myrtle Avenue                  24.0   \n",
              "504   IBX_6           Wilson Avenue                  24.0   \n",
              "505   IBX_7         Atlantic Avenue                  24.0   \n",
              "506   IBX_8           Sutter Avenue                  24.0   \n",
              "507   IBX_9          Livonia Avenue                  24.0   \n",
              "508  IBX_10             Linden Blvd                  24.0   \n",
              "509  IBX_11           Remsen Avenue                  24.0   \n",
              "510  IBX_12            Utica Avenue                  24.0   \n",
              "511  IBX_13       Flatbush–Nostrand                  24.0   \n",
              "512  IBX_14          East 16 Street                  24.0   \n",
              "513  IBX_15         McDonald Avenue                  24.0   \n",
              "514  IBX_16      New Utrecht Avenue                  24.0   \n",
              "515  IBX_17                8 Avenue                  24.0   \n",
              "516  IBX_18                4 Avenue                  24.0   \n",
              "517  IBX_19  Brooklyn Army Terminal                  24.0   \n",
              "\n",
              "     midday_trains_per_hour  subway_lines_serving_station  is_terminal_subway  \n",
              "499                    12.0                             0                   1  \n",
              "500                    12.0                             0                   0  \n",
              "501                    12.0                             0                   0  \n",
              "502                    12.0                             0                   0  \n",
              "503                    12.0                             0                   0  \n",
              "504                    12.0                             0                   0  \n",
              "505                    12.0                             0                   0  \n",
              "506                    12.0                             0                   0  \n",
              "507                    12.0                             0                   0  \n",
              "508                    12.0                             0                   0  \n",
              "509                    12.0                             0                   0  \n",
              "510                    12.0                             0                   0  \n",
              "511                    12.0                             0                   0  \n",
              "512                    12.0                             0                   0  \n",
              "513                    12.0                             0                   0  \n",
              "514                    12.0                             0                   0  \n",
              "515                    12.0                             0                   0  \n",
              "516                    12.0                             0                   0  \n",
              "517                    12.0                             0                   1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-751de4ff-d655-4dd5-a728-7b07d5803078\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>peak_trains_per_hour</th>\n",
              "      <th>midday_trains_per_hour</th>\n",
              "      <th>subway_lines_serving_station</th>\n",
              "      <th>is_terminal_subway</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>IBX_1</td>\n",
              "      <td>Roosevelt Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>IBX_2</td>\n",
              "      <td>Grand Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>IBX_3</td>\n",
              "      <td>Eliot Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>IBX_4</td>\n",
              "      <td>Metropolitan Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>IBX_5</td>\n",
              "      <td>Myrtle Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>IBX_6</td>\n",
              "      <td>Wilson Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>IBX_7</td>\n",
              "      <td>Atlantic Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>IBX_8</td>\n",
              "      <td>Sutter Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>IBX_9</td>\n",
              "      <td>Livonia Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>IBX_10</td>\n",
              "      <td>Linden Blvd</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>IBX_11</td>\n",
              "      <td>Remsen Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>IBX_12</td>\n",
              "      <td>Utica Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>IBX_13</td>\n",
              "      <td>Flatbush–Nostrand</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>IBX_14</td>\n",
              "      <td>East 16 Street</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>IBX_15</td>\n",
              "      <td>McDonald Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>IBX_16</td>\n",
              "      <td>New Utrecht Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>IBX_17</td>\n",
              "      <td>8 Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>IBX_18</td>\n",
              "      <td>4 Avenue</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-751de4ff-d655-4dd5-a728-7b07d5803078')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-751de4ff-d655-4dd5-a728-7b07d5803078 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-751de4ff-d655-4dd5-a728-7b07d5803078');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"                       \\\"subway_lines_serving_station\\\",\\\"is_terminal_subway\\\"]]\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"IBX_1\",\n          \"IBX_6\",\n          \"IBX_12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Roosevelt Avenue\",\n          \"Wilson Avenue\",\n          \"Utica Avenue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"peak_trains_per_hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 24.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          24.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"midday_trains_per_hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 12.0,\n        \"max\": 12.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          12.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subway_lines_serving_station\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_terminal_subway\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       peak_trains_per_hour  midday_trains_per_hour  \\\n",
            "count            518.000000              518.000000   \n",
            "mean              29.075290               22.862934   \n",
            "std               16.896091               12.278464   \n",
            "min                0.000000                0.000000   \n",
            "25%               17.000000               15.000000   \n",
            "50%               25.000000               20.000000   \n",
            "75%               37.000000               30.000000   \n",
            "max               85.000000               65.000000   \n",
            "\n",
            "       subway_lines_serving_station  is_terminal_subway  \n",
            "count                    518.000000          518.000000  \n",
            "mean                       1.976834            0.067568  \n",
            "std                        1.105396            0.251245  \n",
            "min                        0.000000            0.000000  \n",
            "25%                        1.000000            0.000000  \n",
            "50%                        2.000000            0.000000  \n",
            "75%                        3.000000            0.000000  \n",
            "max                        6.000000            1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# ANCHOR VARIABLES (PARAMETERIZED RADII + BEST-PRACTICE)\n",
        "#\n",
        "# Adds RAW + CAPPED + BINARY for Cultural at both radii:\n",
        "#   - cultural_count_0p25mi, cultural_count_0p5mi                (raw)\n",
        "#   - cultural_count_0p25mi_capped10, cultural_count_0p5mi_capped10\n",
        "#   - has_cultural_0p25mi, has_cultural_0p5mi                    (binary)\n",
        "#\n",
        "# Existing outputs retained:\n",
        "#   Universities:\n",
        "#     has_university_0p25mi, has_university_0p5mi\n",
        "#   Hospitals (tight definition):\n",
        "#     has_hospital_0p25mi, has_hospital_0p5mi\n",
        "#   Stadiums/Arenas (tight):\n",
        "#     has_stadium_0p1mi\n",
        "#   Parks (big parks adjacency flags):\n",
        "#     adjacent_major_park_0p25mi, adjacent_major_park_0p5mi\n",
        "#\n",
        "# Notes:\n",
        "# - Uses station centroids for point-based buffers.\n",
        "# - Facilities dataset sometimes lacks geometry; we build points from lat/lon if needed.\n",
        "#\n",
        "# Requires:\n",
        "# - station_buffers: GeoDataFrame with [\"stop_id\",\"stop_name\",\"geometry\"] in projected CRS (EPSG:2263 recommended)\n",
        "# =========================================================\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from shapely.geometry import shape\n",
        "\n",
        "DEBUG = True\n",
        "def _log(msg: str):\n",
        "    if DEBUG:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Validate station_buffers\n",
        "# -----------------------------\n",
        "req = {\"stop_id\", \"stop_name\", \"geometry\"}\n",
        "missing = req - set(station_buffers.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"station_buffers missing required columns: {missing}\")\n",
        "if station_buffers.crs is None:\n",
        "    raise ValueError(\"station_buffers.crs is None. Please project station_buffers to a projected CRS (e.g., EPSG:2263).\")\n",
        "\n",
        "# -----------------------------\n",
        "# Config: radii\n",
        "# -----------------------------\n",
        "FEET_PER_MILE = 5280.0\n",
        "R_UNIV = [0.25, 0.50]\n",
        "R_HOSP = [0.25, 0.50]\n",
        "R_CULT = [0.25, 0.50]\n",
        "R_PARK = [0.25, 0.50]\n",
        "R_STAD = 0.10\n",
        "\n",
        "# Cultural groups to include (tight)\n",
        "CULT_GROUPS = {\n",
        "    \"CULTURAL INSTITUTIONS\",\n",
        "    \"HISTORICAL SITES\",\n",
        "    # \"LIBRARIES\",  # uncomment if you want libraries included\n",
        "}\n",
        "\n",
        "# Cultural refinements\n",
        "CULT_CAP = 10  # cap counts at 10 (Winsorize)\n",
        "\n",
        "# -----------------------------\n",
        "# Socrata paging helpers\n",
        "# -----------------------------\n",
        "def socrata_paged(url, limit=50000, where=None, select=None, timeout=120):\n",
        "    offset = 0\n",
        "    rows = []\n",
        "    while True:\n",
        "        params = {\"$limit\": limit, \"$offset\": offset}\n",
        "        if where:  params[\"$where\"] = where\n",
        "        if select: params[\"$select\"] = select\n",
        "\n",
        "        r = requests.get(url, params=params, timeout=timeout)\n",
        "        r.raise_for_status()\n",
        "        js = r.json()\n",
        "\n",
        "        if isinstance(js, dict) and \"features\" in js:\n",
        "            feats = js.get(\"features\", [])\n",
        "            if not feats:\n",
        "                break\n",
        "            rows.extend(feats)\n",
        "            _log(f\"⬇️ Loaded {len(feats):,} features (offset={offset:,})\")\n",
        "            if len(feats) < limit:\n",
        "                break\n",
        "        elif isinstance(js, list):\n",
        "            if not js:\n",
        "                break\n",
        "            rows.extend(js)\n",
        "            _log(f\"⬇️ Loaded {len(js):,} rows (offset={offset:,})\")\n",
        "            if len(js) < limit:\n",
        "                break\n",
        "        else:\n",
        "            raise ValueError(\"Unexpected Socrata response format.\")\n",
        "\n",
        "        offset += limit\n",
        "\n",
        "    return rows\n",
        "\n",
        "def facilities_to_gdf(features):\n",
        "    props = []\n",
        "    geoms = []\n",
        "    for f in features:\n",
        "        p = f.get(\"properties\", {}) if isinstance(f, dict) else {}\n",
        "        g = f.get(\"geometry\", None) if isinstance(f, dict) else None\n",
        "        props.append(p)\n",
        "        geoms.append(shape(g) if g else None)\n",
        "\n",
        "    df = pd.DataFrame(props)\n",
        "    gdf = gpd.GeoDataFrame(df, geometry=geoms, crs=\"EPSG:4326\")\n",
        "\n",
        "    # If geometry is missing, build points from lon/lat\n",
        "    if gdf.geometry.isna().all():\n",
        "        lon_col = next((c for c in gdf.columns if c.lower() == \"longitude\"), None)\n",
        "        lat_col = next((c for c in gdf.columns if c.lower() == \"latitude\"), None)\n",
        "        if lon_col and lat_col:\n",
        "            gdf[lon_col] = pd.to_numeric(gdf[lon_col], errors=\"coerce\")\n",
        "            gdf[lat_col] = pd.to_numeric(gdf[lat_col], errors=\"coerce\")\n",
        "            gdf = gdf.dropna(subset=[lon_col, lat_col]).copy()\n",
        "            gdf = gpd.GeoDataFrame(\n",
        "                gdf.drop(columns=[\"geometry\"], errors=\"ignore\"),\n",
        "                geometry=gpd.points_from_xy(gdf[lon_col], gdf[lat_col]),\n",
        "                crs=\"EPSG:4326\"\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\"Facilities has no geometry and no longitude/latitude to build points.\")\n",
        "\n",
        "    gdf = gdf.dropna(subset=[\"geometry\"]).copy()\n",
        "    return gdf\n",
        "\n",
        "def parks_to_gdf(features):\n",
        "    props = []\n",
        "    geoms = []\n",
        "    for f in features:\n",
        "        p = f.get(\"properties\", {}) if isinstance(f, dict) else {}\n",
        "        g = f.get(\"geometry\", None) if isinstance(f, dict) else None\n",
        "        props.append(p)\n",
        "        geoms.append(shape(g) if g else None)\n",
        "    parks = gpd.GeoDataFrame(pd.DataFrame(props), geometry=geoms, crs=\"EPSG:4326\")\n",
        "    parks = parks.dropna(subset=[\"geometry\"]).copy()\n",
        "    return parks\n",
        "\n",
        "def norm_upper(s):\n",
        "    return s.astype(str).str.strip().str.upper()\n",
        "\n",
        "# -----------------------------\n",
        "# Station centroids (points)\n",
        "# -----------------------------\n",
        "station_pts = station_buffers[[\"stop_id\",\"stop_name\",\"geometry\"]].drop_duplicates().copy()\n",
        "station_pts[\"geometry\"] = station_pts.geometry.centroid\n",
        "station_pts = gpd.GeoDataFrame(station_pts, geometry=\"geometry\", crs=station_buffers.crs)\n",
        "\n",
        "# -----------------------------\n",
        "# Load Facilities (NYC Open Data)\n",
        "# -----------------------------\n",
        "FAC_URL = \"https://data.cityofnewyork.us/resource/ji82-xba5.geojson\"\n",
        "_log(\"Loading DCP Facilities Database (paged)…\")\n",
        "fac_feats = socrata_paged(FAC_URL, limit=50000)\n",
        "fac = facilities_to_gdf(fac_feats)\n",
        "_log(f\"✅ Facilities loaded with geometry: {len(fac):,}\")\n",
        "\n",
        "# Project to station CRS\n",
        "fac = fac.to_crs(station_buffers.crs)\n",
        "\n",
        "# Standardize key fields\n",
        "for c in [\"facgroup\", \"facsubgrp\", \"facname\"]:\n",
        "    if c not in fac.columns:\n",
        "        raise ValueError(f\"Expected column '{c}' not found in facilities. Columns: {list(fac.columns)[:50]}\")\n",
        "fac[\"FACGROUP_U\"]  = norm_upper(fac[\"facgroup\"])\n",
        "fac[\"FACSUBGRP_U\"] = norm_upper(fac[\"facsubgrp\"])\n",
        "fac[\"FACNAME_L\"]   = fac[\"facname\"].astype(str).str.strip().str.lower()\n",
        "\n",
        "# -----------------------------\n",
        "# Helper: compute 0/1 flag within radius using station point buffers\n",
        "# -----------------------------\n",
        "def flag_within_radius(points_gdf, station_points, radii_miles, prefix):\n",
        "    out = station_buffers\n",
        "    for r in radii_miles:\n",
        "        out_col = f\"{prefix}_{str(r).replace('.','p')}mi\"\n",
        "        radius_ft = r * FEET_PER_MILE\n",
        "\n",
        "        buf = station_points[[\"stop_id\",\"geometry\"]].copy()\n",
        "        buf[\"geometry\"] = buf.geometry.buffer(radius_ft)\n",
        "        buf = gpd.GeoDataFrame(buf, geometry=\"geometry\", crs=station_points.crs)\n",
        "\n",
        "        sj = gpd.sjoin(\n",
        "            points_gdf[[\"geometry\"]],\n",
        "            buf[[\"stop_id\",\"geometry\"]],\n",
        "            how=\"inner\",\n",
        "            predicate=\"within\"\n",
        "        )\n",
        "        hit_ids = set(sj[\"stop_id\"].astype(str).unique())\n",
        "        out = out.drop(columns=[out_col], errors=\"ignore\")\n",
        "        out[out_col] = out[\"stop_id\"].astype(str).isin(hit_ids).astype(int)\n",
        "\n",
        "        _log(f\"✅ {out_col}: flagged={out[out_col].sum()} (radius={r}mi)\")\n",
        "    return out\n",
        "\n",
        "# -----------------------------\n",
        "# Helper: compute COUNT within radius using station point buffers\n",
        "# -----------------------------\n",
        "def count_within_radius(points_gdf, station_points, radii_miles, prefix):\n",
        "    out = station_buffers\n",
        "    for r in radii_miles:\n",
        "        out_col = f\"{prefix}_{str(r).replace('.','p')}mi\"\n",
        "        radius_ft = r * FEET_PER_MILE\n",
        "\n",
        "        buf = station_points[[\"stop_id\",\"geometry\"]].copy()\n",
        "        buf[\"geometry\"] = buf.geometry.buffer(radius_ft)\n",
        "        buf = gpd.GeoDataFrame(buf, geometry=\"geometry\", crs=station_points.crs)\n",
        "\n",
        "        sj = gpd.sjoin(\n",
        "            points_gdf[[\"geometry\"]],\n",
        "            buf[[\"stop_id\",\"geometry\"]],\n",
        "            how=\"inner\",\n",
        "            predicate=\"within\"\n",
        "        )\n",
        "        counts = sj.groupby(\"stop_id\").size()\n",
        "        out = out.drop(columns=[out_col], errors=\"ignore\")\n",
        "        out[out_col] = out[\"stop_id\"].map(counts).fillna(0).astype(int)\n",
        "\n",
        "        _log(f\"✅ {out_col}: mean={out[out_col].mean():.2f}, max={out[out_col].max()} (radius={r}mi)\")\n",
        "    return out\n",
        "\n",
        "# =========================================================\n",
        "# 1) UNIVERSITY / COLLEGE — structured filter\n",
        "# =========================================================\n",
        "univ = fac[\n",
        "    (fac[\"FACGROUP_U\"] == \"HIGHER EDUCATION\") &\n",
        "    (fac[\"FACSUBGRP_U\"] == \"COLLEGES OR UNIVERSITIES\")\n",
        "].copy()\n",
        "\n",
        "univ_pts = univ.copy()\n",
        "univ_pts[\"geometry\"] = univ_pts.geometry.centroid\n",
        "\n",
        "station_buffers = flag_within_radius(univ_pts, station_pts, R_UNIV, \"has_university\")\n",
        "\n",
        "# =========================================================\n",
        "# 2) HOSPITAL — tighter: structured + name contains 'hospital'\n",
        "# =========================================================\n",
        "hosp = fac[\n",
        "    (fac[\"FACGROUP_U\"] == \"HEALTH CARE\") &\n",
        "    (fac[\"FACSUBGRP_U\"] == \"HOSPITALS AND CLINICS\") &\n",
        "    (fac[\"FACNAME_L\"].str.contains(\"hospital\", na=False))\n",
        "].copy()\n",
        "\n",
        "hosp_pts = hosp.copy()\n",
        "hosp_pts[\"geometry\"] = hosp_pts.geometry.centroid\n",
        "\n",
        "station_buffers = flag_within_radius(hosp_pts, station_pts, R_HOSP, \"has_hospital\")\n",
        "\n",
        "# =========================================================\n",
        "# 3) STADIUM / ARENA — manual list + 0.10mi radius (tight)\n",
        "# =========================================================\n",
        "major_venues = pd.DataFrame([\n",
        "    (\"Yankee Stadium\", 40.829643, -73.926175),\n",
        "    (\"Citi Field\", 40.757088, -73.845821),\n",
        "    (\"Madison Square Garden\", 40.750504, -73.993439),\n",
        "    (\"Barclays Center\", 40.682650, -73.975370),\n",
        "    (\"USTA Billie Jean King / Arthur Ashe\", 40.749824, -73.847147),\n",
        "], columns=[\"venue\", \"lat\", \"lon\"])\n",
        "\n",
        "venues_gdf = gpd.GeoDataFrame(\n",
        "    major_venues,\n",
        "    geometry=gpd.points_from_xy(major_venues[\"lon\"], major_venues[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(station_buffers.crs)\n",
        "\n",
        "# Create has_stadium_0p1mi\n",
        "station_buffers = flag_within_radius(venues_gdf, station_pts, [R_STAD], \"has_stadium\")\n",
        "\n",
        "# =========================================================\n",
        "# 4) CULTURAL — structured groups, COUNT at two radii (RAW)\n",
        "#     Then add:\n",
        "#       - BINARY presence\n",
        "#       - CAPPED count (upper=CULT_CAP)\n",
        "# =========================================================\n",
        "cult = fac[fac[\"FACGROUP_U\"].isin(CULT_GROUPS)].copy()\n",
        "cult_pts = cult.copy()\n",
        "cult_pts[\"geometry\"] = cult_pts.geometry.centroid\n",
        "\n",
        "# Raw counts\n",
        "station_buffers = count_within_radius(cult_pts, station_pts, R_CULT, \"cultural_count\")\n",
        "\n",
        "# Add binary + capped for each radius\n",
        "for r in R_CULT:\n",
        "    base = f\"{str(r).replace('.','p')}mi\"\n",
        "    raw_col   = f\"cultural_count_{base}\"\n",
        "    bin_col   = f\"has_cultural_{base}\"\n",
        "    cap_col   = f\"cultural_count_{base}_capped{CULT_CAP}\"\n",
        "\n",
        "    station_buffers = station_buffers.drop(columns=[bin_col, cap_col], errors=\"ignore\")\n",
        "    station_buffers[bin_col] = (station_buffers[raw_col] > 0).astype(int)\n",
        "    station_buffers[cap_col] = station_buffers[raw_col].clip(upper=CULT_CAP).astype(int)\n",
        "\n",
        "    _log(f\"✅ {bin_col} + {cap_col} created (raw={raw_col})\")\n",
        "\n",
        "# =========================================================\n",
        "# 5) MAJOR PARK adjacency (>=50 acres) — parks polygons\n",
        "# =========================================================\n",
        "PARKS_URL = \"https://data.cityofnewyork.us/resource/enfh-gkve.geojson\"\n",
        "_log(\"Loading NYC Parks Properties (paged)…\")\n",
        "park_feats = socrata_paged(PARKS_URL, limit=50000)\n",
        "parks = parks_to_gdf(park_feats)\n",
        "_log(f\"✅ Parks loaded with geometry: {len(parks):,}\")\n",
        "\n",
        "parks = parks.to_crs(station_buffers.crs)\n",
        "\n",
        "# Big parks\n",
        "ACRE_TO_SQFT = 43560.0\n",
        "parks[\"area_sqft\"] = parks.geometry.area\n",
        "parks_big = parks[parks[\"area_sqft\"] >= 50 * ACRE_TO_SQFT].copy()\n",
        "_log(f\"✅ Major parks (>=50 acres): {len(parks_big):,}\")\n",
        "\n",
        "# adjacency flag for each radius: station point buffer intersects park polygons\n",
        "for r in R_PARK:\n",
        "    out_col = f\"adjacent_major_park_{str(r).replace('.','p')}mi\"\n",
        "    radius_ft = r * FEET_PER_MILE\n",
        "\n",
        "    buf = station_pts[[\"stop_id\",\"geometry\"]].copy()\n",
        "    buf[\"geometry\"] = buf.geometry.buffer(radius_ft)\n",
        "    buf = gpd.GeoDataFrame(buf, geometry=\"geometry\", crs=station_pts.crs)\n",
        "\n",
        "    sj = gpd.sjoin(\n",
        "        buf[[\"stop_id\",\"geometry\"]],\n",
        "        parks_big[[\"geometry\"]],\n",
        "        how=\"inner\",\n",
        "        predicate=\"intersects\"\n",
        "    )\n",
        "    hit_ids = set(sj[\"stop_id\"].astype(str).unique())\n",
        "    station_buffers = station_buffers.drop(columns=[out_col], errors=\"ignore\")\n",
        "    station_buffers[out_col] = station_buffers[\"stop_id\"].astype(str).isin(hit_ids).astype(int)\n",
        "\n",
        "    _log(f\"✅ {out_col}: flagged={station_buffers[out_col].sum()} (radius={r}mi)\")\n",
        "\n",
        "# -----------------------------\n",
        "# Cleanup helper cols (optional)\n",
        "# -----------------------------\n",
        "station_buffers = station_buffers.drop(columns=[\"FACGROUP_U\",\"FACSUBGRP_U\",\"FACNAME_L\"], errors=\"ignore\")\n",
        "\n",
        "# -----------------------------\n",
        "# Preview (choose which columns you want in the final model)\n",
        "# -----------------------------\n",
        "cols_preview = [\n",
        "    \"stop_id\",\"stop_name\",\n",
        "    \"has_university_0p25mi\",\"has_university_0p5mi\",\n",
        "    \"has_hospital_0p25mi\",\"has_hospital_0p5mi\",\n",
        "    \"has_stadium_0p1mi\",\n",
        "    \"cultural_count_0p25mi\",\"cultural_count_0p25mi_capped10\",\"has_cultural_0p25mi\",\n",
        "    \"cultural_count_0p5mi\",\"cultural_count_0p5mi_capped10\",\"has_cultural_0p5mi\",\n",
        "    \"adjacent_major_park_0p25mi\",\"adjacent_major_park_0p5mi\",\n",
        "]\n",
        "existing = [c for c in cols_preview if c in station_buffers.columns]\n",
        "\n",
        "_log(\"✅ Anchor variables (parameterized radii + cultural raw/cap/binary) complete.\")\n",
        "display(station_buffers[existing].tail(40))\n",
        "\n",
        "print(\"\\nCultural raw (0.25mi) summary:\\n\", station_buffers[\"cultural_count_0p25mi\"].describe())\n",
        "print(\"\\nCultural capped (0.25mi) summary:\\n\", station_buffers[\"cultural_count_0p25mi_capped10\"].describe())\n",
        "print(\"\\nCultural binary (0.25mi):\\n\", station_buffers[\"has_cultural_0p25mi\"].value_counts())\n",
        "\n",
        "print(\"\\nCultural raw (0.5mi) summary:\\n\", station_buffers[\"cultural_count_0p5mi\"].describe())\n",
        "print(\"\\nCultural capped (0.5mi) summary:\\n\", station_buffers[\"cultural_count_0p5mi_capped10\"].describe())\n",
        "print(\"\\nCultural binary (0.5mi):\\n\", station_buffers[\"has_cultural_0p5mi\"].value_counts())\n"
      ],
      "metadata": {
        "id": "Ou13ynwxCX2R",
        "outputId": "fcacd668-1074-4988-9ef8-2d9474d82d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DCP Facilities Database (paged)…\n",
            "⬇️ Loaded 34,708 features (offset=0)\n",
            "✅ Facilities loaded with geometry: 34,708\n",
            "✅ has_university_0p25mi: flagged=113 (radius=0.25mi)\n",
            "✅ has_university_0p5mi: flagged=217 (radius=0.5mi)\n",
            "✅ has_hospital_0p25mi: flagged=39 (radius=0.25mi)\n",
            "✅ has_hospital_0p5mi: flagged=122 (radius=0.5mi)\n",
            "✅ has_stadium_0p1mi: flagged=0 (radius=0.1mi)\n",
            "✅ cultural_count_0p25mi: mean=9.97, max=82 (radius=0.25mi)\n",
            "✅ cultural_count_0p5mi: mean=34.11, max=207 (radius=0.5mi)\n",
            "✅ has_cultural_0p25mi + cultural_count_0p25mi_capped10 created (raw=cultural_count_0p25mi)\n",
            "✅ has_cultural_0p5mi + cultural_count_0p5mi_capped10 created (raw=cultural_count_0p5mi)\n",
            "Loading NYC Parks Properties (paged)…\n",
            "⬇️ Loaded 2,056 features (offset=0)\n",
            "✅ Parks loaded with geometry: 2,056\n",
            "✅ Major parks (>=50 acres): 95\n",
            "✅ adjacent_major_park_0p25mi: flagged=87 (radius=0.25mi)\n",
            "✅ adjacent_major_park_0p5mi: flagged=163 (radius=0.5mi)\n",
            "✅ Anchor variables (parameterized radii + cultural raw/cap/binary) complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    stop_id               stop_name  has_university_0p25mi  \\\n",
              "478     S09             Tottenville                      0   \n",
              "479     S11             Arthur Kill                      0   \n",
              "480     S13         Richmond Valley                      0   \n",
              "481     S14         Pleasant Plains                      0   \n",
              "482     S15            Prince's Bay                      0   \n",
              "483     S16                Huguenot                      0   \n",
              "484     S17                Annadale                      0   \n",
              "485     S18             Eltingville                      0   \n",
              "486     S19             Great Kills                      0   \n",
              "487     S20             Bay Terrace                      0   \n",
              "488     S21         Oakwood Heights                      0   \n",
              "489     S22                New Dorp                      0   \n",
              "490     S23              Grant City                      0   \n",
              "491     S24            Jefferson Av                      0   \n",
              "492     S25            Dongan Hills                      0   \n",
              "493     S26                Old Town                      0   \n",
              "494     S27                Grasmere                      0   \n",
              "495     S28                 Clifton                      0   \n",
              "496     S29               Stapleton                      0   \n",
              "497     S30           Tompkinsville                      0   \n",
              "498     S31               St George                      0   \n",
              "499   IBX_1        Roosevelt Avenue                      0   \n",
              "500   IBX_2            Grand Avenue                      0   \n",
              "501   IBX_3            Eliot Avenue                      0   \n",
              "502   IBX_4     Metropolitan Avenue                      0   \n",
              "503   IBX_5           Myrtle Avenue                      0   \n",
              "504   IBX_6           Wilson Avenue                      0   \n",
              "505   IBX_7         Atlantic Avenue                      0   \n",
              "506   IBX_8           Sutter Avenue                      0   \n",
              "507   IBX_9          Livonia Avenue                      0   \n",
              "508  IBX_10             Linden Blvd                      0   \n",
              "509  IBX_11           Remsen Avenue                      0   \n",
              "510  IBX_12            Utica Avenue                      0   \n",
              "511  IBX_13       Flatbush–Nostrand                      0   \n",
              "512  IBX_14          East 16 Street                      0   \n",
              "513  IBX_15         McDonald Avenue                      0   \n",
              "514  IBX_16      New Utrecht Avenue                      0   \n",
              "515  IBX_17                8 Avenue                      0   \n",
              "516  IBX_18                4 Avenue                      0   \n",
              "517  IBX_19  Brooklyn Army Terminal                      0   \n",
              "\n",
              "     has_university_0p5mi  has_hospital_0p25mi  has_hospital_0p5mi  \\\n",
              "478                     0                    0                   0   \n",
              "479                     0                    0                   0   \n",
              "480                     0                    0                   0   \n",
              "481                     0                    0                   0   \n",
              "482                     0                    0                   0   \n",
              "483                     0                    0                   0   \n",
              "484                     0                    0                   0   \n",
              "485                     0                    0                   0   \n",
              "486                     0                    0                   0   \n",
              "487                     0                    0                   0   \n",
              "488                     0                    0                   0   \n",
              "489                     0                    0                   0   \n",
              "490                     0                    0                   0   \n",
              "491                     0                    0                   0   \n",
              "492                     0                    0                   0   \n",
              "493                     0                    0                   0   \n",
              "494                     0                    0                   0   \n",
              "495                     0                    0                   0   \n",
              "496                     0                    0                   0   \n",
              "497                     0                    0                   0   \n",
              "498                     0                    0                   0   \n",
              "499                     0                    0                   1   \n",
              "500                     0                    0                   0   \n",
              "501                     0                    0                   0   \n",
              "502                     0                    0                   0   \n",
              "503                     0                    0                   0   \n",
              "504                     0                    0                   0   \n",
              "505                     0                    0                   0   \n",
              "506                     0                    0                   0   \n",
              "507                     0                    0                   0   \n",
              "508                     0                    0                   1   \n",
              "509                     0                    0                   1   \n",
              "510                     0                    0                   0   \n",
              "511                     1                    0                   0   \n",
              "512                     1                    0                   0   \n",
              "513                     0                    0                   0   \n",
              "514                     0                    0                   0   \n",
              "515                     0                    0                   0   \n",
              "516                     0                    0                   0   \n",
              "517                     0                    0                   0   \n",
              "\n",
              "     has_stadium_0p1mi  cultural_count_0p25mi  cultural_count_0p25mi_capped10  \\\n",
              "478                  0                      0                               0   \n",
              "479                  0                      0                               0   \n",
              "480                  0                      0                               0   \n",
              "481                  0                      0                               0   \n",
              "482                  0                      1                               1   \n",
              "483                  0                      0                               0   \n",
              "484                  0                      0                               0   \n",
              "485                  0                      2                               2   \n",
              "486                  0                      0                               0   \n",
              "487                  0                      0                               0   \n",
              "488                  0                      0                               0   \n",
              "489                  0                      0                               0   \n",
              "490                  0                      0                               0   \n",
              "491                  0                      0                               0   \n",
              "492                  0                      0                               0   \n",
              "493                  0                      1                               1   \n",
              "494                  0                      0                               0   \n",
              "495                  0                      1                               1   \n",
              "496                  0                      7                               7   \n",
              "497                  0                      1                               1   \n",
              "498                  0                      5                               5   \n",
              "499                  0                      3                               3   \n",
              "500                  0                      1                               1   \n",
              "501                  0                      0                               0   \n",
              "502                  0                      1                               1   \n",
              "503                  0                      3                               3   \n",
              "504                  0                      2                               2   \n",
              "505                  0                      1                               1   \n",
              "506                  0                      0                               0   \n",
              "507                  0                      1                               1   \n",
              "508                  0                      1                               1   \n",
              "509                  0                      0                               0   \n",
              "510                  0                      0                               0   \n",
              "511                  0                      0                               0   \n",
              "512                  0                      1                               1   \n",
              "513                  0                      0                               0   \n",
              "514                  0                      0                               0   \n",
              "515                  0                      0                               0   \n",
              "516                  0                      4                               4   \n",
              "517                  0                      0                               0   \n",
              "\n",
              "     has_cultural_0p25mi  cultural_count_0p5mi  cultural_count_0p5mi_capped10  \\\n",
              "478                    0                     0                              0   \n",
              "479                    0                     0                              0   \n",
              "480                    0                     0                              0   \n",
              "481                    0                     0                              0   \n",
              "482                    1                     1                              1   \n",
              "483                    0                     0                              0   \n",
              "484                    0                     0                              0   \n",
              "485                    1                     2                              2   \n",
              "486                    0                     0                              0   \n",
              "487                    0                     0                              0   \n",
              "488                    0                     0                              0   \n",
              "489                    0                     1                              1   \n",
              "490                    0                     0                              0   \n",
              "491                    0                     0                              0   \n",
              "492                    0                     1                              1   \n",
              "493                    1                     1                              1   \n",
              "494                    0                     0                              0   \n",
              "495                    1                     8                              8   \n",
              "496                    1                    13                             10   \n",
              "497                    1                     8                              8   \n",
              "498                    1                     6                              6   \n",
              "499                    1                     8                              8   \n",
              "500                    1                     1                              1   \n",
              "501                    0                     0                              0   \n",
              "502                    1                     3                              3   \n",
              "503                    1                     9                              9   \n",
              "504                    1                     3                              3   \n",
              "505                    1                     2                              2   \n",
              "506                    0                     2                              2   \n",
              "507                    1                     3                              3   \n",
              "508                    1                     3                              3   \n",
              "509                    0                     1                              1   \n",
              "510                    0                     3                              3   \n",
              "511                    0                     4                              4   \n",
              "512                    1                     6                              6   \n",
              "513                    0                     0                              0   \n",
              "514                    0                     4                              4   \n",
              "515                    0                     0                              0   \n",
              "516                    1                    10                             10   \n",
              "517                    0                     2                              2   \n",
              "\n",
              "     has_cultural_0p5mi  adjacent_major_park_0p25mi  adjacent_major_park_0p5mi  \n",
              "478                   0                           0                          1  \n",
              "479                   0                           0                          1  \n",
              "480                   0                           1                          1  \n",
              "481                   0                           0                          1  \n",
              "482                   1                           1                          1  \n",
              "483                   0                           1                          1  \n",
              "484                   0                           0                          1  \n",
              "485                   1                           0                          1  \n",
              "486                   0                           0                          0  \n",
              "487                   0                           0                          1  \n",
              "488                   0                           1                          1  \n",
              "489                   1                           0                          1  \n",
              "490                   0                           0                          0  \n",
              "491                   0                           0                          0  \n",
              "492                   1                           0                          0  \n",
              "493                   1                           0                          1  \n",
              "494                   0                           0                          0  \n",
              "495                   1                           0                          0  \n",
              "496                   1                           0                          0  \n",
              "497                   1                           0                          0  \n",
              "498                   1                           0                          0  \n",
              "499                   1                           0                          0  \n",
              "500                   1                           0                          0  \n",
              "501                   0                           0                          1  \n",
              "502                   1                           0                          1  \n",
              "503                   1                           0                          0  \n",
              "504                   1                           0                          1  \n",
              "505                   1                           0                          0  \n",
              "506                   1                           0                          0  \n",
              "507                   1                           0                          0  \n",
              "508                   1                           0                          0  \n",
              "509                   1                           0                          0  \n",
              "510                   1                           0                          0  \n",
              "511                   1                           0                          0  \n",
              "512                   1                           0                          0  \n",
              "513                   0                           0                          0  \n",
              "514                   1                           0                          0  \n",
              "515                   0                           0                          0  \n",
              "516                   1                           0                          0  \n",
              "517                   1                           1                          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfb5e390-00b5-4973-aa4f-0fea2b60f7cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_name</th>\n",
              "      <th>has_university_0p25mi</th>\n",
              "      <th>has_university_0p5mi</th>\n",
              "      <th>has_hospital_0p25mi</th>\n",
              "      <th>has_hospital_0p5mi</th>\n",
              "      <th>has_stadium_0p1mi</th>\n",
              "      <th>cultural_count_0p25mi</th>\n",
              "      <th>cultural_count_0p25mi_capped10</th>\n",
              "      <th>has_cultural_0p25mi</th>\n",
              "      <th>cultural_count_0p5mi</th>\n",
              "      <th>cultural_count_0p5mi_capped10</th>\n",
              "      <th>has_cultural_0p5mi</th>\n",
              "      <th>adjacent_major_park_0p25mi</th>\n",
              "      <th>adjacent_major_park_0p5mi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>S09</td>\n",
              "      <td>Tottenville</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>S11</td>\n",
              "      <td>Arthur Kill</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>S13</td>\n",
              "      <td>Richmond Valley</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>S14</td>\n",
              "      <td>Pleasant Plains</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>S15</td>\n",
              "      <td>Prince's Bay</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>S16</td>\n",
              "      <td>Huguenot</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>S17</td>\n",
              "      <td>Annadale</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>S18</td>\n",
              "      <td>Eltingville</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>S19</td>\n",
              "      <td>Great Kills</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>S20</td>\n",
              "      <td>Bay Terrace</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>S21</td>\n",
              "      <td>Oakwood Heights</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>S22</td>\n",
              "      <td>New Dorp</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>S23</td>\n",
              "      <td>Grant City</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>S24</td>\n",
              "      <td>Jefferson Av</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>S25</td>\n",
              "      <td>Dongan Hills</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>S26</td>\n",
              "      <td>Old Town</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>S27</td>\n",
              "      <td>Grasmere</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>S28</td>\n",
              "      <td>Clifton</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>S29</td>\n",
              "      <td>Stapleton</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>S30</td>\n",
              "      <td>Tompkinsville</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>S31</td>\n",
              "      <td>St George</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>IBX_1</td>\n",
              "      <td>Roosevelt Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>IBX_2</td>\n",
              "      <td>Grand Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>IBX_3</td>\n",
              "      <td>Eliot Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>IBX_4</td>\n",
              "      <td>Metropolitan Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>IBX_5</td>\n",
              "      <td>Myrtle Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>IBX_6</td>\n",
              "      <td>Wilson Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>IBX_7</td>\n",
              "      <td>Atlantic Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>IBX_8</td>\n",
              "      <td>Sutter Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>IBX_9</td>\n",
              "      <td>Livonia Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>IBX_10</td>\n",
              "      <td>Linden Blvd</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>IBX_11</td>\n",
              "      <td>Remsen Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>IBX_12</td>\n",
              "      <td>Utica Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>IBX_13</td>\n",
              "      <td>Flatbush–Nostrand</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>IBX_14</td>\n",
              "      <td>East 16 Street</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>IBX_15</td>\n",
              "      <td>McDonald Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>IBX_16</td>\n",
              "      <td>New Utrecht Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>IBX_17</td>\n",
              "      <td>8 Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>IBX_18</td>\n",
              "      <td>4 Avenue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>IBX_19</td>\n",
              "      <td>Brooklyn Army Terminal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfb5e390-00b5-4973-aa4f-0fea2b60f7cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfb5e390-00b5-4973-aa4f-0fea2b60f7cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfb5e390-00b5-4973-aa4f-0fea2b60f7cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nCultural binary (0\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"stop_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"S30\",\n          \"S27\",\n          \"S26\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"Tompkinsville\",\n          \"Grasmere\",\n          \"Old Town\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_university_0p25mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_university_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_hospital_0p25mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_hospital_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_stadium_0p1mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cultural_count_0p25mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cultural_count_0p25mi_capped10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_cultural_0p25mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cultural_count_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 13,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cultural_count_0p5mi_capped10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_cultural_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adjacent_major_park_0p25mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adjacent_major_park_0p5mi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cultural raw (0.25mi) summary:\n",
            " count    518.000000\n",
            "mean       9.965251\n",
            "std       15.142864\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        3.000000\n",
            "75%       12.000000\n",
            "max       82.000000\n",
            "Name: cultural_count_0p25mi, dtype: float64\n",
            "\n",
            "Cultural capped (0.25mi) summary:\n",
            " count    518.000000\n",
            "mean       4.289575\n",
            "std        4.082932\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        3.000000\n",
            "75%       10.000000\n",
            "max       10.000000\n",
            "Name: cultural_count_0p25mi_capped10, dtype: float64\n",
            "\n",
            "Cultural binary (0.25mi):\n",
            " has_cultural_0p25mi\n",
            "1    391\n",
            "0    127\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Cultural raw (0.5mi) summary:\n",
            " count    518.000000\n",
            "mean      34.110039\n",
            "std       49.872269\n",
            "min        0.000000\n",
            "25%        3.000000\n",
            "50%        9.000000\n",
            "75%       43.000000\n",
            "max      207.000000\n",
            "Name: cultural_count_0p5mi, dtype: float64\n",
            "\n",
            "Cultural capped (0.5mi) summary:\n",
            " count    518.000000\n",
            "mean       6.677606\n",
            "std        3.807038\n",
            "min        0.000000\n",
            "25%        3.000000\n",
            "50%        9.000000\n",
            "75%       10.000000\n",
            "max       10.000000\n",
            "Name: cultural_count_0p5mi_capped10, dtype: float64\n",
            "\n",
            "Cultural binary (0.5mi):\n",
            " has_cultural_0p5mi\n",
            "1    481\n",
            "0     37\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}